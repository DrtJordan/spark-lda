[1]何清,庄福振,曾立,赵卫中,谭庆.PDMiner:基于云计算的并行分布式数据挖掘工具平台[J].中国科学:信息科学,2014, 07:871-885.
关键词:云计算,并行算法,分布式,数据挖掘,大数据
摘要:随着信息技术和互联网的发展,各种信息呈现爆炸性增长,且包含丰富的知识.从海量数据信息中挖掘得到有用的知识仍然是一个挑战性的课题.近几十年来,数据挖掘技术,作为从海量数据信息中挖掘有用信息的关键技术已经引起了广泛的兴趣和研究.但是由于数据规模的增长,以往的很多研究工作并不能有效地处理大规模数据,因此,开发设计或者扩展已有算法使之能处理大规模数据集,已经成为数据挖掘中非常重要的研究课题.近年来,基于云计算的数据挖掘技术研究已经成为一个热点话题,本文中我们研究开发一个基于大规模数据处理平台Hadoop的并行分布式数据挖掘工具平台PDMiner.在PDMiner中,开发实现了各种并行数据挖掘算法,比如数据预处理、关联规则分析以及分类、聚类等算法.实验结果表明,并行分布式数据挖掘工具平台PDMiner中实现的并行算法:1)能够处理大规模数据集,达到TB级别;2)具有很好的加速比性能;3)大大整合利用已有的计算资源,因为这些算法可以在由这些商用机器构建的并行平台上稳定运行,提高了计算资源的利用效率;4)可以有效地应用到实际海量数据挖掘中.此外,在PDMiner中还开发了工作流子系统,提供友好统一的接口界面方便用户定义数据挖掘任务.更重要的是,我们开放了灵活的接口方便用户开发集成新的并行数据挖掘算法.
[2]汪莹,周婷,王光岐,张海凤.基于数据挖掘的安全管理信息系统研究——以某煤炭企业班组安全管理为例[J].中国矿业大学学报,2014, 02:362-368.
关键词:数据挖掘,数据仓库,煤炭企业,班组安全管理信息系统,安全监测,模糊聚类
摘要:构建了基于7大功能模块的煤炭班组安全管理信息系统,给出了应用数据挖掘到该系统开发与设计中的基本流程.以某煤炭企业为例,采用数据仓库将该企业班组安全管理信息系统中各分立业务数据库以特定主题进行集成,并利用联机分析处理(OLAP)服务器构建了多维星型结构模型.采用模糊聚类算法对该煤炭班组安全监测数据进行了数据挖掘,划分出安全监测点隶属区域,不同区域代表不同安全级别.结果表明:采用数据仓库和OLAP服务器技术,实现了系统对煤炭班组安全信息多角度和多方位分析.该数据挖掘算法提高了安全监测区域划分的准确度,系统界面颜色差异化设计,使得挖掘结果更加直观明了.
[3]傅钢善,王改花.基于数据挖掘的网络学习行为与学习效果研究[J].电化教育研究,2014, 09:53-57.
关键词:网络学习,行为,学习效果,数据挖掘
摘要:随着计算机与网络的快速发展和广泛应用,网络学习已经是学校教育教学的重要组成部分。已有研究表明,网络学习行为与学习效果密切相关,因此探究网络学习行为与学习效果对有效开展网络学习具有重要意义,也是目前研究的热点与趋势。本研究以陕西师范大学参加"现代教育技术"网络学习系统学习的2801名学习者作为研究对象,以数据库数据作为网络学习行为特征数据来源,采用数据挖掘方法与统计学方法对网络学习者的行为特征进行定量分析,并探讨了网络学习行为特征与学习效果的关系。
[4]张继福,李永红,秦啸,荀亚玲.基于MapReduce与相关子空间的局部离群数据挖掘算法[J].软件学报,2015, 05:1079-1095.
关键词:局部离群数据,相关子空间,Map Reduce,局部稀疏度,概率密度
摘要:针对高维海量数据,在Map Reduce编程模型下,提出了一种基于相关子空间的局部离群数据挖掘算法.该算法首先利用属性维上的局部稀疏程度,重新定义了相关子空间,从而能够有效地刻画各种局部数据集上的分布特征;其次,利用局部数据集的概率密度,给出了相关子空间中的局部离群因子计算公式,有效地体现了相关子空间中数据对象不服从局部数据集分布特征的程度,并选取离群程度最大的N个数据对象定义为局部离群数据;在此基础上,采用LSH分布式策略,提出了一种Map Reduce编程模型下的局部离群数据挖掘算法;最后,采用人工数据集和恒星光谱数据集,实验验证了该算法的有效性、可扩展性和可伸缩性.
[5]邓仲华,刘伟伟,陆颖隽.基于云计算的大数据挖掘内涵及解决方案研究[J].情报理论与实践,2015, 07:103-108.
关键词:大数据,大数据挖掘,云计算,体系架构
摘要:文章基于传统数据挖掘与大数据挖掘对比的视角,对大数据挖掘的内涵进行了探讨,提出了云计算与挖掘服务融合的大数据挖掘体系架构,且以融合多功能的Hadoop大数据挖掘平台为例,剖析大数据挖掘内部工作流程并分析其优势及挑战,从而为用户对大数据挖掘的认知与应用需求提供参考。
[6]余永红,向晓军,高阳,商琳,杨育彬.面向服务的云数据挖掘引擎的研究[J].计算机科学与探索,2012, 01:46-57.
关键词:云计算,Hadoop,数据挖掘,面向服务的体系结构(SOA)
摘要:数据挖掘算法处理海量数据时,扩展性受到制约。在商业和科学研究的各个领域,知识发现的过程和需求差异较大,需要有效的机制来设计和运行各种类型的分布式数据挖掘应用。提出了一种面向服务的云数据挖掘引擎的框架CloudDM。不同于基于网格的分布式数据挖掘框架,CloudDM利用开源云计算平台Hadoop处理海量数据的能力,以面向服务的形式支持分布式数据挖掘应用的设计和运行,并描述面向服务的云数据挖掘引擎系统的关键部件和实现技术。依据面向服务的软件体系结构和基于云平台的数据挖掘引擎,可以有效解决海量数据挖掘中的海量数据存储、数据处理和数据挖掘算法互操作性等问题。
[7]黄章树,刘晴晴.基于云计算服务模式的数据挖掘应用平台的构建[J].电信科学,2012, 01:53-57.
关键词:云计算,数据挖掘,框架构建
摘要:本文将云计算的服务模式应用到数据挖掘应用平台的设计中,提出了3层4模式的云计算服务层次体系,并将此体系应用到数据挖掘平台的构建中,构建了基于云计算服务模式的数据挖掘应用平台框架,详述了平台各子系统的功能,阐述了该平台的特色。此平台集成了多种数据挖掘方法,具有良好的通用性和可扩展性,可以为从事数据挖掘应用和研究的企业或学者提供一个良好的交流平台。
[8]盛宇.基于微博的学科热点发现、追踪与分析——以数据挖掘领域为例[J].图书情报工作,2012, 08:32-37.
关键词:微博,学科热点,热点发现,数据挖掘
摘要:指出依据传统信息源对学科热点进行分析研究存在时间上严重滞后的缺点,提出基于微博的学科热点发现、跟踪和分析机制,论证其可行性并给出实现方法和步骤。以基于新浪微博的"数据挖掘"领域学科热点的研究作为实例,将微博结果同传统研究结果进行对比,表明该方法同传统热点分析结论有重合部分,但又可以反映出传统方法所无法反映出的最新热点。
[9]赵又霖,邓仲华,陆颖隽.数据挖掘云服务分析研究[J].情报理论与实践,2012, 09:33-36+44.
关键词:数据挖掘,云服务,云计算,分析
摘要:文章阐述了云服务中Web数据挖掘的相关服务,从云服务理念的角度提出了新的云服务模式——数据挖掘云服务。客观分析了数据挖掘云服务任务实施具有的优势与面临的挑战,结合数据挖掘与云计算的契合点预测了数据挖掘云服务的发展趋势,提出数据挖掘云服务的服务框架。
[10]李思男,李宁,李战怀.多标签数据挖掘技术:研究综述[J].计算机科学,2013, 04:14-21.
关键词:多标签,数据挖掘,分类,排序,度量
摘要:传统的单标签数据挖掘技术研究对象中,每个样本仅属于一个类别标签,但在实际应用中一个样本更倾向于同时具备多个属性,即属于多标签数据类型。多标签数据挖掘技术现已成为数据挖掘技术中的一个研究热点。其研究成果广泛地应用于各种不同的领域,如图像视频的语义标注、功能基因组、音乐情感分类以及营销指导等。从多标签数据挖掘的方法和度量方式两个方面对多标签数据挖掘进行了系统详细的阐述,最后归纳了目前研究中存在的问题和挑战并展望了本领域的发展趋势。
[11]段桂江,严懿,王洋.基于数据挖掘的质量成本分析与控制[J].计算机集成制造系统,2013, 07:1692-1703.
关键词:质量成本,回归分析,关联分析,模糊神经网络,数据挖掘
摘要:为实现基于质量成本的生产过程质量控制与改进,基于回归分析方法对质量成本进行水平分析,确定企业的质量水平,进而对其进行优化分析;结合质量成本数据中包含的质量信息,挖掘隐藏于质量成本动态数据之间的关联规则;基于企业积累的经验数据和关联分析的结果,模糊化生产制造过程的特征数据,利用模糊神经网络对质量成本进行预测性分析;最后根据分析结果,提出质量成本控制与改进的系统方法。
[12]王梦雪.数据挖掘综述[J].软件导刊,2013, 10:135-137.
关键词:数据挖掘,决策树法,关联规则法,神经网络法,研究现状,发展趋势
摘要:随着计算机技术的迅猛发展,数据挖掘技术越来越受到世界的关注。从数据挖掘的概念出发,介绍了数据挖掘的对象、功能及其挖掘过程,结合数据挖掘的几种常见挖掘算法:决策树法、关联规则法和神经网络法等,对其主要思想及其改进做了相关描述;总结了国内外数据挖掘的研究现状和应用,指出了数据挖掘的发展趋势。
[13]李军华.云计算及若干数据挖掘算法的MapReduce化研究[D].导师：傅彦.电子科技大学,2010.
关键词:云计算,MapReduce,中文热点话题,协同过滤
摘要:云计算是2008年以来国际IT业热炒的概念,近两年来已开始在中国落地生根,是业界不可回避和逆转的一大趋势。我们可以把云计算看作是分布处理、并行处理以及网格计算的发展,其中并发、分布是云计算的关键,海量数据处理和海量计算是云计算的重头戏。但是云计算本身只是一种思维模式,要真正发挥它的魔力,除了硬件以外,更重要的是还得有软件的云计算平台支撑以及可以在平台上高效运行的并行化程序。海量数据处理和海量计算是数据挖掘领域的一个常见问题,许多传统数据挖掘算法往往只能适用小规模输入数据,当输入数据增大时,它们往往会因计算量的增大而速度减慢甚至无法运行,这无疑是许多传统挖掘算法的瓶颈。云计算则恰好擅长处理大规模数据和大规模计算,如果我们能够将传统数据挖掘算法并行化,并将之部署到云计算平台上运行,数据挖掘领域中的上述瓶颈问题就能迎刃而解。而能否有效借助云计算平台解决上述问题,关键在于能否合理地将相应的数据挖掘算法并行化。所以本论文首先主要从分布式文件系统和分布式编程模式两大方向分析了Google、Sector/Sphere和Hadoop三大云计算平台框架;然后从用户角度出发,综合考虑文本内容、人类遗忘性和话题流行度等因素,提出了一种基于网络日志的中文热点话题提取算法,并将其MapReduce化后部署到Hadoop云计算平台上运行,取得了良好的加速比效果,成功地提高了算法的运行速度和扩大了算法输入数据的规模;最后通过分析传统协同过滤算法、局部线性回归算法和朴素贝叶斯算法的详细流程、瓶颈问题和可并行化点,采取并行和串行相结合的方式,提出了将这几大算法MapReduce化的方法,不但证明了这些算法的可MapReduce化,而且在输入大批量数据的Hadoop集群实验中,取得了不错的加速比效果,比较成功地解决了这些算法计算量过大和计算时间过长的难题。本论文的研究为数据挖掘领域相关算法提供了可行的MapReduce化方案,实验结果证明了上述方案的切实有效性。
[14]张明辉.基于Hadoop的数据挖掘算法的分析与研究[D].导师：王清心.昆明理工大学,2012.
关键词:数据挖掘,Hadoop,Mahout,K-Means
摘要:数据挖掘,也称数据库中知识发现,就是从大量的、不完全的、有噪声的、模糊的、随机的数据中,提取隐含在其中的、人们事先不知道的、但又是潜在有用的信息和知识的非平凡过程。目前,数据挖掘技术已经在金融、医疗、军事、管理等诸多领域的决策分析中被广泛应用。随着计算机和互联网技术的高速发展,数据量也呈爆炸性增长,极大的加重了数据挖掘技术的负担。云计算的出现,为数据挖掘提出了新的方式,其弹性化的计算能力,海量的存储能力,节约成本,提高效率方面的优点,成为解决数据挖掘技术所面临难题的有效方式。Hadoop是一个用于构建云计算平台的Apache开源项目,基于此项目的分布式计算平台已经非常稳定,并被广泛应用于很多领域。在Hadoop平台上,采用了MapReduce编程模型来进行分布式计算,使用HDFS分布式文件系统来实现文件存储。将传统的数据挖掘算法移植到Hadoop平台下,便可进行大规模数据的挖掘任务。Mahout便是Apache下一个全新的开源项目,提供了一些使用MapReduce编程模型完成的机器学习和数据挖掘算法,旨在帮助开发人员更加方便快捷地创建智能应用程序。因此本文首先从MapReduce编程模型和HDFS两方面来介绍Hadoop平台,分析其核心架构和运行机制。然后对Mahout进行了深入的探讨,仔细研究了Mahout内部数据表示模型,并以K-Means算法为例,分析其在Mahout中的并行化策略。最后,使用路透社21578新闻集,对它进行聚类来验证该算法的有效性,并分析实验结果,对K-Means算法聚类结果从不同距离度量方式,运行时间,迭代次数等角度,进行评估。并使用不同数据量数据,分别在串行和并行两种模式下运行K-Means算法,比较其效率。
[15]于自强.海量流数据挖掘相关问题研究[D].导师：禹晓辉.山东大学,2015.
关键词:流数据,分布式计算,k近邻搜索,频繁伴随模式
摘要:随着移动终端、传感器、互联网等技术的飞速发展,流数据作为一种典型的大数据已经在许多领域广泛出现。当前,流数据包含时空数据、传感数据、社交网络数据等多种类型数据,数据本身蕴含巨大的价值,这使得流数据挖掘具有重要的学术价值和应用价值。与静态数据相比,流数据有其自身特点：原始数据量巨大、数据到达速度快、数据处理对时效性要求高、数据难以重复获取。由于流数据自身的特点,一些已有的数据挖掘技术很难直接用来解决流数据挖掘问题,因此研究流数据挖掘相关问题具有重要意义。本文针对海量流数据挖掘领域的相关问题进行了研究。第一个问题是多数据流的频繁伴随模式发现问题。频繁伴随模式(Frequent Co-occurrence Pattern)是指一组对象较短时间内在同一个数据流里伴随出现,并且在之后指定的一段时间内以同样的方式出现在多个数据流上。本文的目标是实时发现多个数据流里出现的所有频繁伴随模式。在实际应用中,城市交通管控系统的伴随车辆发现、电子商务中的热销商品组合挖掘、基于签到数据的伴随人群发现以及社交网络数据中基于高频伴随词组的热点事件发现等应用都可以抽象为多数据流的频繁伴随模式发现问题。为解决这一问题,本文提出了基于segment片段的流数据划分策略,并设计了DIMine和CooMine两种挖掘方法。这两种算法首先对有效的segment片段建立索引,然后基于segment索引结构设计剪枝策略,通过不断削减挖掘范围以达到快速发现频繁伴随模式的目的。DIMine和CooMine挖掘算法在挖掘效率、内存消耗和索引维护代价取得了很好的效果。但它们是适合单机运行的集中式算法,难以直接部署到分布式环境中应对规模巨大的流数据。为了能够在大规模流数据中发现频繁伴随模式,本文设计了多数据流频繁伴随模式的分布式挖掘方法。该方法首先产生所有数据流中可能形成频繁伴随模式的候选模式,然后通过哈希方法将不同数据流的相同候选模式发送至至同一个计算单元,继而判定该候选模式是否为频繁伴随模式。由于每个候选模式是独立的,不同的候选模式可以由多个计算单元同时处理,因此该方法能够利用分布式服务器集群进行并行计算,从而具备良好的可扩展性。本文研究的第三个问题是分布式时空数据的k近邻搜索问题。时空数据是一种典型的流数据,k近邻搜索是许多数据挖掘问题的基本操作。给定一个时空数据集和任意一个查询点,k近邻搜索要求实时地得到该时空数据集中与该查询点距离最近的k个对象。已有的时空数据k近邻搜索算法通常假设时空数据集规模有限且查询数量较少,其研究重点是面向单个计算节点的k近邻集中式查询算法,很难将它们应用到分布式环境下以处理大规模时空数据和高并发k近邻搜索。为此,本文提出了面向海量时空数据的分布式k近邻搜索算法。该算法首先设计了分布式动态条状索引结构(DynamicStrip Index, DSI),与已有的网格索引相比,DSI索引结构能够适应不同的数据分布。此外,DSI索引结构更容易分布式部署到多个计算节点之上。基于该索引,我们设计了DKNN查询算法。该算法能够将KNN查询的迭代次数减少至两次,与已有的算法相比,DKNN算法的性能更加高效且可以预测。随后,我们将DSI索引结构和DKNN查询算法在开源的流数据处理平台S4上进行了实现,通过大量实验证明了算法良好的可扩展性和优异性能。本文对流数据挖掘相关问题进行了深入研究,针对特定问题,给出了针对性的解决方案。本文的创新点和贡献如下：(1)本文首次提出多数据流频繁伴随模式发现这一问题,并给出了DIMine算法和CooMine算法两种解决方案。(2)本文提出了分布式的多数据流频繁伴随模式挖掘算法,实现从大规模流数据中快速发现频繁伴随模式。(3)本文设计了海量时空数据的分布式k近邻搜索算法,以应对规模急剧增长的时空数据和海量并发查询。
[16]李秋虹.基于MapReduce的大规模数据挖掘技术研究[D].导师：汪卫.复旦大学,2013.
关键词:数据挖掘,MapReduce,云计算
摘要:网络技术的快速发展和信息共享系统的大量应用催生了大数据时代的来临,很多传统的基于单机的数据挖掘算法已经无法满足大数据的挖掘需求,如何进行高效的并行的数据挖掘成为当前研究的热点。当前各种计算机应用系统处理的数据规模日渐增长和结构日益复杂,大规模图数据和大规模高维数据的出现对传统的数据挖掘方法提出了挑战。大规模图结构数据在各种应用中大量出现,例如生物信息学领域包含庞大的基因相互作用网络；WEB数据管理领域包含庞大的社会网络、WEB网页网络,社会媒体数据也多是以图的形式描述的。很多互联网上的信息如音频、视频都可表示为高维数据,在大数据背景下有效地进行图数据和高维数据的数据挖掘需要合适的分布式计算模型。MapReduce计算模型是目前最流行的一种云计算环境下的分布式计算模型,它可以将计算均匀地分布在多台异构的计算机上,并且屏蔽了复杂的并行编程,使得复杂的并行应用可以归结到两个简单的函数,map函数和reduce函数,它的高可用性、高可扩展性、高容错性以及简单性使得其受到企业界和学术界的重视。一些著名的IT公司如Facebook、雅虎等均采用Hadoop作为云计算环境中的重要基础软件。虽然MapReduce在分布式计算方面取得了巨大的声誉,但由于很多图数据和高维数据的数据挖掘算法的计算及其分布式处理往往涉及复杂的处理流程,经常需要多次迭代和大量的通信,而MapReduce通常适用于大数据集上的简单应用,导致MapReduce模型并不适用于具有局部性和迭代性的数据挖掘应用。但是其他的图处理系统,如Pregel, Hama等却不具备MapReduce优异的可扩展性和容错性,这对大规模的数据挖掘是非常重要的一个性质。为了使得MapReduce模型适用于图数据和高维数据的挖掘,本文对其进行了改造,提出了基于MapReduc e的局部迭代的MapReduce模型(LI-MR模型),并且在局部迭代的MapReduce模型指导下,研究一些具体的具有局部迭代性的数据挖掘算法,包括社会网络的权威值计算和社会网络的社区挖掘,以及高维数据聚类问题。本文主要研究内容和研究贡献包含以下几个部分。1.提出局部迭代的MapReduce模型以支持图挖掘由于MapReduce编程模型缺乏对算法迭代性和局部性的有效的支持策略,为了适应数据挖掘算法的迭代性和局部性,我们提出了局部迭代的MapRedue模型(LI-MR模型),并且通过两种方式实现了LI-MR模型的主要思想,第一种方式是扩展Hadoop系统,对其内核API进行改造以实现缓存和索引,从而支持Hadoop应用对数据的随机存取需求；第二种方式是Hadoop系统集成HBase数据库来实现缓存和索引。LI-MR模型的主要思想包括以粗粒度的数据块作为处理单位,消息通讯主要为数据块之间的信息交互；通过缓存和索引机制从上一次迭代的结果中获得对应数据块计算需要的局部信息,支持数据块的内存计算,支持算法的局部计算。2.提出局部迭代的标号传播算法大规模图的划分问题一直是人们所关注的热点问题,社会网络的社区挖掘作为图划分问题的一个应用,有很高的时效性的要求。标号传播算法(LPA)是一个时间复杂度为线性的快速社区挖掘算法,但是对于大规模的社会网络其运行时间仍然过长,本文提出局部迭代的标号传播算法运用LI-M(?)模型来解决标号传播算法的并行化问题。3.提出局部迭代的PageRank算法以往在MapReduce上运行PageRank算法,采取的方法以边为处理单位,这样导致数据在集群内的大量迁移。局部迭代的PageRank算法在LI-MR模型的指导下,将传统的基于内存的PageRank算法与MapReduce的良好的可扩展性结合起来,采用子图作为处理单位,子图内部的通讯不必在整个集群中迁移,这样,既保存了传统内存算法的效率,又得益于MapReduce的高可用性。4.提出基于局部敏感哈希函数的海量高维数据的分布式聚类方法对于海量高维数据的聚类,本文提出一种有效的基于代表点的批量处理方式,通过局部敏感性哈希函数,可以将距离近的数据点快速地聚集在一个桶中,采用桶的中心点作为代表点来代表这个桶内的所有点,通过这种代表点机制可以有效地削减聚类的数据规模。对于海量数据,需要一个较大的分类个数来满足对数据精度的刻画,对于较大的分类个数,本文通过局部敏感哈希函数来对比较计算进行裁减,尤其是对于具有较大k值的聚类,该方法可以在保证聚类质量的前提下大幅度提高聚类的效率。提高k-means运行效率的另一种方法是提高所选中心点的质量,本文针对k-means++不易于并行化的问题,提出了一种基于LI-MR模型的中心点选取方法,提高了k-means++并行选取中心点的效率。
[17]李菁菁,邵培基,黄亦潇.数据挖掘在中国的现状和发展研究[J].管理工程学报,2004, 03:10-15.
关键词:数据挖掘,趋势,统计
摘要:数据挖掘是人工智能和数据库研究的新兴领域,近年来,数据挖掘技术的理论与应用研究发展迅速,并引起了国内外研究人员的重视。本文以科学引文索引数据库(SCI)、工程索引数据库(EI)以及清华全文数据库(CNKI)中有关"数据挖掘"研究文章的统计数据为研究基础,对数据挖掘在我国研究的总体趋势、研究热点、研究分支三个方面进行分析和研究。本文分析了数据挖掘在我国的发展,并对进一步发展我国数据挖掘的理论研究和实际应用提出了建议。
[18]王光宏,蒋平.数据挖掘综述[J].同济大学学报(自然科学版),2004, 02:246-252.
关键词:数据挖掘,数据库中知识发现,人工智能,模式
摘要:从人工智能、统计分析和数据库技术3个方面对数据挖掘技术进行了总结;从模式识别的角度讨论了数据挖掘技术的主要任务,包括分类、聚类、回归、关联、序列和偏差6种模式的识别.详细介绍了数据挖掘技术的常用方法,包括模糊理论、粗糙集理论、云理论、证据理论、人工神经网络、遗传算法以及归纳学习.列举了当前数据挖掘技术的实际应用场合,并指出其今后的发展趋势以及急需关注的问题.
[19]孙玉芬,卢炎生.流数据挖掘综述[J].计算机科学,2007, 01:1-5+11.
关键词:数据流,数据挖掘,时空复杂度,滑动窗口
摘要:作为一种新的数据形态,流数据对数据挖掘提出了诸多挑战。学者们已提出大量处理流数据的挖掘算法。本文对这些算法进行了综述。首先介绍了多个不同的数据流模型,这些模型对算法设计有着不同的要求。然后,总结了流数据挖掘算法的特点,并给出了算法中常用的技术。最后,分析了各个流数据挖掘任务中的代表性算法。
[20]贾澎涛,何华灿,刘丽,孙涛.时间序列数据挖掘综述[J].计算机应用研究,2007, 11:15-18+29.
关键词:时间序列,数据挖掘,相似性搜索,模式发现
摘要:在综合分析近年来时间序列数据挖掘相关文献的基础上,讨论了时间序列数据挖掘的最新进展,对各种学术观点进行了比较归类,并预测了其发展趋势。内容涵盖了时间序列数据变换、相似性搜索、预测、分类、聚类、分割、可视化等方面,为研究者了解最新的时间序列数据挖掘研究动态、新技术及发展趋势提供了参考。
[21]陈英,徐罡,顾国昌.一种本体和上下文知识集成化的数据挖掘方法[J].软件学报,2007, 10:2507-2515.
关键词:数据挖掘,本体,上下文知识,归纳学习算法
摘要:在数据挖掘中使用本体和上下文知识能够将普遍的知识和特定的知识引入数据挖掘的决策因素中,是增进数据挖掘准确性的有效手段,同时也是数据挖掘领域研究的热点和难点之一.针对该问题,首先探讨了本体与上下文知识的集成化表示方法,包括上下文知识分类方法、如何在本体描述方法上扩展上下文知识及上下文知识转化方法.其次,以层次化结构的本体与上下文知识为例,构建了一个依据于本体和上下文知识集成的归纳学习算法并验证了该算法的有效性和准确性.
[22]李锋.面向数据挖掘的隐私保护方法研究[D].导师：李建华.上海交通大学,2008.
关键词:数据挖掘,隐私保护,分布式模型,隐私保护聚类,隐私评估方法,安全距离比较
摘要:数据挖掘技术的研究工作极大地推动了自动化数据分析和预测技术的发展。现有的数据挖掘技术,包括探索性分析、描述性和预测性建模、模式和规则发现、内容分析等,已逐渐应用于各类政府服务以及商业科研活动中。对原始数据的访问是挖掘工作开展的前提,但对持有者而言,数据集通常具有私密性,直接访问该类数据将构成隐私威胁。随着信息隐私保护的相关政策和法律法规陆续问世,隐私问题成为数据挖掘迈向实际应用的重大阻碍之一。采用技术手段,能够在保证足够精度和准确度的前提下,使数据挖掘方在不触及实际隐私数据的同时,仍能进行有效挖掘工作,称为数据挖掘的隐私保护方法。围绕分类挖掘、聚类挖掘和关联规则挖掘等主要的数据挖掘方法,已经展开了许多研究工作。而隐私保护的有效性以及与挖掘环境的耦合性是数据挖掘隐私保护方法需要解决的根本问题。围绕该问题,本文从隐私保护方法的安全评估与增强以及隐私保护方法与环境耦合度方面展开了深入研究。从隐私保护技术角度,本文首先分析和总结了现有数据挖掘隐私保护方法的发展,从数据分布、挖掘类型、保护技术等视角给出了现有数据挖掘隐私保护方法的完整分类视图,并在此基础上进行了比较和归纳。数据扰乱方法是集中式环境中的主要数据挖掘隐私保护方法,其中加性随机干扰技术具有代表性。本文通过对该技术进行矩阵建模,采用特征向量分解技术,发现现有的随机干扰技术在特征值分解攻击中存在脆弱性,也使得原有的隐私强度评估方法失去效用。针对该问题,本文提出了新的隐私强度量化评估模型,并通过上限阀值曲线投影,推导和设计了基于该评估模型的随机干扰改进方法。实验表明,该方法在基于特征向量分解的攻击中具有鲁棒性。随机干扰技术是一种通用的数据扰乱方法,对其进行有效评估和改进具有通用性和普遍意义。分布式环境是数据挖掘应用增长较快的领域,但由于分布式环境的复杂度和安全问题,传统集中式数据挖掘隐私保护方法无法直接应用于分布式环境中。本文分析和定义了分布式挖掘环境的隐私安全等级,并给出了相应的隐私约束问题定义。基于该问题,提出了多方安全统计方法和k匿名置换协议,并在此基础上给出了分布式数据扰乱隐私保护方法,将集中式加性随机干扰技术安全应用于分布式环境中。之后通过定义多个共谋攻击和恶意攻击模型,对方法的安全性进行了分析,在实验和分析中证明了该方法在半诚实环境中是隐私安全的,具有极高的健壮性。对该方法的研究,使传统集中式的随机扰乱和重建技术能够直接应用于分布式环境中,使之成为扰乱技术在分布式环境中实现的一般化框架。欧氏空间运算是数据挖掘的基础算法之一。本文分析和研究了基于欧氏空间运算的分布式数据挖掘隐私保护方法的安全性,发现在共谋攻击中存在安全威胁。结合同态加密技术,本文提出了欧氏空间下的三方及多方安全距离比较协议,并在预处理、并行计算、协议归并等方面进行性能优化。最后应用于全分布式的k中值聚类过程,通过实验证明了方法的安全性和优化的有效性。此外,安全距离比较协议也能够直接支持基于欧氏距离及其扩展的数据挖掘方法,如k近邻、k均值等,在分类挖掘、聚类挖掘、Web挖掘等领域具有通用性和普遍意义。最后,对本文的研究工作进行了总结和展望,从基于信号处理的随机扰乱与统计方法、随机扰乱方法的统一评估标准、分布式环境下的通用匿名数据运算方法、半诚实环境中共谋攻击的统一安全性衡量方法、密码机制在迭代计算中的优化方法等角度探讨了继续研究的可行性和预期目标。
[23]陈桂芬.面向精准农业的空间数据挖掘技术研究与应用[D].导师：刘大有.吉林大学,2009.
关键词:玉米精准作业,空间数据挖掘,模糊聚类,粗糙集,决策树,时间序列,智能空间决策系统
摘要:随着“3S”技术在农业领域的不断普及,农业数据增长迅速,农业已成为空间数据挖掘最富有机遇与挑战性的应用领域之一。本文是在实施国家“863”项目“玉米精准作业系统研究与应用”的过程中,基于土壤肥力数据库和玉米精准作业的要求,利用空间数据挖掘技术,提出了解决玉米精准施肥、土壤肥力评价、地力等级分类和产量预测等问题的新方法,研究成果已成功应用于玉米精准作业智能决策系统中。主要工作和创新点:1.进行了基于空间模糊聚类算法的玉米精准施肥的研究。使用模糊聚类分析方法,建立土壤养分分类模型;利用八连通法进行空间聚类分析,并将模糊聚类结果应用于空间聚类。这种两阶段聚类方法优于传统的单阶段聚类,其分类结果对玉米精准施肥具有重要的指导意义。2.提出了基于加权的空间模糊动态聚类算法及在土壤肥力评价中的应用。该算法与基于模糊等价关系的传递闭包方法进行比较表明,其聚类准确率要明显高于未加权的模糊聚类算法。将其改进的算法运用到精准农业的土壤肥力评价中,与实际情况相符。3.研究了基于粗糙集-决策树的优化算法及在地力评价中的应用。研究结果表明基于聚类的样本优选方法去除了大量冗余样本,基于粗糙集的属性约简方法去除了部分冗余属性,使用决策树方法构建决策树,节省了时间和空间,降低了模型的复杂度。因而,本文提出的聚类和粗糙集约简相结合的方法在时间、空间和准确性方面均优于其他方法,该算法能有效提高土壤地力等级分类的准确性和客观性。4.采用时间序列算法中的滑动求和自回归方法(ARIMA)来对玉米产量进行预测,实验结果表明应用ARIMA模型预测的玉米产量与实际值拟合效果很好。5.设计并实现了玉米精准作业智能空间决策支持系统(MPISDSS)。该系统将具有空间信息处理功能的地理信息系统、具有空间信息分析功能的空间数据挖掘技术、人工智能领域中的专家系统技术与传统的信息管理系统、决策支持系统有效集成,并将GIS中的统计分析方法与数据可视化结合起来,极大提高了农业管理部门进行农业生产决策的能力。
[24]朱传华.三峡库区地质灾害数据仓库与数据挖掘应用研究[D].导师：胡光道.中国地质大学,2010.
关键词:三峡库区,地质灾害,数据仓库,滑坡灾害预测,数据挖掘
摘要:崩塌、滑坡、泥石流等突发性地质灾害及其风险评价已经成为人们普遍关心的主要问题之一。滑坡是地质灾害的主要类型之一,其危害和影响程度仅居地震、火山之后,具有分布地区广、发生频率高、运动速度快、灾害损失严重等特点。对滑坡灾害进行预测预报研究能够提高对突发性地质灾害事件的快速反应能力,达到有效防灾、减灾的目的,意义十分重大。长江三峡库区是中国滑坡灾害发生的重灾区之一,三峡水库沿岸地质地貌条件复杂,且处于亚热带气候区,雨量充沛,且多暴雨,故崩塌、滑坡及泥石流时有发生,古滑坡分布甚多。移民工程迁建的新城镇几乎都在斜坡地带,水库蓄水后的库水位上升及泄洪后的库水位下降的变化及移民工程的影响下,很多古滑坡将会复活,而且还会导致新滑坡的发生。一些县城新址,由于受滑坡影响被迫多次变迁,不少移民工程遭受崩滑灾害或严重威胁。随着三峡工程的进展,对库区地质灾害的防范,引起了国务院高度重视。2001年7月,国务院全面启动长江三峡库区地质灾害防治。随着三峡库区地质灾害防治信息化建设工程的推进,目前已积累了丰富的地质灾害数据。由于地质灾害的突发性和危害性,三峡库区地质灾害预警指挥要求按指挥对象,包括不同灾害类型的不同预警级别、同一预警级别内的不同分级对信息进行重组,不但需要有分析、统计和利用这些信息的高水平方法库和模型库,还需要能够在浩如烟海的数据库中快速去寻找和挖掘有用信息的工具,使决策过程准确、迅速,这是传统的操作型数据库难以或无法作到的。而利用数据仓库联机分析处理与数据挖掘的理论及方法技术,可以对海量数据进行自动有效地分析及利用,发现数据内在联系,从中挖掘出有用的规则和知识,为决策支持系统服务。本研究的目的在于使用数据仓库技术有效整合长江三峡库区的地质灾害数据,并应用数据挖掘技术,从滑坡灾害历史数据中挖掘出有利于滑坡灾害预测预报的有效信息,为预警指挥系统服务。论文的研究内容主要包括地质灾害数据仓库建设和滑坡灾害预测数据挖掘应用研究等两个方面：(1)地质灾害数据仓库的建设采用“数据驱动”的系统设计方法,即数据仓库的模式主要由分析下层的数据源系统获得,其思路主要是：利用以前已经建立的数据库进行数据仓库的建设,要尽量利用已有的数据和代码,而不是从头开始；数据仓库的设计是从已有的数据库系统出发,按照业务领域的要求重新考察数据之间的联系,以组织数据仓库中的主题。整个设计按照需求规格说明、概念模型设计、逻辑模型设计和物理模型设计等四个阶段完成。在需求规格说明阶段识别了源数据库,即已有的操作型数据库,包括地质灾害专业属性数据库和空间数据库等。根据对数据源的分析,确定了三峡库区地质灾害数据仓库的主题,包括区域地质灾害预测预报、移民新城区地质灾害预测预报、单体地质灾害预测预报、涌浪预测预报、治理工程评估、监测预报和预警决策支持与应急指挥等主题。根据数据的收集进度和本人已完成的研究工作等实际情况,论文选择区域地质灾害预测预报主题和滑坡监测预报主题等两个主题作为研究的重点。在主题确定的基础上,概念设计阶段分别对区域地质灾害预测预报主题和滑坡监测预报主题数据源的数据层次进行了分析,推导并选取了滑坡敏感性事实和滑坡位移监测事实,确定了事实度量、维和层次,建立了滑坡敏感性和滑坡位移监测概念多维模型。其中滑坡敏感性事实确定的事实度量有已知滑坡、工程地质岩组、斜坡结构类型、构造、坡度、高程、地表河流、植被、土地覆盖、公路、坡向和地表曲率等度量；维有滑坡类型维、比例尺维和地区维等维,相应的层次分别为类型—>类—>型—>式—>期—>性、比例尺—>规模和县市—>省—>库区等层次。滑坡位移监测事实确定的事实度量有变形位移量、降雨、温度、库水位变动、地震、突发性暴雨和人工活动等度量；维有滑坡类型维、时间维、监测点维和监测类型维等维,相应的层次分别为类型—>类—>型—>式—>期—>性、日期—>月份—>季度—>年份、监测点—>滑坡体—>村—>镇—>县和监测内容—>监测仪器—>监测方法—>监测类型等层次。逻辑设计阶段将已建立的概念多维模型转换为逻辑多维模型,并设计了滑坡敏感性多维模型和滑坡位移监测多维模型的ETL过程,其中滑坡敏感性多维模型的ETL过程包括空间数据ETL和属性数据ETL两个部分。物理模型设计阶段在Oracle Warehouse Builder (OWB)中实现了数据源到目标数据仓库的上载,建立基于Oracle数据库的地质灾害数据仓库,并从分区、索引、实体化视图和存储结构设计等方面对数据仓库性能进行优化。(2)滑坡灾害预测数据挖掘应用研究基于地质灾害数据仓库的多维数据集,使用内嵌于Oracle数据库的Oracle Data Mining (ODM)中的支持向量机回归算法展开工作。支持向量机作为下一代算法,它是基于统计模型而不是通过自然学习系统的松散分析,在理论上可以取得最优的预测结果。能较好地解决小样本、非线性高维数和局部极小点等实际问题,被视为替代神经网络的较好算法。ODM中的支持向量机回归算法具有使用方便,易于部署,对算法模型参数的干预较少的特点。①首先,以忠县为研究区,进行滑坡敏感性区划研究。滑坡敏感性分析通过已发生滑坡和致滑坡内在因子之间的空间分布统计关系,评价特定地区范围内潜在滑坡事件发生的可能性,有利于国土开发和规划,从宏观上减轻滑坡灾害的威胁。研究采用普遍认可和使用的GIS栅格模型,基于数据仓库多维建模建立滑坡敏感性多维数据集,在数据仓库的基础上使用ODM的支持向量机回归算法对研究区的滑坡敏感性进行分析。为了检验Oracle Data Mining中支持向量机回归算法的性能,特引入两种常用的定量统计模型：证据权法和Logistic回归方法,进行研究对比。采用与支持向量机模型建立时完全一致的样本和预测变量,建立证据权预测模型和Logistic回归预测模型。预测结果表明,尽管没有完全预测全部已知的滑坡分布,但支持向量机得到的敏感性很高和敏感性高的区域预测了88.02%的已知滑坡,证据权法和Logistic回归所预测的百分比分别为84.48%和58.94%。可以看出,支持向量机模型的预测能力优于证据权法和Logistic回归模型。②另外,以白水河滑坡监测数据为例,进行滑坡位移监测数据时间序列分析。时间序列分析具有预测复杂系统发展趋势的能力,一直是滑坡位移动态预报研究的热点。针对目前的预测模型多基于平面文件进行分析的不足,研究中引入在数据仓库多维模型的基础上进行时间序列分析的框架,数据挖掘基于数据仓库,并参照状态空间重构原理对白水河滑坡位移时间序列数据进行处理,使用ODM的PL/SQL API建立支持向量机回归时间序列模型对处理后的数据进行挖掘,多步预测结果表明,支持向量机回归算法的前5步预测值的误差率控制在8%以内,性能相当不错。第六步的预测值误差较大,可能是受4,5月份降雨量达355mm及5月份水位下降4.68m的组合工程情况的影响,滑坡已处于临滑突变阶段(2007年6月30日白水河滑坡中部约10万m3的土体坍塌座落。),数据不再具有指导性,但84.1%的准确性仍能满足工程要求。由此可见,ODM的支持向量机回归算法可应用于滑坡监测的短期预测。通过论文研究,主要的创新与特色在于：(1)基于数据仓库的概念,通过对滑坡敏感性事实的深入分析,设计并建立空间数据GIS栅格模型的滑坡敏感性多维数据集,将三峡库区滑坡和致滑坡因子空间数据按不同比例尺、不同地区和不同滑坡类型等三个视角存放在地质灾害数据仓库中,实现空间数据按主题的集成,达到快速响应滑坡空间预测预报研究的数据需求。(2)深入分析滑坡位移监测时间序列数据,考虑时间、监测点、监测类型和滑坡类型等四个维度,设计并建立滑坡位移监测多维数据集。并基于数据仓库的多维数据集,使用ODM的PL/SQL API建立支持向量机回归时间序列模型进行数据挖掘研究。论文研究也存在一些不足,主要表面在以下这些方面：(1)数据仓库的构建基于对业务领域的理解和对业务数据“预处理”,对于具有连续性属性的空间数据预处理——致滑坡因子的重分类——采用专家经验和双变量统计方法验证结合,具有一定的主观性。(2)设计并建立滑坡位移监测多维数据集并对滑坡位移监测时间序列进行数据挖掘研究,但没有对位移和库水位、位移和降雨量进行交叉预测,挖掘模型应用的可靠性和准确性有待进一步验证。(3)数据挖掘与GIS制图没有一体化。数据挖掘的结果数据需要输出,然后由GIS软件生成滑坡敏感性预测结果图。总之,将地质灾害数据集成到数据仓库,选用基于数据仓库的挖掘工具,进行滑坡灾害预测预报是一种可行的新途径。
[25]王爱平,王占凤,陶嗣干,燕飞飞.数据挖掘中常用关联规则挖掘算法[J].计算机技术与发展,2010, 04:105-108.
关键词:数据挖掘,关联规则,频繁项集,挖掘算法
摘要:文中首先介绍了数据挖掘中关联规则的经典算法——Apriori算法。再从宽度、深度、划分、采样、增量式更新等几个角度对关联规则挖掘进行了分类讨论。然后运用文献查询和比较分析的方法对常见的关联规则挖掘算法进行了概述,主要包括FP-growth算法、DHP算法、Partition算法、FUP算法、CD算法等算法。最后对关联规则挖掘的发展远景进行了展望。
[26]黄兴荣,李昌领.基于SQL Server 2005的数据挖掘的研究[J].计算机与现代化,2010, 05:195-198.
关键词:数据挖掘,SQL Server2005,数据挖掘方案,SQL Server分析服务
摘要:提高数据挖掘的效率是目前信息技术研究的热点问题之一。介绍了数据挖掘的概念、过程模型以及体系结构,讨论了基于Microsoft SQL Server 2005的数据挖掘方案和采用SQL Server分析服务实现数据挖掘的相关技术。采用SQLServer分析服务的数据挖掘,实现了数据挖掘、数据仓库与应用程序的紧密耦合,从而大大提高了数据挖掘的效率。
[27]丁雪.基于数据挖掘的图书智能推荐系统研究[J].情报理论与实践,2010, 05:107-110.
关键词:数据挖掘,关联规则,智能推荐
摘要:针对目前传统数字图书馆无法为用户提供准确个性的图书推荐服务的问题,提出构建基于数据挖掘技术的图书智能推荐系统,简单分析数据挖掘技术中关联规则技术适用图书推荐的原因和相关概念,并且对该系统的框架进行研究,最后通过实验,运用数据挖掘软件对真实的借阅记录进行关联规则挖掘,得出关联规则作为图书智能推荐系统的关键技术是行之有效的结论。
[28]李婷,傅钢善.国内外教育数据挖掘研究现状及趋势分析[J].现代教育技术,2010, 10:21-25.
关键词:教育数据挖掘,研究现状,关键内容,发展趋势
摘要:教育数据挖掘是一个新兴的、备受关注的研究领域。文章运用文献计量与内容分析法,对国内外公开发表的关于教育数据挖掘的文献进行统计分析,把握其发展脉络及研究现状,探讨研究中的关键内容,并展望该领域未来的研究趋势,为进行教育数据挖掘的研究与实践提供参考。
[29]龚著琳,陈瑛,苏懿,刘雅琴,徐立钧.数据挖掘在生物医学数据分析中的应用[J].上海交通大学学报(医学版),2010, 11:1420-1423.
关键词:数据挖掘,生物医学,统计学
摘要:随着信息技术的发展,采集、存储和管理数据的手段日益完善,数据挖掘学科应运而生。文章阐述数据挖掘的概念;通过给出各种数据挖掘方法在生物医学研究领域中的应用实例,分析数据挖掘与生物医学领域中统计学的关系,并就国内生物医学数据挖掘的应用现状、需要解决的问题以及今后研究的发展方向等进行综述。
[30]李玲俐.数据挖掘中分类算法综述[J].重庆师范大学学报(自然科学版),2011, 04:44-47.
关键词:数据挖掘,分类,综述
摘要:对分类算法中需要解决的关键问题进行了分析;综述了不同分类算法的思想和特性,决策树分类算法能够很好地处理噪声数据,但只对规模较小训练样本集有效;贝叶斯分类算法精度高、速度快,错误率低,但分类不够准确;传统的基于关联规则算法分类准确率高,但容易受硬件内存的制约;支持向量机算法分类准确率高、复杂度低,但速度慢。针对各种分类算法的缺陷,结合其优点,论述了当前一些速度更快、准确率更高、能实现更好分类效果的新算法,如多决策树综合技术、基于先验信息和信息增益的混合分类算法,基于粗糙集和遗传算法的神经网络分类算法等;对数据挖掘分类算法作了展望,提出今后的研究重点。
[31]李雪锋.基于云计算环境的web数据挖掘算法研究[D].导师：陈旭东.北京交通大学,2010.
关键词:云计算,Hadoop集群,Web Graph挖掘算法,社交网络
摘要:目前,单一CPU节点的计算能力已经发展到一个瓶颈,而利用云计算技术,人们可以方便的通过网络获取强大的计算能力、存储能力以及基础设施。因此将消耗大量计算资源的复杂计算通过网络分布到多节点上进行计算的方式成为了新的有效的解决方案。Web数据挖掘是从Web超链接、网页内容和使用日志中探寻有用的信息的数据挖掘方法。Web Graph是Web数据挖掘中非常重要的用来描述web信息的数据结构。这种数据结构在Web页面爬取、搜索引擎结果排序以及社交网络等应用中更是有着非常广泛的应用。论文针对Web数据挖掘中Graph的算法在云计算环境中进行研究。论文介绍了Web Graph数据结构,搭建了云计算环境,提出社交网站用户Graph数据的获取方案,并使用力导向算法形象描述Graph数据；论文同时设计并优化了Web Graph直径的计算算法,并利用云计算环境进行了算法功能和性能测试,测试结果表明：在集群中部署分布式算法,可以显著提高Graph数据挖掘的效率。论文研究成果在搜索引擎以及社交网络分析领域具有较高的应用价值。
[32]张保稳.时间序列数据挖掘研究[D].导师：何华灿.西北工业大学,2002.
关键词:数据挖掘,时间序列分析,时间序列数据挖掘,时序相似性,有效支持度,状态演化模式挖掘,模糊状态演化模式挖掘
摘要:作为一种新的数据分析工具，数据挖掘的发展十分迅速。各种类型的数据都可以作为数据挖掘的对象。时间序列在数据集中十分普遍。对时间序列进行数据挖掘已成为当前研究的焦点之一。当前对时间序列数据挖掘的研究大部分集中在相似性研究方面，针对模式发现和规则发现的研究内容比较少。而且，这些研究很少考虑时间序列自身的复杂性。另外，对于时间序列数据挖掘过程中不确定性的处理尚待探讨。本文主要研究了一种新的时间序列数据挖掘框架。该框架在挖掘过程中结合时序分析技术，引入了时序本身的内在特征，可以从时序中发现其背后系统的规律，并将其用于未来趋势的分析和预测。另外，本文用模糊集理论对时间序列数据挖掘过程中的不确定性进行了处理，提出了一种模糊时序数据挖掘的框架。本文的主要研究内容及成果如下：1．基于状态空间重构技术提出了面向单一时序状态演化模式挖掘(SEPM)的框架。给出了有关的一系列概念，并对挖掘过程进行了详细研究，然后，将SEPM推广到多维时序。2．提出了模糊模式有效支持度的概念，对其阈值的选取给出了有关的定理；基于有效支持度对模糊关联规则挖掘算法进行了改进；研究了SEPM中的不确定性，提出了模糊状态演化模式挖掘(FSEPM)，并对实现过程进行了详细研究，接下来引入有效支持度的概念对FSEPM进行了优化。3．通过实验分析，验证了FSEPM算法的有效性；分析了算法的关键参数对算法性能的影响。通过对FSEPM和SEPM进行对比试验，验证了FSEPM的优越性。
[33]刘君强.海量数据挖掘技术研究[D].导师：潘云鹤.浙江大学,2003.
关键词:知识发现,数据挖掘,关联规则,分类规则,多维多层多数据类型关联规则,频繁模式,闭合频繁模式,最大频繁模式,黑板系统,分布式问题求解,智能代理,移动型智能代理,协同数据挖掘,分布式数据挖掘,移动式数据挖掘,智能型数据挖掘工具,算法,软件,海量数据库
摘要:随着信息技术特别是网络技术飞速发展，人们收集、存贮、传输数据能力小断提高。数据出现了爆炸性增长，与此形成鲜明对比的是，对决策有价值的知识却非常匮乏。知识发现与数据挖掘技术正是在这一背景下诞生的一门新学科。数据挖掘要在实际应用中发挥作用，高性能挖掘算法和数据挖掘软件平台是重要的技术基础。本文以数据挖掘最基本问题，频繁模式与关联规则挖掘为切入点，研究高时间效率、高空间可伸缩性的挖掘算法和分布、异质、海量数据的协同挖掘软件模型。本文首先发现了基于树表示形式的虚拟投影方法，用于按深度优先挖掘密集型数据集；提出了稀疏型数据集表示形式及非过滤投影方法；进一步提出了基于伺机投影的思想，设计并实现了基于伺机投影的全新算法OpportuneProject，对比实验表明该算法挖掘各种规模与特性数据库的效率与可伸缩性都是最佳的。由于其内在的计算复杂性，挖掘密集型数据的频繁模式完全集非常困难，解决办法是挖掘频繁模式的闭合集或最大集。本文提出了一种组织闭合模式集的复合型频繁模式树，支持搜索空间的高效剪裁，有效地平衡了树生成与树剪裁的代价，实现了闭合模式集挖掘算法CROP，其效率与可伸缩性大大优于CHARM等算法。在此基础上，本文提出了闭合性剪裁和一般性剪裁相结合，并能适时前窥的最大模式挖掘算法MOP，大大优于MaxMiner和MAFIA等算法。本文进一步提出了根据信息熵自动生成与人机交互相结合来确定数值型与类别型属性概念层次的新方法，不仅支持逐层挖掘而且能进行跨层挖掘，并实现了多支持率剪裁，将所提出的挖掘频繁模式完全集、闭合集的新算法推广到无冗余关联规则、多维多层多数据类型关联规则、多支持率分类规则的挖掘问题。本文在所取得的数据挖掘算法研究成果基础上，对数据挖掘软件模型作了深入研究。首先提出了数据挖掘作业描述语言MDL和挖掘任务模型脚本语言，设计并实现了一个集成数据仓库管理功能、挖掘引擎具有一定智能、体系结构可扩展的数据挖掘工具，并已经集成到一个大型商业连锁企业的经营决策系统中。本文在研究分布式问题求解技术和分析移动型智能代理技术的基础上，提出了从网络海量数据中发现有用知识的协同挖掘模型。首先定义了黑板和知识源的描述语言以及知识交换格式，设计和实现了支持互联网上分布式问题求解的黑饭系统，提出了分布式网络海量数据挖掘系统DistributedMiner。接着在分析移动式智能代理技术的基础上，设计了一种移动式智能代理服务器，通过重构基础结构提出了移动式网络海量数据挖掘系统模型MobifeMiner。
[34]秦昆.基于形式概念分析的图像数据挖掘研究[D].导师：关泽群;李德仁;王新洲.武汉大学,2004.
关键词:图像(遥感图像)数据挖掘与知识发现,形式概念分析理论(概念格理论),商空间理论,关联规则,聚类,分类,知识库,基于知识的分类,基于知识的图像检索,基于知识的日标识别,图像数据挖掘软件原型,RSImageMiner
摘要:随着图像数据获取设备和获取手段的迅速发展，我们获取了海量的图像数据，如何充分地利用这些图像数据，从图像数据中挖掘出隐含的、潜在的规律性的知识，是目前迫切需要解决的问题。本文对图像(遥感图像)数据挖掘与知识发现这一新的概念的内涵和外延进行了系统地深入地分析和研究，将这一概念解释为“利用空间数据挖掘的理论和方法(空间聚类分析、空间关联规则分析、空间序列分析等)从图像库(或多幅图像、一幅图像的多个分块)中提取出规律性的潜在的有用的信息、图像数据关系、空间模式等，自动抽取出具有语义意义的信息(知识)，从而为图像的智能化处理服务的过程”，强调这个概念是一个动态的概念，是一个过程，其目的是为图像的智能化处理服务，可以对人量的图像数据库进行挖掘，也可以只对一幅图像进行挖掘，它是在其它相关技术的基础上发展起来的，由于还处于初期阶段，与这些相关技术之间的区别有时候可能还不是很明显。本文认为图像数据挖掘是一个具有自己的独特的研究内容的、具有自己的理论和技术框架的一门新的理论和技术。本文对这一概念与其它相关概念之间的关系进行了分析和对比，对图像数据挖掘的研究内容和研究体系进行了界定。本文对形式概念分析(概念格)理论进行了系统地深入地分析，形式概念分析理论也称作概念格理论，是用数学的形式化的方法对人从数据中产生概念的过程进行分析的有力工具，这与数据挖掘是从大量数据中产生知识的过程是一致的，冈此，形式概念分析理论非常适合于进行数据挖掘的研究。本文对基于形式概念分析理论的数据挖掘的原理和算法进行了研究，将关联规则、分类规则、聚类规则统一成“A(?)B”的形式，从而建立了集关联规则挖掘、分类规则挖掘和聚类规则挖掘为一体的统一的数据挖掘的框架。本文重点对关联规则挖掘的算法进行了深入的研究，并研究出两种集概念格的构建和Hasse图的绘制为一体的关联规则挖掘的快速算法。其中，第二种算法建立了辞典序索引树，并根据概念格节点的内涵基数实现分层存放，经过实验验证，证明这两种算法都优于经典的关联规则挖掘算法Apriori算法，并且第二种算法比第一种算法更加快速有效。我们对现实世界的认识是在不同的层次、不同的粒度世界里进行的，对于图像数据挖掘来说也是如此，这就涉及到一个图像数据挖掘的粒度问题。本文通过对商空间理论的分析与研究，利用商空间理论提供的形式化语言来描述图像数据挖掘的不同的粒度世界，将商空间理论与形式概念分析理论相结合，对图像数据挖掘与知识发现的机理进行了研究，从理论上提出了一个概念驱动的图像数据挖掘与知识发现的理论框架，即通过商空间理论建立图像数据挖掘的形式化分析体系，在该形式化分析体系的指导下，利用基于形式概念分析理论的数据挖掘算法，从不同粒度的图像世界中提取出不同层次的概念，分析概念之间的包含与被包含关系，从而挖掘出图像数据中隐含的潜在有用的规律性的知识。图像数据挖掘与知识发现是一个非常复杂的过程，当我们面对一堆纷繁复杂的图像数据时，可以利用商空间的分层递阶的处理方法，首先将这个复杂的问题进行分解，根据区域、层次、图像内容等将图像数据挖掘划分成各个子问题，从不同的粒度分别进行图像数据挖掘，然后再将这些不同粒度的图像数据挖掘的结果进行集成。根据图像数据的位置，可以将图像数据划分为不同的区域，对这些不同的区域的图像数据分别进行挖掘;根据图像数据的层次，将图像数据挖掘划分为像素层次的微观粒度的挖掘、像素集团层次的中观粒度的挖掘、对象层次的宏观粒度的挖掘以及基于对像及其相关的领域信息的宏观粒度的挖掘。根据图像的内容，可以分别进行光谱(颜色)特征知识挖掘、纹理特征知识挖掘、形状特征知识挖掘、空间关系特征知识挖掘等。在进行图像数据挖掘的过程中，以提取各个层次的概念以及概念之间的关系为主要目的，从而挖掘出相关的关联知识。这样，将商空间理论与形式概念分析理论相结合，建立概念驱动的基于商空间理论和概念格理论的统一的图像数据挖掘的框架。本文重点对光谱(颜色)特征知识挖掘、纹理特征知识挖掘、空间关系特征知识挖掘等进行了实验研究，从图像数据中挖掘出了大量的光谱特征知识、纹理特征知识以及空间分布规律知识等。本文选取了大量的航空纹理样本图像，进行了基于纹理特征知识的纹理图像分类的实验，并且与基于灰度共生矩阵、基于马尔柯夫随机场的纹理分类方法进行了对比实验，实验结果证明本文所研究的集于图像数据挖掘的纹理分类方法的分类精度比另外两种纹理分类方法的分类精度更高。利用图像数据挖掘的方法可以从图像数据中挖掘出大量的图像知识，本文对图像知识的存储与管理以及基于知识的应用等问题进行了研究。本文提出了利用关系数据库以及文本文件的方式实现图像知识的统一存储和管理的方法，建立了一个图像知识库系统，实现了图像知识的有效存储和添加、删除、查询等功能。图像数据挖掘的主要目的之一就是为图像的智能化处理服务，针对图像的智能化处理的目的，本文对图像数据挖掘的应用:基于知识的图像分类?
[35]崔广才.基于粗糙集的数据挖掘方法研究[D].导师：刘大有.吉林大学,2004.
关键词:数据挖掘,粗糙集,约简,增量式,遗传算法,特征矩阵
摘要:近年来，数据挖掘引起了信息产业界的极大关注，其主要原因是存在大量可供使用的数据，并且迫切需要将这些数据转换成有用的信息和知识。粗糙集理论对于人工智能和认知科学是十分重要的，从它一提出来就受到到模糊数学创始人 Zadeh 的重视和高度评价，并将其列入他新提倡的软计算的基础理论之一。将粗糙集应用于数据挖掘领域，能提高对大型数据库中的不完整数据进行分析和学习的能力，具有广泛的应用前景和实用价值。属性约简是粗糙集理论中的一个重要课题。由于大型数据库中常常包含许多对发现规则来讲是冗余的、不必要的属性，研究人员发现，如果能将冗余属性删除，将会大大提高系统潜在知识的清晰度，降低发现规则的时间复杂性，提高发现效率。对于大型数据库中的海量数据，更需要的是增量地更新数据挖掘结果，而不是从每次更新的数据库重新进行挖掘。这种算法渐增地进<WP=121>行知识更新，修正和加强先前业已发现的知识。增量算法是提高学习效率的一个重要算法之一。在数据挖掘中使用增量算法，不仅复杂度较小，而且可以通过增加实例修正已有的规则集。为解决上述问题，本文研究了一些基于粗糙集和遗传算法的数据挖掘方法，主要工作包括：1．研究了数据挖掘的原理和现状，当前的数据挖掘方法已综合了数据库、人工智能、统计学、模式识别、机器学习、数据分析等众多领域的研究成果。本文从数据挖掘和知识分类的角度出发，探讨了数据挖掘的相关概念、工作步骤和关键技术。数据挖掘（DM）是指从大量的原始数据中发现隐含的、未知的、有用的知识的非平凡过程。简单的说，就是从数据到知识的过程。在数据挖掘系统中数据库被分为两部分，一部分是训练集，一部分是测试集。通过使用训练集，进行一个学习过程且获得相应的知识模式。工作步骤主要包括：数据准备、实际的挖掘、规则表述。在此基础上将数据挖掘和知识发现、在线分析等进行了比较，指出数据挖掘是从存放在数据库、数据仓库或其他信息库中的大量数据中挖掘有趣知识的过程。从数据分析的角度来看，OLAP位于较浅的层次，而DM则处于较深的位置。数据挖掘方法主要有：决策树、神经网络、模糊论、遗传算法、贝叶斯网络和粗糙集等方法。通过总结数据挖掘的方法，得出数据挖掘系统的模型。2．深入分析了粗糙集的基本理论、属性约简的基本方法与算法、遗传算法的基本理论。粗糙集理论是一种新的处理模糊和不确定性知识的数学工具。其主要思想就是在保持分类能力不变的前提下，通过知识约简导出问题的决策或分类规则。粗糙集的核心问题是知识的约简和获取，这离不开一系列的算法作支撑，包括求等价关系、求上下近似、判断属性的重要性、求核、属性约简等，其中属性约简是粗糙集用于数据分析的主要手段。约简算法的设计和实现是粗糙集研究的<WP=122>重要内容之一。讨论了知识约简与知识依赖关系，知识表达系统和决策表的关系，探讨和比较了多种属性约简方法的实现原理，给出了各方法的优缺点。求所有约简属性集的问题实质是一个属性组合情况的搜索问题，用一些启发式规则对搜索算法进行引导，将大大降低算法的复杂度。基于属性重要性和频度的启发式约简算法需要计算决策表的核，而当决策表的属性较多时，决策表可能没有核，从而使该算法失去较好的起点。此外由于引入了用户偏好集，使算法执行前可人为指定某些人主观认为比较重要的属性加入约简，使得算法具有较高的准确性和较强的伸缩性。可是用这种方法得出的约简往往包含很多属性，使得所得到的规则前提条件很长。由于引入用户偏好集，算法最后所得的约简可能还有多余属性，并不符合约简的定义。深入研究了遗传算法实现的共性问题，并给出了各类算子的设计和实现方法。本文提出对选择算子的改进，在执行选择算子时，首先对种群个体进行分类，每类中的个体是相同的，然后对每类个体都计算适应值，若有多类个体的适应值同时为最大，则对适应值最大的几个类的个体数目进行修正，使这几类个体在种群中的数目大致相等，然后再用旋转盘算法对种群中的个体进行选择。3．研究了把信息论应用于决策信息系统属性约简的方法，并与遗传算法相结合，改善了原属性约简算法的性能。属性重要性反映了把某一属性加入到核时互信息的增量,本文将从信息论角度定义的属性重要性度量作为启发信息引入遗传算法，从而得到一种用于求解最小约简的启发式遗传算法。遗传算法中修正算子用来对种群进行修复，保证所有个体都是侯选约简，使搜索总在可行解空间上进行。并在保证侯选约简的条件下，尽可能增加个体适应值。用基于信息熵属性重要性度量和基于粗糙集的属性依赖度的加权平均和作为约简算法中的修正操作依据，由于增加了一个修正算子，使所有经过修正的个体都<WP=123>是候选约简，这使得遗传操作作用在可行候选解空间上，节省了计算资源，有效地加快了算法收敛速度。该算法在选择算子中增加了一步操作，当下一代中最差个体比上一代最好个体适应性差时，用上一代最好个体替换下一代最差个体，并适当地调整优良个体的比例，保证了种群的多样性。改进算法结束条件，使之由群体稳定性来决定，保证了遗?
[36]刘刚.数据挖掘技术与分类算法研究[D].导师：郭金庚.中国人民解放军信息工程大学,2004.
关键词:数据挖掘,知识发现,分类算法,知识模型
摘要:数据挖掘(Data Mining)是致力于数据分析和理解,揭示数据内部蕴藏知识的技术。它是未来信息技术应用的重要目标之一。经过数据挖掘领域研究工作者十几年的努力,出现了许多数据挖掘的新概念、新方法,特别是最近几年,一些基本概念和方法趋于清晰,数据挖掘的研究正向着更加深入的方向发展。像其它新技术的发展历程一样,数据挖掘技术也要经过概念提出、概念接受、广泛研究和探索、逐步应用和大量应用等阶段。从目前的现状看,大部分学者认为数据挖掘的研究仍然处于广泛研究和探索阶段,迫切需要在基础理论、应用模式、系统构架以及挖掘算法和挖掘语言等方面进行创新。分类作为数据挖掘的一个重要研究课题,在统计学、机器学习、神经网络和专家系统中得到了较早的研究,但其中大部分都是内存驻留算法,通常假定数据量很小。随着数据库中数据量和维数越来越大,建立高效的、适用于大量数据集的分类算法已成为数据挖掘面临的一个挑战性问题。近年来,数据挖掘界提出一种新的知识模式,称作跳跃显露模式(JEP:Jumping Emerging Pattern),用来表示两个数据集之间的重大差异,并出现了一些基于JEP的分类算法。研究表明,这些基于JEP的分类算法具有很好的预测准确性,而且数据量和维数都是可规模化的。但是,这些基于JEP的分类法通常需要挖掘大量的JEP,因此影响了它们的效率,且增加了分类算法的复杂性。本文提出一种特殊类型的JEP,称作最有效的跳跃显露模式(SJEP:most Significant Jumping Emerging Patterns)。分析结果表明,SJEP具有很强的区分能力,足以用来建立精确的分类算法。由于已有的算法都不能直接挖掘这种SJEP,本文给出了一种可以在两个数据集上双向挖掘SJEP的有效算法,并讨论了如何建立基于SJEP的分类算法(SJEP_Classifier)。与已有的基于JEP的分类算法相比,基于SJEP的分类算法不仅使用的JEP数量少,预测精度高,而且可以在很短的时间内(通常为若干秒)完成学习阶段。实验结果表明,本文的分类算法(SJEP_Classifier)在平均预测精度方面也优于CBA和C4.5等分类算法。总之,本文在分析、归类现有数据挖掘研究成果以及原型系统的基础上,进行了数据挖掘应用系统体系结构和基于SJEP的分类理论模型以及算法方面的研究,所设计的算法在挖掘效率和对大型数据库挖掘的可用性方面具有潜在的应用前景。
[37]李玉华.面向服务的数据挖掘关键技术研究[D].导师：卢正鼎.华中科技大学,2006.
关键词:数据挖掘,面向服务的体系结构,本体,语义数据集成,隐私保护,质量评价,服务选择
摘要:解决大规模分布异构数据挖掘问题,需要一种便于资源集成、提供高质量数据挖掘服务,并具有较高安全性和隐私保护性的框架模型。面向服务的体系结构(Service Oriented Architecture,SOA)、本体、WEB服务等新技术将为数据挖掘系统的开发提供更强大的技术支持。根据分布异构环境下数据挖掘的特点,综合利用SOA、本体、WEB服务等新技术,遵循以用户为中心的理念,提出了一种开放式的面向服务的数据挖掘系统框架――SODMA。该框架将数据挖掘的算法封装成WEB服务,利用异构数据集成本体和隐私保护策略本体实现应用域的隐私保护语义数据集成,利用以用户为中心的数据挖掘本体和数据挖掘服务质量评价本体帮助用户动态选择适用且高质量的数据挖掘服务(DMS),可在分布环境下为不同领域多层次用户提供高可用性、高性能、高质量、安全的数据挖掘服务。对于分布异构的数据挖掘,异构数据集成是数据预处理很关键的第一步。数据集成的模型需要有效的解决数据异构性、完整性、权限控制、集成范围限定等问题。在分析现有的数据仓库方式、中间件集成、基于本体的数据集成方法优缺点的基础上,借鉴已有的语义数据集成和隐私保护数据挖掘的研究成果,提出了一个基于智能体和本体的隐私保护语义数据集成模型,以解决应用域隐私保护数据挖掘数据预处理的问题。定义了隐私保护数据挖掘本体,数据集成采用全局视图(GAV)和局部视图(LAV)相结合的混合本体集成方法,隐私保护策略集成采用单本体的方法,同时利用模式模糊化和角色模糊化,以提高模型的隐私保护性。数据挖掘服务是涉及数据、计算、挖掘知识的复杂服务应用,用户需要具备非常全面的专业知识才能正确使用。现有的以系统为中心的设计中,数据挖掘解决方案特别重视算法和系统工程,而没有首先探讨最终用户将如何方便地使用新的数据挖掘技术,使系统难于操作和使用。有的系统利用数据挖掘本体和预测执行时间的方法来帮助用户选择正确并且高质量的数据挖掘服务,但是数据挖掘本体只是对数据挖掘的方法进行枚举,无法保证服务的质量。在分析和总结了前人对于数据挖掘技术和系统研究成果的基础上,结合数据挖掘应用的领域知识,遵循以用户为中心的设计理念,提出了以用户为中心的数据挖掘本体,一方面根据数据挖掘功能和挖掘对象来组织数据挖掘算法,另一方面根据应用领域知识为用户提供有效的数据挖掘应用解决方案,帮助不同领域多层次用户方便选择数据挖掘服务。此外还进一步讨论了基于本体描述语言(OWL)的数据挖掘本体实现。具体的数据挖掘算法和域应用解决方案是数据挖掘本体的实例,是用户应用的核心。研究了反洗钱领域数据挖掘应用解决方案实例,包括应用域的层次,若干基本的数据挖掘算法,数据挖掘应用解决方案和所用算法间的映射等。主要实现可疑交易甄别、交易网络分析和洗钱模式发现等数据挖掘应用,给出了可视化链接分析方法,可实现交互式可视化的交易网络分析,提出了基于图熵的链接发现算法,可有效地发现交易网络的关键节点,给出改进的基于Apriori的SLAGM频繁子图发现算法,用于交易网络的结构分析。用户可利用域数据集成本体提供的语义模型,在数据挖掘本体的指导下选择数据挖掘算法和应用解决方案以定义具体的数据挖掘任务。在用户需求获取完成以后,接下来就是要根据用户需求选择合适的数据挖掘服务执行,而大多数最终用户并不具备这样的专业知识。从方便用户的角度出发,系统需提供一套服务选择机制,来帮助用户选择高质量的数据挖掘服务。系统综合通用WEB服务的评价标准、数据挖掘领域的专用评价因子及用户评价反馈等多种因素及服务的动态性,给出了一个较全面的数据挖掘服务评价本体,讨论了服务质量的评价方法,给出了基于服务质量评价的动态数据挖掘服务选择方法,用户可根据数据挖掘服务评价本体的语义模型,输入质量约束条件,也可以调整评价因子权值,系统在满足用户约束条件的服务集中,通过计算出服务的综合质量值,挑选最适合的算法执行。基于上述成果,实现了一个外汇反洗钱领域的隐私保护数据集成和数据挖掘服务选择的原型系统,并总结了系统设计特点。
[38]王志勇.数据挖掘方法在短期负荷预测中的应用研究[D].导师：曹一家;郭创新.浙江大学,2007.
关键词:数据挖掘,短期电力负荷预测,灰色理论,模糊粗糙集,互信息理论,范例推理,人工神经网络,多Agent
摘要:短期负荷预测是各级电力系统调度、运营部门的一项重要工作，它关系到确定燃料的供应计划、运行中电厂出力要求的制订、经济性安排机组起停以及合理安排机组检修计划等方面。随着电力市场的逐步发展、完善，短期负荷预测对于提高电力系统经济性将起到越来越重要的作用。随着电力信息化水平的不断提高，大量的负荷及其相关数据被储存在电力系统数据库中，如何合理、有效的利用这些数据，并从中获取对于指导负荷预测工作有用的“知识”是当前面临的一个重要问题。而数据挖掘方法可以从大量的数据中挖掘出隐含的、先前未知的、对决策有潜在价值的知识和规则，并将提取的知识表示为概念、规则、规律、模式等形式，这些知识蕴涵了数据集中的数据对象之间的特定联系，揭示出一些有用的信息。本文综合利用多种数据挖掘方法对电力负荷相关数据进行分析，利用得到的信息为负荷预测建模提供更为合理的依据，使建模过程尽量减少人为的主观影响，解决建模过程中的难点问题，从而提高负荷预测的准确性。论文首先介绍了负荷预测的基本概念及研究发展现状，然后对数据挖掘的基本定义以及常用方法进行了介绍，并对其在电力系统负荷预测中的应用情况进行了综述。本文的主要研究成果可分为五部分：第二章提出了基于灰色理论的电力系统异常负荷数据辨识与修正方法。首先将传统灰色预测模型进行了改进，然后分别使用前向灰色插值法和后向灰色插值法对缺失点负荷进行预测，最后使用两种预测的最优组合来确定最终的填补值；在填补负荷缺失点的同时，针对负荷序列中的异常值使用灰色插值方法进行了辨识及修正。第三章中提出了基于数据挖掘方法的负荷预测神经网络结构的确定。如何合理地确定神经网络的输入变量，并且避免出现过多的输入造成“维数灾”是基于神经网络的负荷预测方法一直没有妥善解决的问题。本章中提出使用模糊粗糙集方法来有效克服传统粗糙集方法的不足进行神经网络输入变量选取；还提出当缺少领域知识的情况下，使用互信息理论来进行神经网络输入参数的合理、有效的选取，经实例验证和比较，表明本章提出的基于模糊粗糙集和互信息理论的属性约简算法是有效可行的。第四章针对短期负荷预测具有明显周期性的特点，提出了一个改进范例推理系统来进行短期负荷预测。该系统将范例推理、自组织映射以及互信息理论进行了有效的结合。首先使用互信息方法确定了范例的表示、组织方法以及各个范例属性的匹配权重；然后通过选取适当的聚类数目将历史范例进行聚类，在进行范例匹配时进行两次匹配：首先将新问题所对应的范例与各个聚类中心进行匹配，得到最相似聚类，然后再在该聚类中进行二次匹配，最后将得到的最相似范例集进行重用、修正，得到最终预测结果。第五章提出了一种负荷模式识别、分类方法。针对获取的客户用电数据，在经过一定的预处理后使用多种聚类分析方法进行分析，通过选取最合适的聚类方法以及聚类数目得到工作日及周末的典型负荷代表曲线。然后利用聚类所得到的知识，选择合适的推理方法获取分类规则，从而为将未知类型单位划分给某特征曲线类提供了有效的工具，得到的分类规则也有较高的正确率。第六章中提出了一个基于多Agent的变电站负荷预测模型，首先将变电站负荷进行聚类辨识、分类，然后对每一个类别分别进行预测，最终将预测结果进行累加，得到该变电站负荷总量。可以将方法进行推广，对区域内各变电站均用此方法进行合成预测，考虑到各区域中负荷模式类别和所占比重均有所不同，而且不同区域内的天气状况也有所区别，本章中首次提出采用多Agent来对预测系统进行了建构。
[39]王亚琴.道路交通流数据挖掘研究[D].导师：朱扬勇.复旦大学,2007.
关键词:数据挖掘,智能交通系统,交通流,交通状态识别,交通流量预测,空间聚类,skyline连续查询,数据挖掘系统
摘要:研究交通流的各种形态及其运行规律,建立快速、稳定、高效的交通流模型是智能交通系统的重要研究内容。随着智能交通系统的发展,智能交通系统中积累了海量交通流数据,于是研究者开始研究利用先进的数据挖掘技术分析智能交通系统中的交通流信息,发现交通流信息中隐含的交通模式及规则。本文针对交通流信息的特点以及智能交通系统的新的数据挖掘应用需求,对交通流数据预处理、交通流量预测、交通状态识别、交通流空间聚类以及实时交通流的查询等若干问题进行了研究,设计了适合的数据挖掘模型和算法。这些问题的研究对于智能交通系统的交通信号管理与控制、交通流诱导、动态交通分配等方面有着重要的意义。本文的主要研究内容和成果包括以下几个方面:(1)智能交通系统是一个非常庞大的系统,其复杂性和稳定性使交通流数据的采集质量难以保证,对交通流数据进行异常检测及预处理对于后续的数据分析、挖掘结果的质量和预测的准确性具有重要意义。本文根据交通领域的流量—时间占有率的倒“V”字型曲线模型,提出了一种基于曲线拟合的交通流异常检测方法,利用三次多项式的最小二乘法拟合流量/时间占有率曲线,并且利用分箱的思想对拟合好曲线上下部分分别采用基于统计的方法划分上下界,有效的识别异常交通流数据。(2)道路网络上运行的交通流具有不同的空间分布模式,如城市主干道的交通流具有“线”性模式、繁华路段的交通流具有“面”状模式等,根据交通流运行的空间分布特性,对城市道路交通网络进行实时、动态的交通区域划分是当前智能交通系统的研究热点之一。利用聚类分析方法对分布在道路网络空间中的环形感应线圈检测器检测的交通流数据进行空间聚类(Spatial Clustering)分析,使具有相似性质且具有空间关联性的交通流数据对象聚成一类,可以发现道路交通流的空间分布模式。本文基于凝聚的层次聚类算法思想,设计了一个高效的交通流空间聚类算法ESCA-TF(Efficient Spatial Clustering Algorithm ofTraffic Flow),自底向上的生成道路交通流的空间聚集类。ESCA-TF无需执行复杂的空间连接和空间合并操作,实验证明具有良好的时间效率。(3)对道路交通流状态进行分析研究,及时、准确地识别和预测道路交通流的状态是智能交通系统实现动态交通管理的重要前提。交通流状态的识别和预测包括交通流量短时预测和交通状态的实时识别。对于路口短时交通流量预测,本文提出了基于二次聚类的交通流量序列分割和BP神经网络的组合模型的路口短时交通流量预测方法,实验证明基于二次聚类和BP神经网络组成的组合模型提高了神经网络模型的预测精度;对于道路交通状态的实时识别,本文提出了基于聚类分析的交通状态动态识别模型,基于该模型我们不需任何先验知识就可以识别道路交通状态,且具有较高的拥挤判别率和较快的判别反应时间。(4)随着微电子技术、无线通信、移动定位技术的发展,在智能交通系统中,许多具有普适计算功能的移动装置(如PDAs、cellphone及各种GPS装置)可以跟踪人或车的实际位置,获取和传输与用户位置相关的各种有用信息,因此对于道路网络上的移动交通流提供基于位置(Location-Based Services,LBS)的服务也是当前交通信息化和智能交通系统的一个研究方向。Skyline查询提供了一种重要的基于位置服务的功能,本文设计了道路网络上移动对象的skyline连续查询算法。算法分为两个部分:独立查询点的Skyline查询算法RNASQ(Absolute Skyline Query)和Skyline连续查询算法RNCSQ(Continuous SkylineQuery)。RNASQ算法无需计算所有对象到查询点的网络距离,具有较好的时间效率。在RNASQ算法的基础上,本文提出了道路网络的上Skyline连续查询算法RNCSQ。在RNCSQ算法中,Skyline连续查询转化为对查询路径的顶点和查询对象与查询点距离的交叉点的有限个独立查询,可以快速地判断连续分段的分割点,有效地计算Skyline连续查询的连续分段。(5)建立统一、开放、可扩展的智能交通系统数据挖掘平台是交通流数据挖掘研究的重要内容。本文提出了一个四层的ITS数据挖掘平台体系结构,主要划分为:数据层、数据挖掘算法工具层、分析逻辑层和应用系统层。这种层次的系统应用平台模式便于数据挖掘算法、分析功能的设立,方便数据挖掘系统的开发与配置,可以使用户轻松地根据实际应用的需要使用数据挖掘技术,基于此结构的数据挖掘系统具有良好的可扩展性及与实体的独立性,便于二次开发。在可扩展的智能交通系统数据挖掘应用平台体系架构的基础上,本文设计实现了一个基于SOA技术的智能数据挖掘平台UTDD(Urban TrafficData-Mining Development),实现了本文提出的交通流数据挖掘方法。
[40]孙友强.时间序列数据挖掘中的维数约简与预测方法研究[D].导师：王儒敬.中国科学技术大学,2014.
关键词:时间序列,数据挖掘,维数约简,特征提取,因果关系,特征表示,趋势距离,预测
摘要:时间序列数据是一种常见的数据形式,广泛存在于各种现实应用中。相应地,利用数据挖掘技术从时间序列中发现其中蕴含的信息和知识也成为了研究的热点,其研究成果在金融、工业、农业、医药、气象、交通、计算机网络等领域取得了成功的应用。然而不同于传统静态数据,时间序列数据通常具有时序性、数量大、维数高、特征多等特性。因此,研究如何有效地通过时间序列数据挖掘技术来处理和分析时间序列数据具有重要的意义。本文以时间序列数据为研究对象,针对时间序列的高维特性,主要研究时间序列的维数约简技术,包括特征提取方法与特征表示方法。从时间序列的应用角度出发,主要研究时间序列的预测方法,包括单变量时间序列的预测与多变量时间序列的预测。时间序列的特征提取是通过选择数量较少且反映原序列主要信息的特征子集实现维数约简的技术。针对时间序列的时序特性,本文提出了一种基于因果关系挖掘的多变量时间序列特征提取方法。该方法是一个二维的特征提取,即不仅提取出特征变量,也提取特征变量的有效滞后期。同时,利用Granger因果关系挖掘的因变量及滞后期所组成的特征子集对结果也有较好的因果解释性。时间序列的特征表示是将高维的时间序列数据转换为低维表示并尽可能保留原始时间序列的特征信息。针对传统符号表示方法中只根据均值特征描述原始时间序列可能造成信息丢失的不足,本文提出了基于趋势距离的时间序列符号聚集近似表示方法,并构造了满足距离下界性的距离度量。首先提出了基于序列段起点值和终点值的趋势距离度量方法来量化不同趋势的差异,然后把趋势因素集成到原符号聚合近似表示方法中,实现利用均值特征和趋势特征共同表示原始时间序列。单变量时间序列预测是利用时间序列自身的历史值来预测未来的数据。针对传统的基于自回归滑动平均模型的预测模型建立后不能更新最新时间序列信息的不足,本文通过将自回归滑动平均模型的差分方程形式与传递形式结合,构建了一种预测值实时自修正的预测模型。新的预测模型会包含新的观测值的影响,从而提高预测的精度并减少运算量。多变量时间序列预测是利用多个变量时间序列对目标时间序列进行预测。本文的预测方法首先利用基于因果关系挖掘的特征提取方法对多变量时间序列进行特征选择,然后使用支持向量回归对目标序列进行预测。特征提取过程中剔除冗余变量和无关变量,从而达到降低支持向量回归的输入维数并提升预测准确率的效果。
[41]时雷.基于物联网的小麦生长环境数据采集与数据挖掘技术研究[D].导师：马新明.河南农业大学,2013.
关键词:小麦,生长环境,异常检测,数据挖掘,物联网,分类,聚类
摘要:小麦是我国三大重要粮食作物之一。在小麦的生产过程中，光照、温度、土壤、水分等各种环境因素都会对其生长产生影响。如何实现对小麦生长环境数据的快速采集，如何对小麦生长环境中出现的异常情况进行自动检测，已经成为了确保小麦安全稳定生产的重要问题。物联网的发展为改变传统的作物生长环境数据采集方式提供了契机。借助物联网中的无线传感器网络等技术可以实现小麦生长环境数据的快速采集、即时传输和动态显示。随着基于物联网的小麦生长环境数据采集应用的实施，积累了大量与小麦生长过程息息相关的环境数据。这些海量数据虽然真实地记录了小麦生长环境的状况，但是也为使用者从中发现异常情况等有用信息带来了巨大的困难。数据挖掘是从大量的、有噪声的数据中挖掘出潜在的有用信息或知识的过程，正是解决这一问题的有效技术。因此，针对小麦生长环境监测中数据实时采集和异常检测的应用需求，本文基于物联网技术和数据挖掘技术，对小麦生长环境监测中的数据采集和数据异常挖掘这两个关键的课题进行了研究和探索。主要的工作如下：（1）针对小麦生长环境数据采集所存在的成本高和实效差等实际问题，采用ZigBee技术实现了基于物联网的小麦生长环境数据采集系统。系统采用基于ZigBee标准的无线传感器网络对空气温度、空气湿度、土壤温度、土壤湿度、风速、风向、降雨量、光辐射等各项小麦生长环境数据进行大范围的采集；利用部署在网络主节点上的基于ARM和Linux的嵌入式系统对采集的数据进行打包及AD转换，重点实现断点续传功能，并通过3G路由器发送到Web服务器；使用位于Web服务器上的信息管理系统对数据进行接收，同时实现了对数据进行查询和下载等功能。系统的设计和实现充分考虑了小麦生长环境数据采集的实际情况，具有良好的应用效果。（2）针对小麦生长环境数据异常挖掘的复杂应用背景和制约因素，提出了一种基于粗糙集和决策树集成的混合分类算法。混合算法将粗糙集作为一个预处理器在不损失有用信息的前提下有效地减少冗余属性，然后使用自助法重采样技术生成一组决策树来构建集成分类器，从而提高对小麦生长环境数据进行异常挖掘的精度。为了验证算法的有效性，在小麦生长环境数据上对不同的分类方法进行了实验评价。实验结果表明所提出的混合算法取得了有效的性能改进。（3）针对数据挖掘中传统的聚类技术无法满足小麦生长环境数据异常挖掘需求的问题，提出了一种基于COD和STORM的聚类集成算法，用于小麦生长环境中海量且动态更新的数据流类型数据的异常检测，实现对小麦生长过程调控的异常预警。基于所提出的聚类集成算法设计和开发了一个小麦生长环境异常检测的原型系统，最后通过实验验证了所提出的聚类集成算法的有效性。主要的创新点如下：（1）基于物联网技术设计了小麦生长环境数据采集系统，取得了良好的使用效果。（2）提出了一种基于粗糙集和决策树集成的混合分类算法，实验结果表明所提出的算法取得了有效的性能改进。3）提出了一种基于COD和STORM的聚类集成算法，设计并实现了一个小麦生长环境异常检测的原型系统，通过实验验证了它们的实际应用价值。
[42]李海林.时间序列数据挖掘中的特征表示与相似性度量方法研究[D].导师：郭崇慧.大连理工大学,2012.
关键词:时间序列,数据挖掘,特征表示,相似性度量,距离度量
摘要:随着社会经济和信息技术的发展,时间序列的数据量增长越来越快。相应地,利用数据挖掘技术在时间序列数据库中发现潜在的有价值的信息和知识也越来越倍受关注,其研究成果已被成功地运用于经济、金融、电子信息、医疗卫生、教育、工业和工程等领域中。然而,时间序列特征表示和相似性度量是时间序列数据挖掘任务中最为基础和关键的工作,其质量的好坏直接关系到时间序列数据挖掘的结果。时间序列数据随时间的推移而不断增长,数据的高维、动态、不确定等特性阻碍了传统数据挖掘技术性能的发挥。特征表示方法的主要目的是利用少量特征近似表示原时间序列,起到有效降维的作用,进而提高数据挖掘任务的效率。同时,相似性度量是测量时间序列之间差异性的方法,通常结合特征表示方法对时间序列之间的相似性进行快速有效地度量,其度量结果可用于分类、聚类、相似性搜索和异常模式发现等时间序列数据挖掘任务中。本文分别以等长和不等长时间序列为主要研究对象,探讨利用不同的方法对这两种类型时间序列数据进行特征表示和相似性度量,使得方法能更为完善和有效地运用于时间序列数据挖掘中,进而获取潜在有价值的信息和知识。本文的主要研究工作如下：(1)从等长时间序列的整体特征出发,提出基于正交多项式回归系数特征表示的相似性度量方法。通过分析多项式最高项次数对时间序列整体形态拟合效果的影响,选取合适的特征系数反映时间序列的主要形态趋势,提出更适合于特征序列的相似性度量方法,并且在理论上证明其满足下界性,提高它在时间序列相似性搜索中的性能。(2)针对分段聚合近似对等长时间序列进行特征表示的问题,利用多维特征对等长时间序列进行特征表示,并构造满足下界性的相似性度量方法。通过对传统分段聚合近似方法及其相似性度量方法满足下界性的剖析,利用不同维度的特征来近似表示分段序列,分别提出了基于二维统计特征和基于二维形态特征的分段聚合近似方法,提高了传统分段聚合近似方法在时间序列数据挖掘中的应用效率。同时,将分段序列的二维形态特征表示推广到更高维形态特征表示,使得较高维数的分段特征表示方法在较大数据压缩率的情况下其距离度量函数的性能有所提高。(3)以云模型理论为基础对等长时间序列实现分段特征表示,并提出了具有较高性能的相似性度量方法。利用云模型反映分段序列数据分布的不确定性,并且给出了云模型相似性度量函数,进而实现云特征序列之间的相似性度量。虽然基于云模型的时间序列相似性度量方法不能满足下界性,但它从局部和全局的角度来考虑时间序列的波动性和不确定性,具有较高的相似性度量质量,有效地提高了时间序列数据挖掘相关算法的性能。(4)针对传统动态时间弯曲方法度量不等长时间序列需要较高时间代价的问题,提出了两种改良后的弯曲度量方法。首先,在权衡计算速度和度量精度的情况下,通过自适应快速分段线性表示对时间序列进行特征表示,再结合导数动态时间弯曲方法来快速有效地对不等长时间序列进行弯曲度量,提出了基于分段线性近似和导数动态时间弯曲的时间序列相似性度量方法。其次,为解决动态时间弯曲方法带来较大计算量的问题,通过缩小最优弯曲路径的搜索范围和提前终止计算最优弯曲路径的策略,提高传统动态时间弯曲方法在时间序列相似性搜索中的计算效率。(5)时间序列特征表示和相似性度量方法在发动机数据挖掘中的应用。根据发动机性能参数时间序列数据的特性,利用新的时间序列特征表示和相似性度量方法来实现发动机性能参数的数据挖掘,进而有效地对发动机性能参数进行特征识别和故障检测,给发动机设计过程中的知识发现增加了新的视角,为管理和保障发动机的运行安全提供参考依据。以上研究成果通过数值实验检验了它们对不同类型时间序列数据进行特征表示和相似性度量的有效性,并且比较了它们在时间序列数据挖掘中提高相关算法的性能,进一步完善了时间序列数据挖掘中的特征表示和相似性度量的研究。
[43]李璠.银行数据挖掘的运用及效用研究[D].导师：黄宪.武汉大学,2012.
关键词:银行,数据治理,数据挖掘,数据效用,核心竞争力
摘要:当今信息化社会，网络经济与虚拟经济日新月异,促进金融行业的经营管理模式产生重大变革，金融市场由供给模式向需求模式转变。在市场竞争越来越充分的大趋势下，数据的商业与经济价值受到广泛关注，已演变为银行一项特殊的专用性资产，在传统资产价值理论基础上，具有其特殊性与相关性。银行数据挖掘的运用及效用研究将金融学、信息技术、管理科学有机结合，认为数据作为银行重要资源禀赋之一，是生产运营过程的产物，技术与管理发展水平的标志，经济人偏好的体现，制度约束的基础。现代银行依托于可量化分析的数据与数据模型，通过更加精细化管理创造价值，提高银行核心竞争力。本文以数据为主线，详细阐述数据在银行前台客户服务、中台风险管控和后台运营支持等各项活动中的作用，同时深入分析客户交易行为和经营管理活动中所产生数据的效用。从数据效用理论、数据治理、客户关系管理、全面风险管理、金融创新几个角度将数据作为银行重要资产所创造的价值展开研究，从而引申出数据有效性对银行各项业务的影响，及数据效用对银行价值创造的重要性。银行数据效用体现在两个方面，一是未经加工处理的原始数据量巨大，但是所蕴含的价值较小，运用技术手段和管理手段对数据进行整合、分类、清洗等加工处理后，数据就实现价值增值，对数据的进一步深入挖掘分析更是脑力劳动与人类智慧的体现，具有经济学意义上的效用；二是有效的数据在银行内部各个业务领域应用广泛，将数据效用应用到银行的各项价值增值活动后，可以显著提高银行综合管理水平与金融创新能力，最终实现银行价值的增值，为银行在未来金融市场竞争中提升核心竞争能力奠定坚实基础。本文的第一章综述银行数据挖掘、运用及效用研究的主要文献。从数据挖掘与应用理论、数据效用、信息理论、知识理论四个方面对国内外相关文献进行解读，并指出现有数据挖掘运用与效用理论研究方面的不足之处。第二章围绕银行数据效用和数据治理的有效性研究展开。在全面阐述数据内涵与外延的基础上，第二节结合银行业务发展特点论述数据效用的实现途径，通过对原始数据收集、清洗、加工、处理及整合后，实现数据的模型化，然后运用数据挖掘的分类、聚类等方法，对数据进行深入分析，提炼出有价值的信息，这些信息得以有效利用后，转化为指导银行管理经营决策的专用性知识型资产。最后知识型资产又以数据的形式保存下来，通过数据的流转发挥更大的价值。第四节研究数据治理的现状及发展趋势为数据效用的提升提供制度保障，主要强调数据治理作为公司治理的重要组成部分，其数据治理组织结构建设、数据标准化、数据质量管控，数据架构规划以及数据安全管理对提高银行经营管理水平的重要意义。并基于信息经济学理论，创新性地设计有效防止数据产生者违规道德风险发生的数据质量管控模型，避免数据生成过程中的道德风险给银行带来福利损失。第三章研究的主要内容是银行客户管理过程中数据的价值增值。银行的经营战略已经从以产品为中心向以客户为中心转变，优化客户关系管理工具与方法，挖掘数据的价值可以提升客户服务水平，为客户创造价值的同时实现银行自身的价值创造。第一节分析银行运用先进信息技术，建设客户信息管理系统的重要意义。文章详细论述数据在客户细分、客户行为分析、客户利润贡献度分析与精准营销中的价值增值。第四章数据在银行风险管理中的效用研究突出由于风险管理在银行的重要性、复杂性与技术依赖性，需要管理实践中将定性管理与定量分析有机结合，科学利用风险管理技术与信息技术对银行海量数据进行深度挖掘分析，既是监管制度的强制性要求，又是银行自身提高风险识别与计量效率，节约风险管理工作整体投入成本的必然选择。数据在银行信用风险、市场风险、操作风险管理中的有效运用，使风险管理创造的价值最大化。第五章将金融发展理论与金融创新理论结合，论述金融创新与客户关系管理、风险管理的关系，探索银行产品、服务和流程创新中的数据效用。揭示打造流程银行，金融产品创新与服务创新与提升数据效用的相关性，阐述建设企业级知识库，加强数据服务对于金融创新的重要意义。论文的主要创新点为：一是将数据作为银行的专有重要战略资源，分析其在银行利润增长、客户关系管理、风险管理、金融创新及构成竞争优势的价值贡献；二是运用信息经济学静态博弈模型，委托-代理理论设计银行内部数据治理机制与质量管控模型；三是以数据为主线将金融理论同信息技术理论有机融合，进行银行内部应用及金融创新过程中数据效用增值的研究。
[44]张喆,常桂然,黄小原.数据挖掘技术在CRM中的应用[J].中国管理科学,2003, 01:53-59.
关键词:数据挖掘,客户关系管理(CRM),知识发现,决策支持,电子商务
摘要:客户关系管理(CRM)是数据挖掘技术的重要应用领域,也正是因为具有数据挖掘技术的支持才使CRM具有越来越广泛的市场价值和研究价值。本篇论文综述了面向CRM的数据挖掘应用的总体研究情况。包括面向CRM数据挖掘的体系结构;从客户生命周期的角度和行业应用角度分析了CRM中数据挖掘的应用状况;最后结合当前数据挖掘技术的发展指出了CRM中数据挖掘应用的进一步发展趋势以及我国在该领域的研究方向。
[45]卢东标.基于决策树的数据挖掘算法研究与应用[D].导师：童恒庆.武汉理工大学,2008.
关键词:数据挖掘,决策树,ID3算法,过度拟合,加权简化熵
摘要:数据挖掘是指从数据库中抽取隐含的、具有潜在使用价值信息的过程,是一种新型的数据分析技术,已经被广泛应用于金融、保险、政府、教育、运输以及国防等领域。数据分类是数据挖掘中一个重要的内容。分类存在很多方法,常见的分类模型有决策树、神经网络、遗传算法、粗糙集、统计模型等。其中决策树算法是以实例为基础的归纳学习算法,以其易于提取显示规则、计算量相对较小、可以显示重要决策属性和较高的分类准确率等优点而得到广泛的应用。据统计,目前决策树算法是利用最广泛的数据挖掘算法之一。然而在实际的应用过程中,现存的决策树算法也存在很多不足之处,如计算效率低下、多值偏向等。因此,进一步改进决策树,提高决策树的性能,使其更加适合数据挖掘技术的应用要求具有重要的理论和现实意义。本文针对上述数据库知识发现的不足,进行深入的研究,探索数据挖掘中决策树分类的优化算法,以便更好地提高分类的准确性,更好地应用于实际工作中。本文主要的研究工作如下:第一,从宏观上介绍了数据挖掘和分类技术的理论基础,并重点对几种常见决策树算法进行了分析和比较,例如ID3、C4.5、CART算法。第二,详细地分析了利用决策树方法对数据进行分类挖掘时常见的几个问题:属性值空缺、连续属性的处理、过度拟合数据等。这些问题都会导致决策树的分类精度下降,因此在构建决策树时必须选择合理的策略,提高决策树的分类精度。第三,本文对决策树算法进行了优化研究,对属性值空缺、属性选择多值化、属性选择标准等问题提出了具体的解决办法。本文还提出了加权简化熵的概念,并对ID3算法进行了改进,经过比较,改进算法在总体性能上优于目前广泛应用的ID3算法。第四,利用新的决策树算法在一个棉纺厂的设备管理系统中进行数据挖掘,为厂家的决策支持提供了科学、准确的根据。
[46]梁循.数据挖掘:建模、算法、应用和系统[J].计算机技术与发展,2006, 01:1-4+65.
关键词:数据挖掘,算法,应用,软件系统
摘要:数据挖掘是20世纪末逐渐形成的一个多学科交叉领域,目前已经广泛成功地应用在金融、零售、医药、通讯、电子工程、航空、旅馆等有大量数据和深度分析需求的领域。文中对数据挖掘的建模、算法、应用和软件工具进行了综述,给出了数据挖掘的定义、范畴和特点,以及数据挖掘的数据集的各种实际情况;总结了数据挖掘在实际应用时的基本步骤和过程;对数据挖掘在各种应用问题上的任务和建模进行了讨论;列举了目前数据挖掘领域中主要流行的算法,并对算法设计需要考虑的问题进行了简要的分析;综述了目前数据挖掘算法在一些领域的应用;较全面地叙述了目前数据挖掘软件工具性能及其开发商情况;最后,对数据挖掘的发展前景和方向进行了展望。
[47]李涛,曾春秋,周武柏,周绮凤,郑理.大数据时代的数据挖掘——从应用的角度看大数据挖掘[J].大数据,2015, 04:57-80.
关键词:大数据,数据挖掘,FIU-Miner,高端制造业,空间数据挖掘,商务智能
摘要:介绍了大数据时代数据挖掘的特点、任务及难点,分析了大数据挖掘的核心架构,提出大数据的核心和本质,即应用、算法、数据和平台4个要素的有机结合。在此基础上介绍了本团队研究设计的大数据挖掘系统FIU-Miner。该系统是一个用户友好并支持在分布式环境中进行高效率计算和算法快速集成的数据挖掘系统平台,使得数据分析人员能够快速有效地进行各类数据挖掘任务。最后,介绍了基于FIU-Miner的3个典型的成功应用案例:高端制造业数据挖掘、空间数据挖掘和商务智能数据挖掘。
[48]卢晶晶.基于数据挖掘的教学评价系统[D].导师：卞艺杰.河海大学,2007.
关键词:数据挖掘,教学评价,决策树算法,层次分析法
摘要:本文探讨了高校教学评价指标的选择，建立和求解有关教学评价的决策树模型，并开展了挖掘结论的具体应用。教师的教学质量评价，是学校全面提高教学质量，有效调节教学行为的一项有效措施。本文针对教学评价，建立数据挖掘系统，希望从大量的教学数据中找出对提高教学质量有帮助的信息与知识，并将其应用到实际中。构建指标体系是进行教学评价的基础和依据，本文利用AHP方法对教师教学评价体系模型进行科学分析，最终明确了评估指标：教学态度、教学内容、教学方法，作为选择挖掘库中教学信息属性的依据，从而减少了挖掘库属性；一方面提高了挖掘效率，另一方面避免因挖掘字段过多，导致建立的决策树过大，出现过度拟合挖掘对象的现象。分析了数据挖掘的常用算法的优缺点：决策树算法描述简单、分类速度快，适合大规模的数据处理；聚类算法存在量化尺度的问题一一划分太粗糙或划分太细致，对于教学评价来说，划分太粗就得不到一个合理的分类，划分太细会导致样本过度拟合；Apriori算法当事务数据库中的事务个数很大时，扫描数据库的开销将变得很大；遗传算法仍存在收敛问题；由于高校人数多、课程量大，教学评价工作量度大，本系统需要对大量的数据进行处理，需要性能良好的算法，因此决定采用决策树算法来进行挖掘。根据决策树中的C4.5算法，建立教学评价数据挖掘模型：先构造教学评价决策树，接着用后剪枝方法对决策树剪枝，然后提取相应的规则，创建知识库。教学内容等连续性属性离散化处理时，分界点的取值通过系统建树后调试确定的，为9.0和9.6。接着，利用VB语言将此模型程序化，开发了具有五大功能模块——系统登陆模块、数据管理模块、教学评价挖掘模块、用户管理模块、数据库管理模块的教学评价数据挖掘系统。为了系统安全与保密，系统进行了安全性的设计，并通过导出步骤应用到实际中去。本系统选择了河海大学土木院、商学院和公管院等三个院系作为数据的来源，通过对数据进行预处理与分析，挖掘出了16条规则。然后对规则进行有效性测试：其中四条规则因测试集中无相关数据，无法判断其有效性；规则4、12、14的正确率因未达到规定的阈值而无效；其余11条规则的正确性都在80％以上，通过加权得到系统挖掘结果的整体正确率为93.33％，说明挖掘结果合理，系统性能良好。最后，讨论了挖掘结论在人事部门招聘的辅助决策的作用和挖掘规则对提高教学水平的可能途径。
[49]化柏林.数据挖掘与知识发现关系探析[J].情报理论与实践,2008, 04:507-510.
关键词:数据挖掘,知识发现,相关性研究,规则
摘要:以数据挖掘与知识发现的分类为切入点,详细探讨数据挖掘与知识发现的关系。总结出关于数据挖掘与知识发现的关系问题有三种观点,即数据挖掘就是知识发现,数据挖掘是知识发现的一个步骤,数据挖掘与知识发现是完全不同的两个概念。三种观点各有道理,取决于研究者的研究背景、研究范畴与目标。最后对数据挖掘与知识发现的发展趋势进行探讨。
[50]吉根林,孙志挥.数据挖掘技术[J].中国图象图形学报,2001, 08:2-8.
关键词:数据挖掘,决策支持,关联规则,分类规则,KDD
摘要:数据挖掘技术是当前数据库和人工智能领域研究的热点课题 ,为了使人们对该领域现状有个概略了解 ,在消化大量文献资料的基础上 ,首先对数据挖掘技术的国内外总体研究情况进行了概略介绍 ,包括数据挖掘技术的产生背景、应用领域、分类及主要挖掘技术 ;结合作者的研究工作 ,对关联规则的挖掘、分类规则的挖掘、离群数据的挖掘及聚类分析作了较详细的论述 ;介绍了关联规则挖掘的主要研究成果 ,同时指出了关联规则衡量标准的不足及其改进方法 ,提出了分类模式的准确度评估方法 ;最后 ,描述了数据挖掘技术在科学研究、金融投资、市场营销、保险业、制造业及通信网络管理等行业的应用情况 ,并对数据挖掘技术的应用前景作了展望 .