[1]刘太安.基于支持向量机的空间数据挖掘方法及其在旅游地理经济分析中的应用[D].导师：汪云甲.中国矿业大学,2012.
关键词:MC-COLS-SVM,COLS-BSVR,空间数据分类或回归,时政指数,景区景点分布指数,预测模型,风险管理模型,数据挖掘软件
摘要:本论文根据旅游地理经济分析预测管理需求，就基于支持向量机的空间数据挖掘分类或回归的理论与方法以及在旅游地理经济管理中的应用展开了系统研究，建立了基于支持向量机的空间数据分类或回归挖掘模型与算法、特征选择算法，设计实现了面向旅游地理经济应用的数据挖掘软件。主要内容如下：（1）提出了SVM若干算法。通过组合优化方法和最小二乘方法，以及多分类支持向量机方法，提出了MC-COLS-SVM分类机算法；通过组合优化方法，以及减少约束，降低问题复杂度，提出了组合优化COLS-BSVR回归机算法。提出了对于支持向量回归机特征选择的算法，并进行了实证分析。（2）构建了基于支持向量机的空间数据挖掘理论与方法体系。研究设计了基于支持向量机的空间数据挖掘工作流程与框架以及实现方法；基于MC-COLS-SVM多分类组合优化思路，设计了空间数据分类算法；基于COLS-BSVR组合优化最小二乘支持向量回归机思路，设计了空间数据回归算法。（3）提出了时政指数、景区景点分布指数，并成功应用于旅游地理经济分析之中。通过对旅游收入、游客人数、时政指数、景区景点分布指数、GDP、CPI等变量时间序列的统计描述分析及其它们对旅游地理经济影响分析，提取了旅游地理经济数据特征，设计了相应的旅游地理经济数据库。（4）建立了基于支持向量机的旅游地理经济预测模型。基于提出的COLS-BSVR支持向量回归机算法，建立了基于支持向量机的旅游地理经济分析预测数学模型；设计了数据挖掘中的数据构造模式，验证了模型与模式的有效性。（5）建立了基于支持向量机的旅游地理经济风险管理模型。基于设计的空间数据分类算法、回归算法以及特征选择算法，结合旅游地理经济特征敏感性分析，建立了风险管理数学模型，验证了模型的有效性。（6）设计并实现了基于支持向量机的旅游地理经济数据挖掘软件。该数据挖掘软件分三层结构构建；各种数据采集预处理后，存入旅游地理经济数据库，通过基于支持向量回归机的算法运算，生成预测信息，供分析决策参考。
[2]宝腾飞.面向移动用户数据的情境识别与挖掘[D].导师：陈恩红.中国科学技术大学,2013.
关键词:移动设备,情境建模,情境识别,关键地点,情境挖掘
摘要:随着移动互联网的兴起,移动设备成为用户使用互联网服务的新途径。通过挖掘移动设备上的情境数据对用户建模是一种新颖的理解用户需求的方案,从而能为互联网服务方提供个性化、情境感知化的服务奠定基础。这里的情境数据指移动设备上的众多传感器探测到的环境和用户行为信息。本文的研究主题是面向移动用户数据的情境识别与挖掘,主要成果如下：1.提出了使用非监督学习模型对用户情境建模的技术方案：对于用户情境建模问题,由于难以获取情境标识,因而监督学习模型难以适用。鉴于此,本文使用非监督学习模型通过情境数据自身性质挖掘用户的情境。本文提出的方案包括两个步骤。在数据预处理步骤中,对用户情境数据日志提取情境会话,由于情境会话间没有明显的分界标识,本文使用了一种最小熵算法来切分情境数据日志；在数据建模步骤中,本文使用了聚类和概率主题模型来挖掘用户情境。通过聚类模型挖掘用户情境的方式为,首先将情境会话映射到情境特征-值组合空间上,然后对情境会话使用K-means算法聚类,最后从聚类结果提取用户情境。通过概率主题模型挖掘用户情境的方式为,首先对其进行扩展从而适应情境数据的结构化特性,然后将情境会话表示成概率主题模型中的变量,最后通过Gibbs采样算法求解模型从而学习用户情境。在真实用户情境数据集上的实验分析表明了该技术方案的有效性。2.提出了通过基站标识数据挖掘用户关键地点的技术方案：关键地点是用户最重要的情境。以往的研究工作主要集中于通过GPS数据挖掘关键地点,然而由于常时间开启GPS传感器会比较耗电,从而影响设备续航时间。鉴于此,本文提出通过基站标识数据挖掘用户关键地点。根据基站的地理位置信息,以及利用基站覆盖范围彼此重叠的特性,本文提出了一个两阶段的关键地点挖掘算法。在在线阶段,检测用户的停留状态,并计算停留区域以及更新停留区域中的地理格栅的热度值；在离线阶段,通过一个递归方法挖掘出用户关键地点。为验证该技术方案的实际应用性,本文还开发了一个演示系统。最后,实验结果表明该方案在用户关键地点的查全率和查准率均高于基准方法。3.监督式情境识别方案的难点在于难以获得大量高质量的情境标识数据。本文提出了结合时间管理软件实现用户情境识别的技术方案。时间管理用户经常面临记录反复发生的情境状态的情况,很多用户厌烦这种重复操作因而放弃了时间管理。本文提出了一种半监督学习方案,通过结合用户时间管理应用中的情境状态记录数据,使用HMM模型来实现用户情境识别,并提出了DP-MUC模型来自动化确定用户情境数目和加速HMM模型的训练时间。最后,同基准算法相比,在真实用户的情境状态记录数据上的实验结果表明该方法具有较好的效果和较高的效率。
[3]李楠.基于关联数据的知识发现研究[D].导师：张学福.中国农业科学院,2012.
关键词:关联数据,知识发现,关联发现,关联数据查询,数据挖掘
摘要:网络资源环境面向结构化、语义化和智能化的方向不断地发展，最终目标是实现语义网。近年来，关联数据已经被W3C推荐为语义网的最佳实践，它实质性地促进了面向语义网的网络变革。关联数据的发展和广泛应用使得“数据网络（关联数据网络）”资源环境呈现在我们面前。这一网络资源环境具有明显地特点和优势，并且为人工智能、知识发现等领域的应用提供了巨大地潜力。但如何发挥这些潜力和优势实现知识发现的应用，是当前研究需要解决的问题。本研究按照文献调研、分析思考、理论研究、应用研究和实践验证的思路，首先识别了基于关联数据的知识发现问题，继而采用综合分析的方法，通过相关基础理论的分析与讨论，解析了基于关联数据的知识发现过程，建立了基于关联数据的知识发现的模型；然后，面向知识发现的应用，分析了基于关联数据的知识发现应用中的主要功能和它们之间的关系，构建了基于关联数据的知识发现应用体系；最后，根据综合分析和应用体系的研究成果，设计了基于关联数据的应用系统模型，并且针对基于关联数据的知识发现应用进行了实验与验证。基于关联数据的知识发现问题源于充分利用关联数据资源和实现知识发现，以及通过知识发现促进网络发展的双重需求。知识发现活动和关联数据网络的发展需要两个领域的理论和应用体系的融合和扩展。在基于关联数据的知识发现综合体系中，关联数据是数据、是网络资源环境、是数据发现工具，为知识发现注入新的活力；知识发现是一般规律、是解决问题的支点和方法、是关联数据网络资源环境上知识活动的目标，帮助实现关联数据的最佳潜力。基于关联数据的知识发现问题研究从知识发现理论研究和关联数据应用研究两个方面入手，结合对科学研究的一般规律和应用发展的特殊需求的分析展开。本研究通过对关联数据基本特征和应用特征的分析，识别了关联数据对知识发现的影响和为知识发现提供的潜力，推知了基于关联数据的知识发现的基本特征和潜力；根据特征的分析，结合知识发现的一般规律，分析了基于关联数据的知识发现过程，并且在此基础上，进一步分析和构建了基于关联数据的知识发现模型。知识发现与关联数据都是重要的实践方法，二者结合的目标也在于指导新的网络环境下的知识发现活动，因此相关应用体系的研究具有重要的实践意义。本研究分析了基于关联数据的知识发现的主要任务，从而构建了综合应用体系模型。通过应用体系，明确了基于关联数据的知识发现应用的层次、结构、目标、主要功能以及各要素之间的关系。在基本规律分析和应用体系研究基础上，本研究进行了基于关联数据的知识发现应用系统原型的设计，并且根据原型进行了系统实现与验证。应用系统原型设计充分利用了理论分析和应用体系研究的成果，提出了一个以模式整合为核心的应用系统模型，能够更好地支持基于关联数据的知识发现活动。本研究构建了以关联数据为底层支撑和逻辑控制，以知识发现作为流程和结构的控制，以关联数据的应用功能为关键操作控制的基于关联数据的知识发现模型。该模型抽象了基于关联数据的知识发现活动的新规律。本研究也面向知识发现的应用和实现，分析和构建了基于关联数据的知识发现应用体系，这一体系可以作为整合已有研究和应用成果和未来相关工作的框架。在基本规律分析和应用体系研究的基础上，本研究设计了基于关联数据的知识发现应用系统的原型。原型设计可以作为知识发现系统开发的框架，并且为相关研究工作提供借鉴。根据研究的结果，本研究组织了实验环境并且实现了基于关联数据的知识发现实验系统，并且使用系统实现了关联数据挖掘和关联规则的发现，验证了本研究的理论和系统设计框架及部分功能。基于关联数据的知识发现研究延伸了知识发现研究的理论体系，同时也加强了关联数据的应用研究。通过综合分析和研究揭示了基于关联数据的知识发现的新规律，为未来的应用开发和实践提供了基础和借鉴。本研究的目标是解析关联数据对于知识发现效率和能力的影响，实现关联数据背景下的知识发现。同时促进二者之间的相辅相成和不断优化，实现对关联数据发展乃至语义网发展的促进。
[4]王冠男.基于GPS轨迹和照片轨迹的时空数据挖掘[D].导师：王志忠.中南大学,2013.
关键词:时空数据挖掘,GPS轨迹,Geo-信息照片轨迹,轨迹相似度,重尾分布,隐半马尔可夫模型,生存分析
摘要:现代信息技术和位置感知技术迅猛发展,人们能够方便的获得各种移动物体的轨迹数据。通过分析轨迹数据可以获得很多有价值的信息,并且推断出新的知识。许多基于位置推荐的门户网站已经引起了大众和研究者的关注,关于轨迹数据挖掘的研究也逐渐变得炙手可热。轨迹数据时时空数据的重要分支,本文主要研究了基于GPS轨迹以及照片轨迹的时空数据挖掘方法,采用多种统计方法挖掘轨迹之间的相似度、旅游者的行走模式等有价值的信息,通过针对真实数据进行实验,证明了方法在实践中的高效性。本文的研究工作主要包含如下四个方面：1)提出度量GPS轨迹相似度的几何算法(GSAs)。轨迹相似度算法能够提炼移动轨迹之间的相似信息,这些信息在城市道路网、交通和地理信息系统中发挥着很重要的作用。首先提出LAR定义(Length-Angle Ratio),用来简化GPS轨迹并检测其中的重点区域(sig-region);然后按照重点区域将轨迹分段,分别使用向量法和面积法计算轨迹中各段之间的差异性；最后通过综合分析这些差异性得到GPS轨迹的相似度。算法的优势在于三方面,首先,当GPS点缺失时,算法仍然有效；其次,GSAs应用了真实距离,体现了轨迹的几何特征,并且在以往研究的基础上充分考虑了每个用户和轨迹的独特性以及交通网的特征；最后,试验证明GSAs在精确度和时间复杂度上均优于其它现有算法。2)提出路线还原方法,将非连续Geo照片轨迹(带有地理位置信息的照片轨迹)还原成连续的GPS轨迹。GPS轨迹占据存储空间大,不易处理,原始Geo照片轨迹虽然易储存,但是不能提供和GPS轨迹同样丰富的信息,将Geo照片轨迹还原为GPS轨迹可以同时解决以上难题。本文首先提出区域兴趣度比,将景点排序。然后应用隐半马尔可夫模型(HSMM)解释旅游者的迁移规律,得到重要区域序列,在此基础上,提出均值算法将重要区域序列还原成完整的GPS序列。最后,提出基于留一交叉检验(LOOCV)的试验方法,检验还原路线与GPS路线的契合性,并且证明得到的连续GPS轨迹符合人群行走基本规律。3)挖掘照片轨迹的统计特征以及时空规律。人群行走活动的基本规律在路线规划、目的地预测和推荐系统中具有举足轻重的作用。首先,通过挖掘行走活动的共同统计特征,发现照片轨迹的一些变量符合对数正态分布,继而服从重尾法则,这些变量包括LAR,重要区域间的距离以及用户在重要区域的停留时间。其次,照片轨迹表现出高度的时空规律,本文主要从三方面来进一步研究这一问题：①重要区域间的距离符合对数正态分布的原因；②影响用户选择目的地的因素；③均方位移在照片轨迹中的特征。真实数据结果证明这些共同的统计特征和时空规律在不同的区域中是相同的。4)用生存分析的方法解决轨迹问题中删失数据的问题。已知在轨迹数据挖掘中存在删失数据的问题,传统模型不适用于这类数据,需要建立相应的删失数据模型。照片轨迹中照片之间的时间间隔为右删失数据,本文以这一数据为例,首先用Kaplan-Meier估计建立非参数模型,研究相应的生存模型和危险率模型。然后建立时间间隔关于拍照停留时间的Buckley-James模型,并且用经验似然的方法估计参数的置信区间。最后建立时间间隔关于拍照停留时间以及用户个人信息的半参数模型,并且提出基于删失数据的经验似然方法,得到经验似然函数比,证明渐进分布为标准卡方分布,简化了置信区间的求解步骤。轨迹挖掘技术为快速发展的信息技术做出了杰出的贡献,而迅猛发展的信息技术又为轨迹数据挖掘提供了更广阔的发展空间,两者相辅相成。本文提供了高效易行的方法和技术,所得到的研究和技术成果并不仅仅可局限于轨迹数据挖掘领域,方法和技术的相关算法可以应用到其它研究领域。本文所做的相关分析研究不仅丰富了轨迹数据挖掘领域的技术,并且对很多现实问题具有指导意义。
[5]王乐.数据流模式挖掘算法及应用研究[D].导师：冯林.大连理工大学,2013.
关键词:数据挖掘,关联规则,频繁模式,高效用模式,不确定数据集,数据流,大数据集
摘要:随着各行业对数据越来越重视和信息技术的快速发展,产生的数据越来越全面,同时数据量也在快速的增长；并且各行业又要求能及时对已产生的数据进行挖掘和分析,这使得数据流挖掘技术愈发重要。由于数据流具有海量性、实时性和动态变化性的特点,这就要求数据流上的挖掘算法有较高的时空效率。尽管数据流上数据挖掘技术取得了一定的进展,但是挖掘算法的时空效率仍然是当前数据挖掘领域中的研究焦点之一。本文主要研究了数据流模式挖掘算法,包括传统数据集类型中的频繁模式挖掘以及大数据集下的频繁模式挖掘、不确定数据流中的频繁模式挖掘、和高效用模式挖掘。本文首先对已有的频繁模式和高效用模式挖掘算法进行了回顾,详细的介绍了算法Apriori和FP-Growth等；然后在对典型的挖掘算法和最新研究成果进行分析研究的基础上,深入研究了传统数据中的频繁模式挖掘、不确定数据上的频繁模式挖掘和具有效用值的数据中的高效用模式挖掘算法。本文取得了如下的创新性研究成果：(1)在传统数据的频繁模式挖掘算法研究中,提出新的尾节点数据结构和一种最多两次MapReduce的并行挖掘算法。针对数据流中的频繁模式挖掘问题,采用尾节点和尾节点表来提高窗口内数据更新的时间效率和维护的空间效率；并通过提高窗口内频繁模式挖掘算法的时间效率,进而提高数据流中模式挖掘的整体时间效率。针对大数据下的数据流频繁模式挖掘问题,首先通过一次MapReduce找到局部频繁模式做为候选项集,然后通过给出的剪枝策略对候选项集进行剪枝,最后进行第二次MapReduce对候选项集中剩余项集进行支持数统计；在多数情况下,该算法不需要第二次MapReduce就可以有效的挖掘到所有的频繁模式。(2)在不确定事务数据的频繁模式挖掘算法研究中,提出具有更高压缩率的树结构来改进不确定数据集及数据流上的频繁模式挖掘算法。首先利用数组来存储事务项集的概率,然后将事务概率在数组中的索引和事务项集映射到一棵树上,从而可以有效的降低维护不确定数据集的树节点个数。在此基础上,结合滑动窗口技术,同时给出两种新的树结构分别来维护窗口中数据和挖掘过程中的子数据集,保证在挖掘的过程中使窗口中事务项集的信息不会从树上丢失；从而使频繁模式挖掘算法的时空效率得到较大的提升。另外,本文还提出一种新的具有权重的频繁模式挖掘模型和算法；该模型主要是将项的权重值引入到频繁模式的挖掘过程中,将权重值大的模式考虑到挖掘结果中。(3)在高效用模式挖掘算法研究中,提出避免使用高估效用值的不产生候选项集的挖掘算法。首先本文提出一个新的树结构来维护事务项集及效用值信息,通过该树结构可以得到项集的准确效用值,而不是高估效用值,从而保证不通过候选项集就可以挖掘到所有的高效用模式,因此可以提高算法的时空效率。在此基础上,结合滑动窗口技术,同时给出一个新的树结构维护窗口中数据,可以使算法通过一遍数据集扫描,在不产生候选项集的前提下就可从数据流中挖掘高效用模式。相对KDD会议和TKDE期刊上最新发表论文UP-Growth算法,新提出的算法的时间效率提高1到2个数量级。
[6]王悦,唐常杰,杨宁,张悦,李红军,郑皎凌,朱军.在不确定数据集上挖掘优化的概率干预策略[J].软件学报,2011, 02:285-297.
关键词:不确定数据,概率干预策略,策略评价,数据挖掘,海量数据分析
摘要:提出了不确定干预分析模型,主要工作包括:(1)建立了用于多维不确定数据分析的不确定监测点模型(uncertain surveillance);(2)建立了基于不确定监测点的不确定干预策略及挖掘评价算法;(3)在真实数据及仿真数据上对所提出的两种算法作了大量实验比较,验证了所提出的干预策略评价优化算法具有较高精度,效率比朴素方法高出3个数量级,适合在实际系统中处理海量干预评价.
[7]冯研,王馨.国内图书馆数据挖掘技术实践应用进展分析[J].图书馆学研究,2011, 20:2-4.
关键词:数据挖掘,图书馆,实践应用
摘要:数据挖掘技术近几年在图书馆行业得到不断广泛的应用,文章通过文献计量学、研究方向和算法、应用软件、数据处理和选择及技术应用详情等方面分析图书馆在数据挖掘实践应用方面的进展情况。
[8]毛宇星,陈彤兵,施伯乐.一种高效的多层和概化关联规则挖掘方法[J].软件学报,2011, 12:2965-2980.
关键词:分类数据,多层关联规则,概化关联规则,层次聚类,约简划分
摘要:通过对分类数据的深入研究,提出了一种高效的多层关联规则挖掘方法:首先,根据分类数据所在的领域知识构建基于领域知识的项相关性模型DICM(domain knowledge-based item correlation model),并通过该模型对分类数据的项进行层次聚类;然后,基于项的聚类结果对事务数据库进行约简划分;最后,将约简划分后的事务数据库映射至一种压缩的AFOPT树形结构,并通过遍历AFOPT树替代原事务数据库来挖掘频繁项集.由于缩小了事务数据库规模,并采用了压缩的AFOPT结构,所提出的方法有效地节省了算法的I/O时间,极大地提升了多层关联规则的挖掘效率.基于该方法,给出了一种自顶向下的多层关联规则挖掘算法TD-CBP-MLARM和一种自底向上的多层关联规则挖掘算法BU-CBP-MLARM.此外,还将该挖掘方法成功扩展至概化关联规则挖掘领域,提出了一种高效的概化关联规则挖掘算法CBP-GARM.通过大量人工随机生成数据的实验证明,所提出的多层和概化关联规则挖掘算法不仅可以确保频繁项集挖掘结果的正确性和完整性,还比现有同类最新算法具有更好的挖掘效率和扩展性.
[9]赛英.粗糙集扩展模型及其在数据挖掘中的应用研究[D].导师：陈文伟.中国人民解放军国防科学技术大学,2002.
关键词:粗糙集,数据挖掘,粗糙集扩展模型,有序规则,排序
摘要:数据挖掘和知识发现是从数据中获取知识的一种新技术。粗糙集作为一种处理不完全、不精确及不确定信息的有效方法，在数据挖掘和知识发现领域大有用武之地。粗糙集方法的成功应用很大程度上依赖于其理论的完善，只有深入地研究粗糙集的理论体系，才能将之更有效地应用到实际领域。本文以国家自然科学基金项目“管理决策中数据仓库与数据挖掘新技术研究”为背景，从理论和应用两个方面较全面和系统地阐述了这一理论的研究内容和方法。完成的工作和取得的创新性成果在于：经过对粗糙集理论的深入研究，作者找到了粗糙集与模态逻辑、模糊集、代数系统和区间集代数等抽象理论之间的关系，一是粗糙集可以为抽象理论提供语义解释，从而使我们能更好地理解掌握这些抽象理论；二是粗糙集建立了各个独立的抽象理论之间的内在关系，使彼此独立的抽象理论联系在了一起。作者研究了粗糙集扩展理论，提出了一种多层粗糙集模型CBM-RS。该模型是一种基于覆盖的扩展的多层粗糙集模型。经过验证，二元自反关系序列下的多层粗糙集模型是CBM-RS模型的特例。CBM-RS模型突破了局限在二元关系之上的多层粗糙集模型的研究。另外，作者提出了基于分类正确度的粗糙集模型，该模型已用于作者研制的数据挖掘方法MIE-RS上。作者提出了从不一致决策表中挖掘最简规则的粗糙集方法MIE-RS。通过分类正确度有效处理了决策表的不一致性，采用启发式算法，挖掘出满足给定精确度的最简产生式规则知识。作者构造了Hash函数来实现算法，有效降低了算法的时间复杂度。并用多个UCI数据集进行了测试，与著名的Rosetta软件进行了实验对比，结果说明MIE-RS可以大大提高总的数据约简量，有效地简化最终得到的规则知识。作者提出了有序信息表上的数据分析与数据挖掘模型OITM。从数据挖掘的角度考虑对象排序问题，通过引进属性值上的有序关系，作者扩充了常见的属性值方法，提出了有序信息表的形式化概念，进而提出了一个有序信息表上的数据分析方法，通过分析有序信息表中的属性依赖，定义了有序信息表的约简集和核的概念；作者还提出和形式化了有序信息表中挖掘有序规则的问题，设计了有序决策逻辑语言(ODL)，并给出了一个挖掘有序规则的方法。基于有序关系来挖掘有序规则可看作是粗糙集模型的非等价关系扩展的一个具体应用实例。本文的研究成果，对于拓宽粗糙集的理论及粗糙集在数据挖掘中的应用，有一定的理论和实践意义。
[10]李仁璞.分类数据挖掘中若干基本问题的研究[D].导师：王正欧.天津大学,2003.
关键词:数据挖掘,分类,粗集理论,神经网络,熵
摘要:面对大规模的、高维的数据，如何建立有效的，可扩展的分类数据挖掘算法是数据挖掘领域的研究热点。围绕以上问题，本文对分类数据挖掘中涉及的若干基本问题进行了深入研究，主要包括以下几个方面的内容：提出了一种结构自适应的神经网络特征选择方法。通过交替删除网络中冗余的输入特征和隐结点，使网络结构在特征选择的过程中保持相对良好。实验表明该方法能快速有效删除特征，提高网络泛化性能。提出一种基于粗集理论和神经网络相结合的分类规则挖掘算法。首先使用粗集理论和神经网络对决策表进行两次属性约简，然后使用粗集理论对约简后的决策表进行规则抽取。该方法充分融合了粗集理论强大的规则生成能力和神经网络优良的容错性能。实验表明，该方法快速有效，生成规则简单准确，具有良好的鲁棒性。属性离散化的方法可以分为两类：局部方法和全局方法。局部方法简单易行但效果较差，而全局方法效果较好但算法复杂计算量大。本文提出一种有效的结合两类方法优点的折衷算法，在一种已有基于熵的局部算法基础上加入对决策表数据不一致度的检验，从而使该算法具有了全局化的特性。实验结果表明使用相同的规则生成器C4.5，本文方法比传统离散化方法生成的规则更强壮。对目前广泛应用的基于粗集理论和信息熵的几种规则不确定性度量准则进行了比较分析，通过定理证明了它们之间存在不一致性以及发生不一致时的必要条件，提出了下一步构建更有效的不确定性度量的方向。提出一种基于粗糙集理论的分类别进行规则抽取的算法。首先获得每类数据的属性约简；然后为每类数据构造一个分辨矩阵和一个合并矩阵,通过两个矩阵的交互作用逐类抽取规则。UCI数据库上的实验结果表明,与传统方法相比该算法能够在更短的时间内得到分类精度更高的规则。
[11]陈刚.基于数据挖掘的电力营销决策支持系统的结构原理及算法研究[D].导师：孙才新.重庆大学,2004.
关键词:神经网络,聚类分析,电力营销,决策支持系统,数据挖掘,数据仓库,联机分析
摘要:随着我国电力市场的逐步发展和完善，电力工业已经逐步从“卖方市场”转变为“买方市场”，这将给我国电力工业的发展带来重大的影响。作为独立市场主体的电力企业，其经营目标转变为关注企业效益的最大化，工作的重点逐渐从发输电方面转移到市场营销开拓以及电力需求侧的管理服务方面。随着机制的转换，传统的面向基本业务的信息管理系统(如用电MIS等)已不能满足电力企业营销工作的需要，如何建立适应于我国电力营销需求的决策支持系统已成为当务之急。数据挖掘技术是人工智能和数据库结合的产物，用于发现海量数据库中存在的潜在关系和规则，已经成为一种重要的智能决策方法以及决策知识获取的重要途径，在决策支持系统中具有重大的应用研究价值。本文对电力营销决策支持的需求进行了详细的分析和设计，在此基础上提出了一种全新电力营销决策支持系统的整体框架设计原理。该系统结构的特点是具有问题引导功能以及融合了数据仓库、OLAP分析以及DM技术，能较好地满足电力营销决策支持系统的实际需要。基于数据仓库的OLAP技术是电力营销辅助决策支持的重要技术之一。在详细分析数据仓库基础上，设计了电力营销数据仓库的实现方案；对电力营销的OLAP分析内容和方法进行了研究；在BusinessObject基础上设计和实现了电量电费的多维决策分析，包括语义层设计、通用查询报表的设计以及切片、旋转和钻取操作等。DM技术与OLAP技术是电力营销决策支持系统中的关键数据分析技术，二者有机结合构成的多维数据挖掘模型能提高数据分析的效果和性能。针对多维数据挖掘模型中的挖掘空间的选择方法问题，提出了一种用于数据挖掘空间选择的神经网络结构和算法，其算法既避免统计方法中复杂的非线性建模问题，又比一般神经网络变量选择方法的计算量小。鉴于聚类分析在数据挖掘中具有重要的作用，本文针对聚类分析中聚类数确定难的问题，深入研究了聚类准则的选择和曲线特性；提出了一种基于SOFM神经网络的结构自适应聚类神经网络，其特点是能够自动确定最佳的聚类数。基于实际营销数据，采用结构自适应聚类神经网络技术实现了用户用电量时间特征分析，所得结论对于电价的针对性的调整以及合理地安排电力生产具有重要的参考价值。本文的研究成果对于电力市场环境下电力企业的电力营销决策系统的方案设计以及实现有重要的参考价值。
[12]杨小兵.聚类分析中若干关键技术的研究[D].导师：孔繁胜.浙江大学,2005.
关键词:数据挖掘,聚类分析,模糊聚类,高斯混合模型,切换回归模型,噪音
摘要:基于数据库的知识发现(Knowledge Discovery in Database,简称KDD)是指从大量数据中提取有效的、新颖的、潜在有用的和最终可被理解的模式的非平凡过程。它是一个反复迭代的人机交互处理过程,该过程需要经历多个步骤,主要包括数据整理、数据挖掘(Data Mining)和结果的解释评估。其中数据挖掘是整个KDD过程中最核心的步骤,数据挖掘的目的就是运用特定的数据挖掘算法,从数据库中提取用户感兴趣的知识,并以一定的方式表示出来,如树、表、规则、图等。聚类分析是数据挖掘的最主要的功能之一,聚类就是将数据对象分组为多个类或簇,在同一个簇中的对象之间具有较高的相似度,而不同簇中的对象差别较大。本文将重点研究聚类分析中的若干关键技术和算法。在第一章中,首先就数据挖掘进行概述,主要讨论数据挖掘的产生、发展以及数据挖掘算法可以实现的功能,主要包括:类/概念描述、关联规则、分类与回归、聚类分析、序列与时序分析以及孤立点分析等。最后给出了本文研究的主要内容和组织结构。在第二章中,首先介绍了聚类分析的定义,聚类算法的基本要求,以及聚类中用到的主要数据类型;然后讨论了聚类分析的各种算法:划分方法、层次方法、基于密度的方法、基于网格的方法以及基于模型的方法;最后对聚类算法的应用领域进行了探讨。第三章介绍了模糊集合的基本概念,模糊集合的运算,模糊截集及分解定理,在此基础上,研究了基于模糊关系的模糊聚类及其算法,通过应用FCM算法的实例解释了模糊聚类的应用。第四章重点研究了高斯混合模型的聚类算法,除了介绍经典的EM算法以外,还讨论了GMDD算法。由于在某些领域,为了更准确地识别出不同性质的数据,人们会根据经验利用加权函数以获得更好的聚类效果,本文以加权似然方程为
[13]麦永浩.数据仓库和数据挖掘方法研究及其在公安信息建设中的应用[D].导师：王行愚.华东理工大学,2000.
关键词:数据仓库,数据挖掘,动态规划,公安信息
摘要:本文根据国内外数据挖掘和数据仓库技术的发展和公安信息的特点,以省级公安综合管理信息系统和其数据仓库的建设为应用背景,运用动态规划方法为工具,对数据仓库和数据挖掘中的若干问题提出了一些优化方法。本文的主要工作如下: 1、根据省级公安综合管理信息系统和公安数据仓库与数据挖掘的特点,本文作者提出了公安数据仓库的模型、公安数据挖掘一般方法的模型、以及基于公安数据仓库的公安数据挖掘一般方法的模型。从横向和纵向两个方面介绍了省级公安综合管理信息系统和其数据仓库结构和功能,说明了将这三者结合进行研究的重要意义和主要手段。2、对于优化公安数据仓库的计算机网络资源配置问题,本文作者将静态规划问题转化为动态规划问题,以避免非线形规划和计算的复杂性;对于公安数据仓库的计算机局域网络信息资源和广域网络信息资源的二维的资源分配问题,利用拉格朗日乘数法,将其降低维数,以降低计算的复杂性。同时,对于在公安数据仓库的智能化集成和数据挖掘中的数据关联问题,为了避免复杂的分析过程,本文作者利用动态规划方法进行分析:其关联是偶然的,还是必然的,关联的程度如何,从而得到一些简单易行的优化策略。3、在公安数据仓库的建立过程中,需要从各个不同的应用系统中集成数据,本文作者通过利用动态规划方法进行分析,对数据载入进行优化,对数据处理进行最优调度,得到总的期望报酬最大。同时,在网络环境中,公安数据仓库管理和存储的数据海量增加,本文作者利用存储区域网络SAN(Storage Area Network)来解决这个问题并利用动态规划方法进行优化配置,以满足随机需求。4、针对在公安数据仓库的使用中,经常遇到数据陈旧或部分残缺,需要更新的问题,本文作者利用动态规划方法对公安数据仓库的及其数据更新策略优化。同时,公安数据仓库信息智能集成经常要涉及到某两个节点之间是否有路径存在,寻找任意两节点间最小代价的路径的问题,本文作者利用一种较为特殊的动态规划方法------传递闭包算法来优化,得到一种收敛较快、适应广泛而又简单易行的优化方法。5、公安数据仓库的数据集成的两个重要方面是公安数据仓库信息源的供给策略研
[14]樊明辉.空间数据挖掘及其可视化系统若干关键技术研究[D].导师：池天河.中国科学院研究生院（遥感应用研究所）,2006.
关键词:空间数据仓库,空间数据集成,空间OLAP分析,概念层次树,空间关联规则,优势关系,粗糙集,空间邻接关系,MST,空间聚类,可视化,开放式数据挖掘系统
摘要:数据挖掘技术已经成为解决“数据爆炸、知识贫乏”问题的有效手段，在地学数据分析领域引入数据挖掘与知识发现的概念、模式和方法，探讨适合地学应用的数据挖掘新方法，对于有效处理海量地学数据、提高地学分析的自动化和智能化水平具有重要意义。可视化技术能为数据挖掘提供直观的数据输入、结果输出和挖掘过程的交互探索分析手段，提供在人的感知力、洞察力、判断力参与下的数据挖掘手段，从而大大地弥补了GIS重“显示数据对象”轻“刻画信息结构”的弱点，有力地提高空间数据挖掘进程的效率和结果的可信度，在地学领域，可视化与空间数据挖掘的结合已成为必然。本文系统地讨论了基于数据仓库的空间数据集成技术，改进了空间关联规则、粗糙集和空间聚类算法，研究了契合上述挖掘算法的若干可视化技术，在此基础上，实现了一种开放式的“即插即用型”数据挖掘系统，并集成上述数据挖掘技术、可视化技术，形成一套可视化空间数据挖掘的理论框架、技术方法和原型系统。研究内容和结果可归纳为：阐述了空间数据集成和空间数据集成模型的相关理论和概念，对多源空间数据的集成模式进行了探讨。讨论了多源空间数据的一体化处理技术和多尺度空间数据的一体化处理技术，提出了基于数据仓库的数据集成总体框架，设计了一个基于Web的空间OLAP工具，并给出了具体的实现流程。改进了Apriori算法，提出了一种基于映射的高效大项集关联规则发现算法MBAR。探讨了空间概念树和层次关联规则结合的途径，提出了基于概念树的多层次空间规则算法，给出了算法处理流程和应用实例。探讨了应用于多准则决策分析的基于优势关系的粗糙集扩展模型，对该模型中已有的求核和知识约简算法进行了研究，提出了一个新的优势区分矩阵的定义，在该定义的基础上给出了相应的求核和求约简算法，给出了在属性约简之后提取优势规则的方法。研究了基于空间邻接关系的空间聚类挖掘算法VSG-CLUST。该算法是一种基于图分割的可视化空间聚类算法，利用Delaunay三角网工具和MST(最小生成树)将地理实体的邻接信息(空间相邻关系)加入并参与到空间聚类中。研究了利用多尺度的空间概念层次关系进行空间聚类挖掘的算法，将尺度因素作为一种约束条件施加于VSG-CLUST算法中MST的分割和修剪策略，即一种基于尺度约束的空间层次聚类挖掘算法。讨论了基于OLAP的空间多维可视化方法，并给出OLAP多维可视化
[15]王华秋.并行数据挖掘理论研究与应用[D].导师：曹长修.重庆大学,2006.
关键词:工作站机群,并行数据挖掘,商业数据仓库,并行关联规则,并行聚类,并行神经网络
摘要:通过数据挖掘进行知识发现是对大型数据库或数据仓库的一种分析,用于发现隐藏在数据仓库中的关系和知识,这些知识会影响管理者的决策和实施。数据仓库上的数据挖掘能够从利用机群并行计算中获利,从而提高其性能和数据分析质量。实际上,挖掘大量数据集会消耗巨大的计算资源,因为在传统的计算机上,对海量数据集进行数据挖掘得到结果是要花费非常多的时间的。一种减少响应时间的方法就是采样,但是在一些情况下,减少训练数据会导致计算模型不准确,甚至不可用。另外一种方法就是并行计算了。高性能计算机和并行数据挖掘结合在一起,就能为挖掘巨型数据集提供一个最佳方案,更快的处理速度意味着用户能够试验更多的模型以更好地理解复杂数据。高性能计算让用户能够分析更多的数据变成现实。这样并行数据挖掘为数据分析和知识提取发挥了越来越重要的作用,在诸如商业和工业领域的数据提取和决策支持中得到应用。虽然目前已提出过一些并行数据挖掘算法,但是存在着通信量过大、可扩展性差、数据分布不合理等问题,出现算法性能随数据量递增效率下降的情况,具有理论或应用局限性。因此本文研究和提出具有新颖的适应性强的高效并行挖掘算法并将其用于商业和工业领域,具有其创新性和必要性。本文在研究并行数据挖掘算法前,搭建了并行计算环境、设计了大型商业数据仓库和使用了工业生产数据库作为研究和应用平台,在构建的数据仓库上利用PC机群进行并行数据挖掘。本文分析了能用于数据挖掘技术的几种不同并行形式,阐述了如何用机群执行并行数据挖掘,提出了几种可用于数据挖掘算法的并行化方法,这些算法有:(1)并行关联规则。本文在比较了当前几种并行关联规则挖掘算法的基础上,为了解决这些算法在候选集和执行时间方面存在的问题,结合关联规则的性质定理,提出了一种快速并行关联规则算法FPARM,改进了全局和局部剪枝策略以及候选集的约简方法。在无共享的工作站机群上进行性能测试,采用改进并行算法的执行效率提高了,达到了算法优化的目的,并将该算法用于商品之间的购物序列模式分析。在实际的关联规则挖掘应用中,多层概念关联规则是用户经常考虑的问题,本文在分析了单数据库多层关联规则算法SMAM算法的基础上,为了提高算法的效率,提出了两种并行多层关联规则算法PMAM-L和PMAM-LG。试验证明PMAM算法是有效的。(2)并行聚类。本文提出了基于并行退火粒子群优化的并行聚类算法,采用了
[16]宋余庆.医学图像数据挖掘若干技术研究[D].导师：孙志挥.东南大学,2005.
关键词:医学图像,聚类分析,特征提取,关联规则,图像分类
摘要:医学影像诊断是医学无创伤性诊断的主要方法之一,是国内外医学领域重点研究的方向。医学图像具有很大的数据量。医学图像中蕴含着丰富的图像特征信息和规则,有待人们去研究和认识,所以,面向医学图像的数据挖掘技术研究成为医学和计算机科学交叉学科研究的一个十分重要的领域。医学图像的高分辨率、数据的海量性、图像特征表达的复杂性等特点,使得数据挖掘技术在医学图像中的研究具有较大的学术价值和广泛的应用前景。目前,面向医学图像的数据挖掘研究刚刚起步,现有的数据挖掘方法直接应用还存在许多问题。研究和探索适合于医学图像的数据挖掘方法及其算法等医学图像数据挖掘的理论和实践问题具有重要而现实的意义,对辅助医生进行医学图像临床诊断具有重要实用价值。本论文介绍了“基于医学图像数据挖掘若干技术研究”工作的相关研究成果,主要内容有:(1)总结了国内外关于图像数据挖掘研究现状和发展,探讨了医学图像的特点,提出了适合医学图像数据挖掘的图像数据预处理技术。图像象素的灰度及其密度是表达医学图像特征的主要内容,本文研究了医学图像的灰度及其密度与人体组织器官的解剖语义关系,分析了医学图像的成像原理和临床诊断要求,定义了表征医学图像的特征内容,并提出了适合医学图像数据的灰度特征及其表达方案。(2)基于医学图像数据挖掘的需求,本文综述了数据挖掘、非结构数据挖掘、图像数据挖掘的理论和方法,探讨了医学图像数据挖掘的方法和途经,提出了基于医学图像的数据挖掘的过程框架。(3)从聚类分析的角度出发,深入研究了医学图像数据的核密度函数、数据分箱问题和基于数据分箱策略的近似核密度构造方法。在此基础上,研究并提出了适用于医学图像数据的基于医学图像近似密度构造的聚类特征提取算法及其实现。根据这个算法,可以为基于医学图像聚类的组织器官分类及其自动分割提供有效的方法和技术。(4)从关联规则发现的角度出发,围绕医学图像的组织分类,深入研究了医学图像数据特征的关联问题,提出了基于关联规则的医学图像分类挖掘方法及其实现技术。图像特征的正确选择对图像数据的关联规则发现十分重要,本文在深入研究医学图像内容特征的基础上,首次提出了医学图像局部特征,并实现了基于医学图像组织器官聚类的医学图像局部特征提取,如:基于灰度共生矩阵和基于小波的特征提取方法和算法等。此外,本文还重点研究了医学图像数据特征的关联规则,探讨了所发现的规则与医学图像诊断的关系,为医学图像自动诊断提供了新的途径。(5)在相关医学图像数据挖掘算法研究的基础上,设计并开发了一个医学图像数据挖掘实验系统,该系统具有医学图像预处理、医学图像数据特征提取等功,能为面向医学图像数据的各种数据挖掘技术的研究和实现提供实验平台。鉴于人体腹部医学图像的数据挖掘研究是一个全新领域,人体腹部影像是医学图像中最复杂的部分,解决好腹部影像问题对整个医学图像都具有适用价值。本文所提出的基于医学图像近似密度构造的聚类特征提取算法及其实现、基于关联规则的医学图像分类规则挖掘方法等创新性研究成果,对医学图像数据挖掘研究、临床医学图像的自动诊断和临床医学早期诊断都具有重要意义。
[17]沈斌.复杂网络与数据挖掘:研究范式的比较和整合[J].复杂系统与复杂性科学,2014, 01:48-52+59.
关键词:信息挖掘,数据挖掘,研究范式,比较与整合
摘要:在分析和对比复杂网络与数据挖掘两种范式的基础上,指出数据挖掘研究需要高度重视系统普适规律和内在机制的发现;复杂网络可以引入数据挖掘技术处理大数据,形成理论与数据的有机协同。进而探讨已有的复杂网络和数据挖掘交叉性探索工作,提出了范式整合的可能方向与途径。
[18]吕婉琪,钟诚,唐印浒,陈志朕.Hadoop分布式架构下大数据集的并行挖掘[J].计算机技术与发展,2014, 01:22-25+30.
关键词:数据挖掘,大数据集,并行算法,Hadoop
摘要:基于Hadoop分布式计算平台,给出一种适用于大数据集的并行挖掘算法。该算法对非结构化的原始大数据集以及中间结果文件进行垂直划分以确保能够获得完整的频繁项集,将各个垂直分块数据分配给不同的Hadoop计算节点进行处理,以减少各个计算节点的存储数据,进而减少各个计算节点执行交集操作的次数,提高并行挖掘效率。实验结果表明,给出的并行挖掘算法解决了大数据集挖掘过程中产生的大量数据通信、中间数据以及执行大量交集操作的问题,算法高效、可扩展。
[19]吴嘉瑞,郭位先,张冰,张晓朦,杨冰,盛晓光.基于数据挖掘的国医大师颜正华含陈皮处方用药规律研究[J].中国中药杂志,2014, 04:618-622.
关键词:陈皮,数据挖掘,关联规则
摘要:该研究在收集处方的基础上,基于中医传承辅助系统构建数据库,进而应用关联规则apriori算法等数据挖掘方法,分析常用单味药物频次、药物组合频次、关联规则与核心药物组合等。研究显示,含陈皮处方常用于治疗胃痛、咳嗽等病证,高频次药物组合包括"陈皮-茯苓"、"赤芍-陈皮"等,置信度为1的关联规则包括"甘草→陈皮"、"白芍-香附→陈皮"、"茯苓→陈皮"等,处方所用药物多具理气活血等功效,用药较为集中,组方法度清晰。
[20]刘新海.大数据挖掘助力未来金融服务业[J].金融市场研究,2014, 02:117-126.
关键词:大数据,数据挖掘,金融服务业
摘要:大数据是IT技术发展到一定阶段的产物,其内涵和外延还在发展中。通过对大数据的深度和广度的挖掘,大数据的价值可以被充分利用。大数据在金融服务业的应用不仅会带来新的商业机遇,还可以带来新的商业模式的变革。本文讨论了金融大数据挖掘所面临的挑战,以及国内金融业大数据挖掘的现状,并对金融大数据和云计算、互联网金融的关系进行了梳理,最后对未来金融大数据挖掘进行了展望。
[21]周剑云.Moodle平台网络课程数据挖掘模式分析[J].中国远程教育,2014, 09:68-71.
关键词:网络课程,数据挖掘,挖掘模式
摘要:在传统教育中,教师通过与学生面对面的交流,获得学生学习行为的表现信息,较为容易掌握学生的学习情况和课程教学效果,但随着现代教育技术的发展,网络学习方式的普及,以及学生学习行为的变化,研究网络课程的教学方法受到了越来越多的关注。本文以Moodle网络课程管理系统为研究基础,分析并提出有针对性的数据挖掘方法构架,以达到对课程建设情况和学生学习情况的跟踪分析,为教师改进教学策略、提高网络课程教学质量提供有力支持及方法借鉴。
[22]李桃陶,周斌,王忠振.基于社交网络的图数据挖掘应用研究[J].计算机技术与发展,2014, 10:6-11.
关键词:图挖掘,图查询,图分类,图聚类,图形数据库,社交网络
摘要:社交网络数据的高度复杂性给数据挖掘研究带来了巨大的挑战,而社交网络数据挖掘更注重实体之间相互关联的特点,使得图数据挖掘技术的研究与应用逐渐成为该领域的热点。传统数据挖掘,如聚类、分类、频繁模式挖掘等技术逐渐拓展到图数据挖掘领域。文中首先介绍了现阶段图数据挖掘算法(其中包括图查询、图聚类、图分类和图的频繁子图挖掘)的研究内容和存在的问题;其次介绍了图形数据库研究现状,以及对比了主流图形数据库管理系统的优劣;最后介绍了图挖掘技术在社交网络中的应用。
[23]王伟平,李建中,张冬冬,郭龙江.一种有效的挖掘数据流近似频繁项算法[J].软件学报,2007, 04:884-892.
关键词:数据流,数据挖掘,频繁项,ε-近似
摘要:数据流频繁项是指在数据流中出现频率超出指定阈值的数据项.查找数据流频繁项在网络故障监测、流数据分析以及流数据挖掘等多个领域有着广泛的应用.在数据流模型下,算法只能一遍扫描数据,并且可用的存储空间远远小于数据流的规模,因此,挖掘出所有准确的数据流频繁项通常是不可能的.提出一种新的挖掘数据流近似频繁项的算法.该算法的空间复杂性为O(ε~(-1)),每个数据项的平均处理时间为O(1),输出结果的频率误差界限为ε(1-s+ε)N,在目前已有的同类算法中均为最优.
[24]陈星莺,张晓花,瞿峰,刘皓明,赵波.数据挖掘在电力系统中的应用综述[J].电力科学与技术学报,2007, 03:51-56.
关键词:数据挖掘,CRISP-DM模型,电力系统
摘要:电力系统各种数据现已呈现爆炸性增长态势,数据挖掘技术将会扮演越来越重要的角色.主要介绍数据挖掘技术及其相关的应用,以及数据挖掘的交叉产业标准(CRISP-DM)和主要方法.结合电力系统的自身特点,分析数据挖掘在电力系统当前的主要应用动态及应用前景.
[25]刘言,蔡文生,邵学广.大数据与化学数据挖掘[J].科学通报,2015, 08:694-703.
关键词:大数据,数据挖掘,可视化,云计算,化学
摘要:数据是重要的战略资源,大数据挖掘技术已成为学术界、企业界甚至各国政府关注的热点.本文介绍了大数据的基本概念及发展现状,综述了与化学研究有关的大数据研究状况,讨论了大数据在基础理论与关键技术2个层面上的主要问题以及大数据挖掘技术在化学各领域中的应用,并对大数据发展的未来及其在化学学科中的应用前景进行了展望.
[26]李德仁,李熙.论夜光遥感数据挖掘[J].测绘学报,2015, 06:591-601.
关键词:夜间灯光,遥感,数据挖掘
摘要:如果从地球上空观测夜间的地球,可以发现人类聚居区和经济带发出夺目的光芒。当夜间的天空无云时,遥感卫星能够捕捉到城镇灯光、渔船灯光、火点等可见光辐射源,这些夜间无云条件下获取的地球可见光的影像即夜光遥感影像。与日间遥感不同,夜光遥感对于反映人类社会活动具有独特的能力,因此被广泛应用于社会经济领域的空间数据挖掘。本文首先介绍能够观测夜间灯光的卫星遥感观测平台和传感器,然后从社会经济参数估算、城市化监测与评估、重大事件评估、环境及健康效应研究、渔业信息提取、流行病研究、油气田监测等方面总结了夜光遥感数据挖掘的现状和特点。最后,文章从新型数据源、知识发现、地面观测和地理国情—世情监测4个方面提出了夜光遥感及其数据挖掘的未来发展趋势。
[27]戴鹤忠.基于数据挖掘技术的证券投资决策研究[D].导师：刘澄.北京科技大学,2015.
关键词:数据挖掘技术,价值投资,投资组合,投资基金
摘要:本文在分析证券投资相关理论和相关研究的基础上,运用数据挖掘技术,从个股选择决策、证券投资组合决策和证券投资基金投资三个方面对证券投资决策问题进行了研究,主要完成了以下几方面的工作：(1)把粗糙集理论运用到证券价值投资选股实践中,通过历史数据来确定各财务指标与证券收益率之间的内在关系度,并运用主客观综合权重来进行多属性投资决策,依据多属性决策结果进行证券投资的价值选股。实证研究结果证明了基于粗糙集理论的价值投资选股方法具有较好的准确性和科学性。(2)充分考虑不同行业股票的差异,选取了五只来自不同行业的股票,并考虑了不同投资者对风险和收益的不同偏好程度,参照投资者效用函数构造新的投资组合目标函数,使得模型可以适用于不同类型的投资者。应用粒子群优化算法,通过生成粒子群的粒子进行不断地速度和位置更新,求解出最优的权重配比,以指导投资者进行投资组合的构建。(3)从基金经理择股能力和择时能力、以及基金在牛市和熊市不同盈利能力两个方面来对我国证券投资基金的绩效进行评价,用于指导投资者针对自身的收益要求与风险承担程度来选择合适的证券投资基金。通过多种模型的比较分析发现：大部分基金经理都具有正的择股能力和负的择时能力；且在牛市时基金普遍能取得高于市场收益的收益,而熊市时大部分基金并不能战胜市场。
[28]郑毅.时间序列数据分类、检索方法及应用研究[D].导师：陈恩红;赵建良（J. Leon Zhao）.中国科学技术大学,2015.
关键词:时间序列分类,时间序列检索,时间序列表示和分析,卷积神经网络,深度学习,地震震源参数机制解估计,股票市场反转点预测,信息检索,模式识别,特征学习,距离度量学习
摘要:时间序列数据是一类重要的具有时序特征的数据对象。时间序列数据可以通过科学应用以及其他商业应用(例如,金融领域)方便的获取得到。一个时间序列是一组按照时间先后顺序排列好的数据采样观察值。具体地,时间序列数据的性质包括：数据规模大(大数据),高维度以及流数据特性(数据更新连续)。此外,时间序列数据采样点具有连续性和数值特性,整个时间序列可以被看成是一个整体的数据对象而非每个单独具体的数值采样点。由于时间序列可以方便的采集得到,大量的时间序列数据可以用于科学研究和深入的数据挖掘。在过去十年中,大量的科学工作者致力于时间序列数据挖掘工作,并取得了很多有效的成果。与此同时,由于时间序列数据的复杂特性,实际应用中时间序列数据挖掘面临了很多挑战。时间序列数据挖掘的目的之一是从时序数据形状角度,尝试抽取所有有意义的知识。整体上来看,时间序列数据挖掘同更一般的数据挖掘任务类似,同样是为了更好的挖掘、抽取得到可以用于进一步分析和应用的知识表示。尽管人类可以很直观的、很自然的通过时间序列数据“形状”上的特性获知每个时间序列的潜在知识,诸如：类别,是否相似,是否是反转点等。然而,对于任何一部计算机,它都只能完成基本的机械式的计算任务。任何包括类似人的这种感知、理解、识别的能力,计算机都无法直接获得。因此,包括数据挖掘、机器学习在内的领域,其根本任务均为设计相应的模型和算法,从某种程度上通过程序使得计算机获得这种智能的感知、理解和识别等能力。本文着重探索时间序列数据挖掘的若干问题。具体而言,本论文从时间序列数据分类、时间序列数据检索以及时间序列表示和建模等方面入手,结合现实生活中的若干具体问题提出了相应的模型和方法,并通过大量实验验证了这些方法的有效性和其在性能上的优势。本篇论文的主要目的之一是通过机器学习和数据挖掘的方法,结合具体工业、科学领域的具体问题,设计并提出解决相应问题的模型和方法,从而更好的解决现实世界中对应的时间序列数据的问题。我们希望本篇论文能够提供一种新的看待时间序列数据的视角给相关时间序列研究人员,从而使该工作获得更广泛的关注并被扩展、引申出更多深入的研究工作。本文的研究内容分为四个部分,分别探索时间序列表示方法,多元时间序列分类问题,时间序列快速检索以及时间序列分段表示以及建模问题。针对以上四个具体的时间序列数据挖掘问题,结合现实世界中四个具体的问题,我们相应的提出了四个具体的模型方法来解决这些问题。在过去十几年里,时间序列数据挖掘中的序列分类问题引起了学术界大量的关注。相应地,以往学者提出了许多有关时间序列分类的方法,并且认为基于最近邻(k-Neartest Neighbor,特别是1-NN)的方法是目前效果最好的分类方法。对于给定的具体分类问题,由于基于最近邻方法的分类效果主要依赖于距离度量的选择,因此,如何对给定问题选择一个合适的距离度量成为了时间序列数据挖掘中的一个热门的研究问题。目前,针对时间序列数据,已经存在许多基于不同角度设计的距离度量方法。其中,应用最为广泛的两个距离度量方法是欧式距离(Euclidean distance)和动态时间反转(Dynamic Time Warping)。欧氏距离是一种简单有效的度量方法,在一些实际的时间序列数据分类中,它可以获得比较好的分类效果。相对地,动态时间反转引入了两个序列对齐的概念,从而允许两个时间序列不同时间点的数据进行对齐。这种序列对齐的方法使得动态时间反转在一些分类场景下获得了比欧式距离好的效果。然而,动态时间反转主要的一个缺点是它需要更多的计算开销,并且,尽管结合1-NN方法,在许多场景下,它可以获得最好的分类效果,但是对于其他一些实际应用问题,它的分类效果没有明显优于其他度量方法。目前的研究结果表明,没有一种时间度量方法能够在所有时间序列数据上都可以获得最好的分类效果。另一方面,一般来说距离度量的选择需要人为的经验选择,因此,这需要大量的人力成本和时间开销。因此,对于时间序列数据如何自动的选择一个合适的距离度量是目前时间序列数据挖掘领域的一个挑战。借鉴特征学习的方法,我们探索距离度量学习方法在时间序列数据上的应用。具体地,通过距离度量的学习,针对不同的数据,我们可以自动的学习得到更好地距离度量方法,从而可以提升时间序列分类的准确率。过去几年,许多距离度量学习方法已经被提出。其中,一种通过线性变换的模型名为近邻成分分析(Neighborhood Components Analysis, NCA)的方法,通过学习得到的原始数据的低维表示方法,结合k-NN分类器,从而提升了分类的准确率。然而,这种简单的线性变换的局限在于它不能够对原始数据高阶的相关性进行建模,从而影响了分类的效果。因此,基于NCA方法,另一种称为非线性近邻成分分析(Nonlinear NCA)的距离度量学习方法被提出。这种方法能够学习获得原始数据更好的低维空间表示,从而可以获得比线性近邻成分分析方法更好的分类的准确率。遗憾的是,对于时间序列数据,以上两种距离度量学习方法不能够捕捉到时间序列的本质特性,即时间轴上的偏移(time shift)。为了能够捕捉时间轴上偏移的特性,我们结合卷积神经网络的优点,即时空不变形,针对时间序列数据,提出了一种全新的距离度量学习方法。具体地,我们基于非线性近邻成分分析方法(NNCA),设计了一种名为卷积非线性近邻成分分析的距离度量学习方法(CNNCA)。该方法不仅能够学习得到低维空间的非线性数据映射,并且可以捕捉到时间序列在时间轴上的偏移。通过学习得到数据的低维空间表示,结合1-NN分类器,我们通过大量实验证明了,对于许多数据集,这种基于卷积非线性近邻分析方法学习得到的距离表示可以获得比传统欧式距离,动态时间反转,基于窗口约束的DTW更好的分类效果。特别对于每个类别都含有大量充足训练数据的数据集,这种方法的优势更明显。另一方面,我们通过比较不同方法的效率,发现CNNCA对于大数据集和长时间序列具有效率上的优势。该项研究内容的主要贡献分为如下三个方面：·尽管目前已经存在若干关于时间序列距离度量学习方法的研究,但是就我们所知,过去的工作在学习距离度量过程中,基本上没有考虑时间轴上的偏移问题,而我们主要考虑时间序列的这个特性。·进而,我们针对时间序列数据提出了一种全新的距离度量学习方法(CNNCA).该方法能够通过卷积神经网络和多层感知机学习得到时间序列的组合特征表示,进而利用随机近邻分类的方法学习得到低维的距离度量表示。·通过在大量公开数据集上的实验对比,我们发现相比传统的时间序列距离度量(如欧式距离、动态时间反转等)以及提及的两种距离度量学习方法(LNCA和NNCA), CNNCA方法学习得到的距离度量都能够在某种程度上提升分类的准确率,特别对于相对较大规模的数据集。随着信息技术的发展和进步,传感器的价格越来越低廉,这使得近些年传感器的使用越来越普及。因此,大量的来自不同领域(例如,生物信息领域,金融领域,移动互联网以及医疗领域)的时间序列数据可以被容易的采集得到。于是,诸如一元时间序列分类问题、多元时间序列分类问题这些时间序列数据挖掘的研究问题得到了很多学者的关注。特别地,较比一元时间序列,多元时间序列数据对于潜在的特征模式能够提供更多的信息(通过不同的维度提供更多的视角),从而,多种角度的信息可以帮助提升时间序列分类的准确率。因此,多元时间序列分类任务在许多实际应用问题中变得越来越重要。在本项研究中,我们着重考虑多元时间序列分类问题。在过去十几年,已经有许多时间序列分类算法被提出。并且,许多以往的工作声称,在这些分类方法中,基于距离度量方法的k最近邻方法(k-NN)能够获得最好的分类效果。另一方面,更多的证据也表明,对于许多不同领域的时间序列数据,动态时间反转度量是目前效果最好的序列距离度量方法。因此,采用动态时间反转(DTW)度量的k-NN方法在大部分场景下可以获得最好的分类准确率。相对基于距离度量的方法,传统的基于特征的分类方法也可以应用于时间序列数据。然而,这种方法的分类准确率严重依赖于人工构造的特征质量。不同于其他数据类型,对于时间序列数据,我们很难直观的人为构造出很好的、能够捕捉到时间序列本质特性的特征表示,因此,基于特征的分类方法的分类效果一般没有基于距离度量的方法的分类效果好,特别对于1-NN和DTW方法。回顾之前提到的1-NN和DTW的不足,我们得到了如下的研究动机。针对基于特征的分类方法,是否可以提高其分类准确率?使得基于特征的分类方法不仅能够在计算效率上有优势并且在分类准确率上也有一定的竞争能力?受到深度学习应用在图像分类任务中的启发,我们设计并提出了一种应用于多元时间序列数据的深度学习框架。深度学习技术不需要人工构造特征表示,相对地,它可以通过原始数据自动的学习得到层次化的特征表示。具体地,我们提出了一种有效的多通道深度卷积神经网络(MC-DCNN)模型用于多元时间序列分类问题。该模型中,每一个通道的输入是相应多元时间序列中某个一元时间序列数据,每个通道独自的学习该一元时间序列的层次化的特征表示。并且,每个通道学习得到的特征表示再通过多层感知机进行特征的融合并进行分类。基于梯度的方法被用于模型的训练。我们通过几个真实世界的数据集对MC-DCNN方法以及对比方法进行评测。实验结果表明MC-DCNN方法的分类效果优于其他的对比方法并且具有更好的泛化能力(特别对于弱标注的数据)。此外,我们还对比了几种不同的激发函数和池化策略(pooling strategy),并且比较了不同激发函数和池化策略组合在训练过程中的收敛速率。为了进一步的提升分类效果,我们采用了一种无监督的预训练卷积神经网络的方法,并且提出了基于预训练的多通道卷积深度神经网络模型。同时,为了更好的感知模型学习得到的特征,我们对卷积层学习得到的局部特征进行了有效的可视化展示。地震学界对于实时的报告地震信息的进行大量的努力和研究。最近几年,这些研究和努力集中在地震预警系统的开发工作中。这些预警系统可以在地震发生后几秒到几分钟之内对公众发出预警消息。目前在世界范围内存在若干个地震预警系统,包括日本的REIS,墨西哥的SAS,台湾的VSN以及土耳其的IERREWS系统。美国的研究人员致力于开发针对加利福尼亚地区的ElarmS早期预警系统,然而该系统的效果不明显。目前已经存在若干鲁棒的算法用于自动的估计地震震源信息。例如,日本的REIS系统能够在P波(P-wave)到达之后5秒钟之内,利用密集的地震监测台站网络数据,得到地震的位置和震级信息。然而,尽管采用新近提出的基于格林函数以及矩张量反演方法,该系统仍然需要若干分钟甚至更多的时间来推断震源机制解信息。同样地,基于GPS数据的方法也需要若干分钟才能够得到大地震矩张量的几何中心。探索实时的推断地震震源机制、震源位置和震级有着非常重大的意义。以海啸预测为例,海啸预测需要使用全部的震源参数,包括震源深度,震级,滑动(slip)以及断层的走向(strike和dip)。例如,2010年10月25日发生在苏门答腊岛西部海域的震级为Mω7.7的浅层地震,引起了局部地区的海啸并且在几分钟之内到达该岛,使得400多人意外丧生。震源机制解的研究表明这次地震是由逆断层机制引起海水运动造成的。另一个相对的例子是在2012年4月11日发生的震级为Mω8.6的印度洋大地震之后大约两小时的震级Mω8.2的余震,该余震并没有引起海啸,尽管已经发布了预警信息。震源机制解的研究表明这两次地震都是由于走向滑动引起的。然而,相对较少的海水移动不太可能会引发海啸。实时的震源机制解估计对于监测地质断层的活动具有很重要的作用。通过分析1999年震级Mω7.6的伊兹米特地震,发现一系列前阵的震源机制解显示出相似的断层滑动方式。局部地区一组地震的震源机制解能够有助于刻画出该地区地质断层的活动。从而有利于实时的描绘出地震活跃区域的断层移动方式。估计震源机制解最大的挑战在于如何在获得地震数据后数秒钟之内更加快速自动化的得出结果。在本研究中,我们借鉴传统Web搜索引擎的思想,设计了一种基于图像的地震图搜索引擎(SeisE),用以在一秒钟之内完成对地震震源参数的估计。具体地,我们事先通过相应的地震模型构造得到大规模的地震图数据库并且用于后续的检索问题。类似于语音数据,每一个地震图数据可以认为是一个一元的时间序列数据,并通过地震监测台站记录得到地震引起的地表运动。每一个地震图即时间序列,包含有地震震源信息以及该地震波传播媒介的信息。假设我们采用的地球速度模型已知,我们采用前向建模方法(forward modeling)来模拟生成地震图并构建地震图数据库。通过设定每个参数的集合构建参数网格来完成地震图数据库的生成。地震搜索引擎的目的是查找得到输入地震记录在地震数据库中最相似的若干个地震图,即传统的时间序列检索问题。整个地震图搜索以及后续震源参数估计过程都可以自动的完成,而不需要人为的干预。因此,该地震搜索引擎可以用于日常自动化的地震震源参数的推断任务。我们通过若干具体的地震事件来验证我们方法的有效性以及效率。特别地,我们的方法可以在少于一秒钟时间内完成对输入地震事件的震源参数估计,同时对于发生在地震数据库之外区域的以及多个重叠地震事件(发生时间相近),我们的系统能够有效的区分出这些情况并且通过设定初始阈值进行过滤。过去二十年,股票收益或者股票指数预测吸引了许多研究者的关注。很长一段时间,为了预测股票市场的变化,主要存在两类预测方法。一种是基于基本面分析的方法,另一种是基于技术分析的方法。前者主要侧重于分析影响上市公司股票价格的各种因素,比如整体经济情况以及公司的经营状况等。目的是判断得出公司未来股票价格的长期走势。相对于基本面分析,技术分析方法也称为图表法,通过分析上市公司股票价格的历史数据,包括股票价格以及股票交易量等信息。至今,许多有效的基于曲线图模式的方法已经被用于预测股票价格的走势,比如,head and shoulder, cup and handle等基于形状的模式。此外,存在许多技术指标(technical indicator),例如,Moving Average, Relative strength index (RSI)等指标用于估计股票价格的反转点。技术分析方法主要采用曲线图模式以及领先的技术指标来预测股票价格走势,并且利用滞后的技术指标来确认预测得到的股票价格反转点。无论是基本面分析还是技术分析方法,两种方法都需要大量的人工分析并且强烈依赖于分析人员的经验和能力才能获得最后的决策。这样使得投资者花费大量时间在分析股市上和决策判断上。随着计算机相关领域的快速发展,科技技术的进步使得很多研究人员尝试采用数据挖掘或者机器学习的方法进行股票市场的预测。在过去二十年,许多有关股票市场预测方法被提出,包括基于机器学习的方法,比如基于神经网络的方法、基于支持向量机(SVM)的方法、基于模糊系统的方法和基于演化算法的方法等,以及基于统计模型的方法,比如基于GARCH (Generalized AutoRegressive Conditional Heteroskedasticity)模型的方法。这些研究的结果指出,定量分析(即技术分析)和定性分析(即基本面分析)对于股票价格的预测都是有帮助的。从基本面分析的角度看,社会上的公开信息,例如新闻,微博用户的整体情感以及有关上市公司股票的分析文章都会影响或者反应出整个股票市场的趋势。Web可以认为是金融信息最大的信息源(例如新闻文章和个体用户的观点等),并且,许多研究人员指出可以基于社会大众的情感分析从而预测股票市场的走势。股票市场被认为是一个高度复杂的系统,它包含了大量的噪声信息,并且是混沌的和非稳定的。已知很多研究人员曾经指出它们的方法(或者基于神经网络的,或者基于模糊逻辑的,或者基于任何其他的数据挖掘和机器学习方法)能够在某种程度上用来预测未来股票价格或者股票价格走势。然而,我相信大部分人员对此都这些方法的可靠性持怀疑的态度。另一方面,纵然我们相信这些方法可以在一定的准确率条件下预测股票市场,例如,55%,那么,对于这些预测的结果,我们怎么用来指导我们进行决策呢?直观地,在进行股票交易的过程中,我们最期望知道的信息是何时是短期时间内该股票的最低价格,并且,更好的情况是我们还可以获知何时是股票价格的最高值。为了简化说法,我们将这些局部时间的最低股价和最高股价合称为股票价格的反转点(turning points),具体地,将最低股价称为“山谷点(valley)”,将最高股价称为“山峰点(peak)”。股票价格反转点可以认为是股票价格序列的一种高等级的抽象表示。任何股票价格序列都可以用一个反转点的序列来表示(山谷点和山峰点交替出现)。如果我们能够相对准确的预测反转点的出现,那么理想的交易决策应该是在山谷点买入股票并且在山峰点卖出股票。基于这种交易策略,我们最终的收益将会增加。然而,如何才能知道何时是反转点呢?如果我们将这个问题考虑为分类问题,并且期望通过数据挖掘方法或者机器学习方法来预测反转点的出现,那么这个问题主要包括两个挑战。第一是怎样获得训练数据,即如何获得已知反转点的股票价格序列数据。第二是如何在已知训练数据的情况下,构造有效地特征从而用来进行反转点的预测。本研究内容主要尝试探索以上两个问题。具体地,我们通过设计得到一种股票反转点预测的方法,最终得到基于预测反转点的股票交易决策支持系统。该系统主要包括两部分内容,一是通过逐端重要点(PIP)识别方法以及逻辑规则方法得到反转点的训练数据。二是通过大量丰富的技术指标(technical indicator)作为反转点的特征进行反转点的预测任务。该项研究目的之一是探索技术指标是否对股票反转点的预测有帮助,另一个目的是通过预测的反转点可以对股票交易人员提供更好的决策支持。
[29]薛洁.两类生物计算问题及其在数据挖掘中的应用研究[D].导师：刘希玉.山东师范大学,2015.
关键词:膜计算,DNA计算,数据挖掘,聚类分析
摘要:作为生物计算的新的研究内容，膜计算从生物体的自身运行机制和合作原理，即细胞、组织等结构中获得灵感，设计出P系统。到现在为止，主要的P系统有三大类：cell-like（细胞）P系统，tissue-like（组织）P系统，Spiking Neural （神经）P系统。这些P系统都是从生命体机制，如细胞、组织中概括提取出来的。膜计算的主要研究方向包括：膜系统的计算能力与计算效率，新型膜计算模型，膜计算的应用以及实现。得益于膜计算具有的并行性特点，膜计算已应用到经济学、语言学、生物建模、密码学、计算机图形学等多个领域，解决了许多问题。DNA计算是以生物DNA为基础的计算，通过DNA分子的变性、复性退火等操作，在特定环境下，在试管中或表面上或芯片上进行反应，从而得出问题解集的过程。DNA计算具有三个显著优势(1)高并行性，运算速度快(2)DNA作为信息的载体，存储容量大。(3)DNA分子生物计算耗能低。研究DNA计算的热门所在，主要为：对于新的DNA模型的发现、分析与研究；能够解决非确定多项式问题的具体的DNA模型；构造基于DNA求解问题的装置并使之自动化等。数据挖掘，是从数据中获取知识和信息的过程。在大数据背景下，针对其出现的新特点，如何对数据进行有效分析，从庞大的信息中发掘可利用的知识，提升数据的有效性和可阅读性，有待数据挖掘研究学者提出合理、可用的方法。聚类分析是一种处理数据（信息）的有用方法或技术。作为数据挖掘极其重要的一部分，聚类有着多种方法，如系统法，动态聚类法，模糊聚类方法等。这些方法各有优缺点，分别在某些特定的情况下取得了理想的聚类效果。论文从基于膜计算的聚类算法和基于DNA计算的聚类算法两个方面进行了研究，主要工作如下：(1)Pǎun曾说：“设计实现新的P系统是膜计算领域的一条重要发展道路”。本文首先对三种主要的膜计算模型进行了扩展，分别提出了基于层结构的膜系统模型，带有动态促进/抑制因子的组织型膜计算模型和具有拓展规则及多输出的脉冲神经模型。在数学图形学、拓扑学中，应用较多的一个理论叫做离散Morse理论。这一理论能够剖析一些离散图形结构的拓扑类型。将膜系统与新型数据结构(如单纯形、复形等)结合，提出基于格（偏序结构）的交流膜系统，基于单纯形的交流膜系统，并使用形式语言证明其计算完备性。作为一种新型的计算方法，膜计算在聚类分析中的应用并不多。结合膜计算的强大并行能力，本文提出了基于动态促进/抑制因子的组织型膜系统的拓扑聚类算法，使用带有动态促进/抑制因子的组织型膜系统规则实现具体聚类步骤，通过一个包含十个数据点的示例说明了算法实施的可行性，与传统操作方法进行了时间复杂度的比较。将改进的脉冲神经膜计算模型与菱形网格相结合，提出基于拓展规则及多输出的脉冲神经膜系统的网格聚类，给出算法的规则，膜系统结构，通过包含多个数据点的示例说明了算法是管用的。提出基于格（偏序结构）的新型结构交流膜计算模型，设计了上确界和下确界规则，通过规则在膜系统中实现了密度聚类算法，减少了算法的时间复杂度，提供了聚类算法的新思想。本文将所提出的基于膜计算的聚类算法应用于具体问题中，给出了三个方面的应用，包括：膜计算、DNA计算在真实数据集中的应用、膜计算在文本聚类以及在空气质量评估中的应用。(2）使用著名Adleman模型、改进的粘贴模型以及K-臂DNA计算模型进行聚类分析。提出了基于Adlman-Lipton计算模型的拓扑聚类算法，基于改进的粘贴DNA计算模型的拓扑方法和基于k-臂即三维DNA模型的划分方法。分别将DNA计算与层次聚类，网格聚类等算法相结合。基于Adlman-Lipton计算模型的拓扑聚类算法，用单链DNA表示顶点和各个顶点之间的边，使用DNA测试分子序列顺序的方法与凝胶电泳方法，两种方法共同作用得到最小生成树，随后，按照一个具体数值（反应之前给定的）删除大于这个数值的边，结果中可连通的顶点的子图数目即聚类的簇的个数。基于改进的粘贴DNA计算模型的拓扑聚类算法中，首先，对于粘贴模型的存储与粘贴链结构、基本操作进行了补充、改进，然后，结合Chamlon算法进行聚类。基于k-臂DNA计算模型的划分聚类算法中，将DNA计算与网格聚类思想相结合，使用网格将二维数据转换到不同的单元格上，设定核心，对每个核心及其连接的顶点进行4-臂DNA编码，在试管中并行产生DNA团，以达到聚类的目的。本文对传统的膜计算模型进行了扩展，并且提出了新型结构膜系统，使用形式语言证明其计算能力，将扩展的膜系统与新型膜系统用于数据挖掘聚类分析中，并通过实验进行了比较分析。使用著名Adleman模型、改进的粘贴模型以及K-臂DNA计算模型进行聚类分析。将上述技术应用到实际问题中。由于膜计算、DNA计算的并行性，在处理数据挖掘任务方面有着极大的潜力，不论在生物信息领域，还是商务智能领域都有着重要意义。
[30]王达明.基于云计算与医疗大数据的Apriori算法的优化研究[D].导师：崔晓燕.北京邮电大学,2015.
关键词:数据挖掘,云计算,医疗大数据,Apriori算法,Hadoop平台
摘要:随着医疗行业的不断发展,医疗数据的规模不断扩大,而其蕴含的价值也不断增高,医疗大数据的概念已经成为很多专家及学者研究的目标。面对医疗大数据庞大的数据规模,传统的存储架构已不能满足其需求,而云计算的出现为医疗大数据的储存和调用提供了一个完美的解决方案。医疗大数据中潜在信息的价值更是无穷无尽的,如何将这些潜在的信息挖掘出来是研究的重点。数据挖掘技术以及关联规则挖掘是能体现医疗大数据价值的重要技术,但是传统的挖掘算法已不能满足医疗大数据以及云计算的要求,通过对算法的改进和优化以适用于医疗云平台,将是未来研究的重要方向。本文首先根据医疗大数据以及云计算的概念及特点,提出了一种医疗云平台的架构方案,包括数据采集层、数据云储存层、数据挖掘层、企业及数据库以及应用层5个部分。针对现有医疗数据挖掘技术中的关联规则算法,本文进行了分析与研究,并通过引入了兴趣度对经典Apriori算法进行改进,并且运用云计算和云平台Hadoop的知识,提出了一种基于MapReduce化以及兴趣度的改进Apriori医疗数据挖掘算法。最后,本文通过搭建Hadoop平台进行仿真实验,算法用JAVA实现,通过对训练数据进行挖掘,结果表明改进算法在处理大数据时空间复杂度更低,且挖掘时间随着数据规模的增大呈线性增长,验证了改进算法在进行大数据挖掘时的优越性。
[31]贾云朋.数据挖掘在股票曲线趋势预测中的研究及应用[D].导师：曹旭光.吉林大学,2015.
关键词:股票分析,数据挖掘,曲线趋势
摘要:我国的股票市场正在快速发展，并走向成熟化。随着股票市场的发展，股票数据曲线趋势的研究仍具有很强的应用价值。技术分析，作为证券分析中的重要组成部分，在国内外的研究己经达到了较高的水平。在信息技术不断发展的同时，新的理论和技术分析手段不断地被应用到技术分析中。目前，市场上有很多种类的股票分析方法，但都有各自的优缺点，存在各种各样的不足。通过对众多股票预测方法研究分析发现，大多股票分析方法都存在操作过程复杂、股票数据分析的不准确或不容易量化分析等问题。本文主要研究了数据挖掘在股价曲线的趋势预测。文章从上市公司的历史股票数据入手，应用数据挖掘中几种常用概念和方法对其未来股价进行分析，以预测该公司股价的未来变化趋势，并与实际趋势进行比较，分析其适用性。主要研究内容包括以下几个方面：文中首先介绍了数据挖掘技术与证券分析技术的基本内容并论证了数据挖掘在股市趋势预测中的可应用性。在此基础上研究了一些现有方法，包括时间序列方法和马尔可夫方法，并分别进行实验。应用时间序列方法预测时使用了一次移动平均预测法、一次指数平滑预测法和两次指数平滑预测法。根据实验结果，发现一次指数平滑预测法避免了一次移动平均预测法无法覆盖样本数据且无法判断样本数据影响力大小的问题，而两次指数平滑预测法避免了一次指数平滑预测法只适合于具有水平发展趋势的时间序列分析的问题。然后根据上述方法中避免缺陷的改进策略，分析马尔科夫预测方法的实验结果，找到其缺陷并提出了考虑成交量影响的马尔可夫预测法，提高数据覆盖率，然后对其进行实验验证。文章最后总结了所有方法，并提出避免新方法状态可能不存在缺陷的方法，以提高运算效率。从实验中可以看到：时间序列法预测计算量小，过程简单，但是误差较大；马尔可夫预测法预测准确度有所提高，但由于只考虑单一因素的影响，所以仍有改良空间；而成交量影响的马尔可夫预测法，考虑到了不同因素的影响，准确度最高，适合预测单一股票短期的价格趋势。文章中使用的方法都较为容易量化实现，且结果清晰，实际股价曲线趋势预测具有一定的参考价值。
[32]何小东,刘卫国.数据挖掘中关联规则挖掘算法比较研究[J].计算机工程与设计,2005, 05:1265-1268.
关键词:数据挖掘,关联规则,算法,频集
摘要:分析数据挖掘中关联规则挖掘算法的研究现状,提出关联规则新的价值衡量方法和关联规则挖掘今后进一步的研究方向。以核心Apriori算法为基点,运用文献查询和比较分析方法对典型的关联规则挖掘算法进行了综合研究:①Apriori方法即使进行了优化,一些固有的缺陷仍然无法克服,还需进一步研究;②今后的研究方向将是提高处理极大量数据和非结构化数据算法的效率、与OLAP相结合以及生成结果的可视化。
[33]王曙燕,耿国华,李丙春.决策树算法在医学图像数据挖掘中的应用[J].西北大学学报(自然科学版),2005, 03:262-265.
关键词:数据挖掘,决策树,分类,医学图像
摘要:目的研究决策树算法在医学图像数据挖掘中的应用。方法利用决策树算法对乳腺癌图像数据进行分类,提出了一个基于决策树算法的医学图像分类器。结果实现了ID3和C4.5算法对图像数据的分类,获得了分类的实验结果。结论该模型系统达到了较高的分类准确率,证明数据挖掘在辅助医疗诊断中有着广泛的应用前景。
[34]孙微微,刘才兴.数据仓库与数据挖掘[J].农业网络信息,2005, 01:36-39.
关键词:数据仓库,数据挖掘,综述
摘要:综述了数据挖掘的实施过程 ,作用与局限性 ,关联规则、分类与预测、聚类分析等三种主要功能 ,数据挖掘在零售业、互联网、电信业、金融业、生物医学及农业中的主要应用 ,最后讨论了数据挖掘所面临的问题。
[35]谈恒贵,王文杰,李游华.数据挖掘分类算法综述[J].微型机与应用,2005, 02:4-6+9.
关键词:数据挖掘,关联规则,决策树,分类算法
摘要:基于数据挖掘分类算法的研究现状,对目前发展较成熟的几种分类算法如决策树、关联规则分类、神经网络、贝叶斯方法、遗传算法等数据挖掘分类算法分别进行了论述。主要分析比较各典型算法的优点和不足,对其他一些算法也作了简单介绍,旨在追溯算法的发展轨迹,指出部分算法可能发展的方向,为进一步研究提供有益的借鉴。
[36]张玉涛,李雷明子,王继民,王建冬.数据挖掘领域的科研合作网络分析[J].图书情报工作,2012, 06:117-122+134.
关键词:数据挖掘,科研合作网络,社会网络分析
摘要:基于SCI和SSCI数据库中以"数据挖掘"为主题的文献题录信息,构建三个科研合作网络(高校间、公司间、国家间),利用社会网络分析方法对这三个不同类型的网络特征进行对比分析。结果显示,数据挖掘领域的研究成果涉及众多研究方向,不同的机构实体有不同的研究重点,所构建的三个不同类型的科研合作网络在诸多网络特征上存在较大的差异,包括合作网络的密度、节点的平均度、最大成分的平均最短路径、最大成分的比重等。最后对部分高校与公司的研究重点进行具体分析。
[37]李明江,唐颖,周力军.数据挖掘技术及应用[J].中国新通信,2012, 22:66-67+74.
关键词:数据挖掘,决策,统计分析
摘要:随着信息技术和数据库技术的快速发展和普及应用,信息化建设取得了长足的发展。信息收集能力得到提高,数据信息量快速增长,然而人们对这种大规模数据的分析、利用、决策能力却比较弱;仅仅依靠传统的数据查询和统计已经不能适应现代社会市场竞争的需要。而数据挖掘技术的出现满足了人们的需求,通过将海量的数据信息转化为有用的数据仓库,为各行各业的发展提供决策性的支持。
[38]颜巍.基于云平台的数据挖掘算法的研究与实现[D].导师：罗光春.电子科技大学,2013.
关键词:Hadoop,MapReduce,数据挖掘,K-Means,协同过滤
摘要:随着信息社会的发展，每天产生的数据量成指数级增长。如何从海量数据中挖掘有用信息成为公司面对的一大难题。数据挖掘算法对数据进行处理，挖掘隐藏有用信息，有利于公司作出发展决定，但目前的挖掘算法处理海量数据需要耗费很长的时间或无法处理海量数据。将传统算法迁移到云平台进行并行化改进可以有效的解决该问题。Hadoop是Apache开发的一种分布式系统框架，底层的HDFS提供了具有高容错、高吞吐率的文件存储读写；MapReduce提供了一种并行化编程框架，用户无需了解分布式并行化编程细节，只需编写Map和Reduce类就能实现分布式程序。Hadoop的海量数据存储平台和简单的并行化计算平台，为传统数据挖掘算法能够处理海量数据提供了基础。本文研究Hadoop平台技术和常见的数据挖掘算法，利用Hadoop集群并行处理数据的能力对K-Means算法、协同过滤算法进行并行化改进。主要工作如下：K-Means算法是一种常见的聚类算法，按照元素之间的相似性将原始数据划分为多个簇。在本文中，针对聚类算法K-Means依赖于k值和初始中心点的缺陷，提出了基于采样和密度的改进K-Means算法。通过采样和密度来确定K-Means算法初始k值和初始中心点，并且基于Hadoop平台进行并行化改进。通过实验验证，改进后的K-Means算法具有很好的并行性。(2)协同过滤算法是目前用的最多的一种项目推荐算法，通过计算用户之间的相似性找到具有最高相似度的k个邻居，然后通过邻居对项目的评分为用户推荐项目。在本文中，针对用户评分的稀疏性，提出了一种基于用户相似度和属性权值的混合推荐算法。通过对用户评分记录的学习，求出项目属性的权值，通过属性的权值并结合用户相似度来推荐项目，最后将算法移植到Hadoop平台。通过实验验证，改进后的协同过滤算法比原始算法具有更好的精准度和并行性。(3)目前，Hadoop平台主要通过命令行进行操作，这对普通用户具有一定的难度。本文设计实现了基于Hadoop平台的数据挖掘系统。该系统将数据挖掘算法和Hadoop平台细节进行封装，对外提供Rest接口，用户通过Rest接口调用并行化的数据挖掘算法进行数据分析，无需了解底层的具体实现。
[39]张轲智.基于web的数据挖掘系统设计与实现[D].导师：刘强;杨军.电子科技大学,2013.
关键词:数据挖掘,web挖掘,数据库
摘要:对企业而言，如何在竞争日趋激烈的商业中生存，发展，争取更多的客户显得格外重要。如果了解客户需要什么，对什么更感兴趣，如何做出关键决策，更能吸引用户购买自己的商品，将为企业获得更多的利润。数据挖掘，作为一种新兴的商业技术，可以获得利于商业化运作、富有竞争力的信息，成为解决此问题的关键。用户在通常的行为过程中，如浏览网页等，会留下大量的记录。这些看似无用的信息在数据挖掘系统里面通过分析、转换、抽取或者利用其他模型化等方式进行处理，就可以得到对商业决策有很大帮助的重要数据。本文研究了以下的内容：首先，探究了数据挖掘的概念，介绍了数据挖掘的过程和功能，并且对数据仓库进行了研究。本次数据挖掘重点采用web挖掘，并且详细讨论了web挖掘的特点和用户行为分析的相关基础知识。接着对数据挖掘的各个功能模块进行设计，并对数据挖掘体系进行研究。非常详尽的介绍了系统中常用的一些算法，并对数据挖掘体系进行了研究分类。重点对关联规则，聚类算法和回归分析等算法进行介绍，并且构造了此次任务所使用的web算法。最后本文对数据挖掘系统进行设计，并对系统架构的相关模块进行实现，包括数据的预处理模块，数据读取的模块，以及兴趣挖掘的模块，再对系统性能进行调试，主要对准确率和查全率这2个指标进行模拟评估，得出系统的可靠性，并且展示出系统所挖掘出来的一些数据。本设计通过提取xml文件中用户在网页中留下的大量记录，作为基础数据源，提出了数据挖掘的一般模型，通过聚类，关联等算法，研究出用户上网行为中的普遍规律，分析出用户潜意识中的需求。对于企业了解用户行为产生了良好的效果，意义在于力求对企业做出利于商业化运作的决策提供良好的支持。
[40]李伟卫.基于Hadoop平台的数据挖掘技术研究[D].导师：张阳.西北农林科技大学,2013.
关键词:云计算,数据挖掘,Hadoop,MapReduce,HBase
摘要:随着科技的飞速发展，人们基于互联网所产生的数据呈现出爆炸般的增长态势。传统的计算机体系架构在大数据面前显得力不从心。云计算的提出，为复杂的大数据处理提供了新的解决方案。Hadoop是Apache基金会的开源项目之一，它基于普通商用计算机集群，展现出了卓越的计算能力、存储能力与调度能力。数据挖掘技术也以此为契机，进入了一个飞速发展的阶段。本研究基于Hadoop平台，在充分学习分布式程序的运行机理基础之上，对几种具有代表性的数据挖掘算法的实现思路与方法进行了深入研究，提出了将它们向分布式平台改造的方案，并实现了可以良好运行的Hadoop版本，从而帮助广大数据挖掘从业人员更好地基于该平台开展各项工作。课题研究的主要内容有：（1）针对传统的以文本方式存储的数据，基于MapReduce分布式编程框架，从数据挖掘三大类算法：分类、聚类和关联规则挖掘算法中，分别取每一类中有代表性的一种，分析算法的运行原理，制订改造方案，针对朴素贝叶斯分类算法、K-modes聚类算法、ECLAT频繁项集挖掘算法，进行了分布式算法的实现，它们均能够基于Hadoop平台高效、稳定运行。（2）针对互联网中新兴的非结构化数据，采用HiveQL语言作为检索入口，基于HBase分布式数据库，实现能够在其中稳定运行的分布式GAC-RDB分类算法。它使用高层语言作为切入点，不需要拥有诸如Java、MapReduce等背景知识，将开发人员从各类底层繁琐代码中解放出来，把主要精力投入到具体的业务分析中去，从而更快速、更便捷地完成各类数据挖掘任务。基于西北农林科技大学高性能计算集群，设计了多组方案对改造后算法的有效性和Hadoop平台的高效性进行了实验验证，将数据绘制成曲线并从多个角度进行了分析。实验结果表明，在保证算法有效性和准确率的前提下，MapReduce编程框架可以有效提高程序的运行效率，降低数据的处理时间；HiveQL查询语言可以减少程序的开发周期，更加方便地处理各种存储在分布式数据库中的数据。
[41]段玲.基于数据挖掘的银行客户分析系统设计与实现[D].导师：陆鑫;范涤.电子科技大学,2013.
关键词:客户关系管理,数据挖掘,决策树,C4.5算法
摘要:随着经济全球化、网络化以及金融自由化浪潮的展开,银行间的竞争日趋激烈。各商业银行已经认识到,银行要在竞争中保持优势,必须注重对客户资源的竞争,而要竞争客户资源,必须通过建立客户关系管理系统来获得实时的客户信息,而数据挖掘技术是实施客户关系管理的关键技术之一。通过数据挖掘技术可以过客户信息进行多维度的分析,从大量客户数据中挖掘出隐含的、对银行决策有帮助的知识和规则。这样才能为不同需求的客户提供差别化的金融服务,从而达到保留现有客户、发掘潜在客户并最终提高银行盈利能力的目的。本课题通过对客户关系管理和数据挖掘技术相关理论和方法的介绍,分析银行客户关系管理如何将信息技术与营销战略决策充分结合,开发一套银行客户分析管理软件,通过该软件银行可以实现对客户的自动管理,并寻找出潜在的高端客户,从而提高银行盈利水平,并为银行决策者提供可靠的数据支撑。本课题使用C4.5算法实现客户分析系统的设计和开发以及通过对银行客户分析系统的各个模块的详细论述,展现出一套科学的、完整的实施流程,但鉴于主客观条件的限制,很多方面的探讨还不太深入。根据实际业务需求,本课题开发的系统能够分析客户数据信息和账务信息,进行较为复杂的数据挖掘,作出分析后提供给银行管理人员使用。目前,该系统已投入到实际业务工作中。通过实践,证明该系统设计能有效的发掘目标客户,提高了银行风险防范能力,促进银行业务发展。
[42]张丹丹.面向数据流挖掘的分类和聚类算法研究[D].导师：沈鸿.北京交通大学,2014.
关键词:数据流,分类,聚类,倾斜分布,密度网格
摘要:随着计算机软硬件技术的飞速发展以及日益大众化,各个领域的数据呈爆炸式增长,数据的广泛使用和巨大数量使得我们的时代成为真正的数据时代。通常情况下,这些数据是以数据流的形式产生和积累的。相对于传统的静态数据集,数据流具有数据量大、随时间不断发生动态变化、连续快速等特点,这就要求流入系统的数据流必须得到实时处理。因此,传统的数据挖掘算法无法直接应用于数据流之上。数据流的特点向传统的数据挖掘算法提出了严峻挑战,并对数据流挖掘算法提出了如下要求：首先,算法需要对到达系统的数据进行实时处理,因为数据流的到达速率非常快,因此,算法的时间复杂度尽量要低；再者,由于数据流的数据规模通常较大,而计算机系统内存空间有限,不可能存储全部的数据信息,因此,算法的空间复杂度要低,使得能在一个仅保存部分数据样本的受限存储空间中得到此问题的近似最优解；此外,由于数据流的流动性,到达数据会随时间不断发生变化,算法必须能够根据数据流的动态变化来自动调节自身参数设置,使自身能够适应数据流的变化。因此,如何在数据流中提取出有用的信息成为当前数据挖掘领域的研究热点和难点。本文首先对数据流挖掘的理论基础以及一些相关的主流技术进行了概述,然后从数据流分类、聚类以及频繁模式挖掘三个角度分别介绍了一些现有的数据流挖掘算法,并在此基础上分别实现了两类不平衡分布数据流的分类算法和基于密度网格的数据流聚类算法。本文具体工作如下：1.对当前基于数据流的分类算法进行了分析。针对两类数据流分布不平衡的问题和概念漂移现象,在结合当前经典的数据流分类算法和集成分类器算法的优点后,设计并实现了一种具有更好适应性的SeRt算法。实验结果表明,该算法能有效地解决两类不平衡分布问题和数据流中存在的概念漂移现象。2.在传统聚类算法K-Means、数据流聚类核心技术——CluStream框架模型以及现有的数据流聚类算法PKS-Stream的基础上,设计并实现了基于密度和网格的数据流聚类算法PKS-Stream-I。该算法是对PKS-Stream算法在密度检测周期选择,稀疏网格检测和移除方面的改进。实验结果表明,该算法相对于PKS-Stream算法具有更小的时间复杂度和空间复杂度,能够产生更好的聚类效果。
[43]刘丽娟.网络用户数据挖掘与行为分析[D].导师：沈波.北京交通大学,2014.
关键词:互联网,用户行为分析,数据挖掘,兴趣模型,网络舆论
摘要:随着互联网的不断发展和用户需求的不断提高,有关网络用户的行为分析和数据挖掘研究迅速发展起来。作为Web2.0技术的典型代表,网络论坛承担着传播信息和舆论导向的作用。因此,对论坛用户的兴趣建模和预测不仅有助于正确分析用户的兴趣所在,而且有助于向用户提供个性化服务。论坛帖子的热度预测对于提前掌握舆论动向具有重要意义。本文首先对常用的数据挖掘算法和用户兴趣模型进行简要介绍,然后对天涯论坛的用户数据集进行处理分析,设计了适合论坛的用户兴趣权重更新算法,并对用户兴趣进行有效预测,接下来分析了帖子热度的影响特征来对热门帖子进行预测。基于论坛访问时间间隔和发帖回帖数量的用户兴趣权重更新算法,建立在用户访问时间存在较大间隔的基础上,将用户的访问时间间隔和发帖回帖次数同时作为权重计算的重要变量；在兴趣预测方面,设计了一种两阶段的用户兴趣聚类算法。通过对论坛数据集进行仿真实验,验证了用户兴趣更新算法和推荐的有效性和准确性。论坛帖子热度受多方面因素的影响。根据网站用户的好友关系、关注关系、经验值等信息提取出用户性质和用户关系特征；帖子受众程度与其讨论内容有密切联系,因此帖子内容也是热度的重要影响因素；另外,帖子的发帖时间也会对其热度产生一定程度的影响。在分析帖子热度影响特征的基础上对帖子热度进行支持向量机回归,取得了满意的预测结果。最后,将用户兴趣建模和热帖预测相关算法应用到网络舆论分析中,设计了基于论坛的用户行为分析系统。系统分为数据获取、数据预处理、用户行为分析和数据存储模块,负责实现用户兴趣识别、上网时间统计、活跃用户发现、意见领袖发现和热帖预测等功能,并详细介绍了各个模块的设计,然后对系统的设计框架进行构建,作为未来系统实现的基础。论文的工作得到了国家自然科学基金(No.61172072,61271308)、北京市自然科学基金(No.4112045)、高等教育博士点基金(No.W11C100030)、北京科技计划(No.Z121100000312024)和北京市教育委员会学科建设与研究生建设项目等课题的支持。
[44]张海涛,黄慧慧,徐亮,高莎莎.隐私保护数据挖掘研究进展[J].计算机应用研究,2013, 12:3529-3535.
关键词:隐私保护数据挖掘,新型分布式系统,高维数据,时空数据
摘要:近年来隐私保护数据挖掘已经成为数据挖掘的研究热点,并取得了丰富的研究成果。但是,随着移动通信、嵌入式、定位等技术的发展与物联网、位置服务、基于位置的社交网络等应用的出现,具有个人隐私的信息内容更加丰富,利用数据挖掘工具对数据进行综合分析更容易侵犯个人隐私。针对新的应用需求,对隐私保护数据挖掘方法进行深入研究具有重要的现实意义。在分析现有的隐私保护数据挖掘方法分类与技术特点的基础上,提出现有方法并应用于新型分布式系统架构应用系统、高维数据及时空数据等领域存在的挑战性问题,并指出了今后研究的方向。
[45]郭秀娟.数据挖掘方法综述[J].吉林建筑工程学院学报,2004, 01:49-53.
关键词:数据挖掘,挖掘工具,挖掘方法,挖掘理论
摘要:数据挖掘方法结合了数据库技术、机器学习、统计学等领域的知识,从深层次挖掘有效的模式.数据挖掘技术的常见方法,关联规则、决策树、神经网络、粗糙集法、聚类方法、遗传算法和统计分析方法被应用到各个领域,数据挖掘技术具有广泛的应用前景.
[46]黄解军,万幼川.基于数据挖掘的电子商务策略[J].计算机应用与软件,2004, 07:12-13+100.
关键词:数据挖掘,电子商务,企业资源计划,客户关系管理
摘要:电子商务是新兴的现代商业模式 ,数据挖掘是先进的信息处理技术。随着商业信息和数据的急剧增加 ,如何有效地分析和利用信息成为企业共同关注的问题。本文阐述了电子商务的发展现状 ,分析了数据挖掘的功能和应用流程 ,探讨了数据挖掘技术在电子商务中市场销售、资源优化、客户管理和信用评估等领域的应用策略。
[47]张焱,欧阳一鸣,王浩,汪曦东.数据挖掘在金融领域中的应用研究[J].计算机工程与应用,2004, 18:208-211.
关键词:数据挖掘,金融犯罪,反洗钱,实时监控
摘要:论文介绍了数据挖掘的几种主流技术,并将其应用于金融领域。针对金融领域中的反洗钱活动,分析了数据挖掘技术的应用特点,提出了一个实际的应用系统原型,论证了其中的一些关键技术,并给出相关的解决方案。该系统的实现对于防范和打击金融犯罪活动,具有重要的现实意义。
[48]毕方明,张永平.数据挖掘技术研究[J].计算机工程与设计,2004, 12:2242-2244.
关键词:数据挖掘,分析,数据库,规则
摘要:数据挖掘是近年来数据库领域中出现的一个新兴研究热点。数据挖掘是对数据库数据的统计分析,其基础是人工智能。阐述了数据挖掘技术的背景,就数据挖掘的主要分析技术进行了研究和分类。介绍了目前数据挖掘常用的技术及数据挖掘过程,指出了数据挖掘技术未来的发展方向。
[49]李玲娟.数据挖掘技术在入侵检测系统中的应用研究[D].导师：王汝传.苏州大学,2008.
关键词:数据挖掘,入侵检测系统,特征选择,层次聚类,基于案例的推理
摘要:数据挖掘(Data Mining)技术是从已知数据集中挖掘有用知识的技术。近十年来的有关研究结果表明,将数据挖掘技术应用于入侵检测系统(Intrusion Detection System,IDS),对有效地进行特征选择,建立合适的检测模型,最终提高入侵检测系统的入侵检测能力,降低其误报率和漏报率有着十分重要的意义。虽然将数据挖掘技术应用于IDS时可借鉴的算法较多,但由于能适合所有情形的数据挖掘算法是不存在的,所以算法研究方面至今尚无权威性的成果;同时,很多研究过于注重理论性与技术性,忽略了所引入的数据挖掘算法的复杂度对入侵检测系统效率的影响;此外,目前成熟的IDS产品基本都采用基于规则的检测方法,这类IDS将数据包与规则库的规则进行精确匹配,如果攻击模式很常见或过于特殊,就容易产生误报或漏报,从而降低入侵检测的准确率。为此,本文以江苏省教育厅的研究项目“基于数据挖掘的入侵检测技术的研究”(02SJD520002)为背景,以适应IDS数据源特点、降低复杂度、提高效率为目标,对数据挖掘算法进行研究,包括特征选择算法、数值归约算法、聚类算法;也以增强灵活性、降低误报率和漏报率为目标,对基于数据挖掘的入侵检测方法进行研究。论文针对入侵检测系统中被检测数据的特点,提出了一种适用于IDS的多次模糊迭代特征选择算法和一种适用于IDS的基于相关性度量的特征选择算法。多次模糊迭代特征选择算法由在属性空间中搜索特征子集、评估每个候选特征子集和分类这三个步骤组成,有与之相应的搜索算法和评估函数;该算法通过多次迭代去除特征值集的冗余特征得到精确度较高的特征值集,使用模糊逻辑得到与精确度要求相应的取值范围;由于单纯对数据进行操作,该算法能更客观地分析数据;论文还基于KDD Cup 99数据集对该算法进行了仿真分析;并将实验结果与特征可视化结果进行了比较;实验结果表明该算法在IDS数据集上可取得良好的特征选择效果。基于相关性度量的特征选择算法对特征值进行模糊处理,计算特征相关性度量值,按度量值降序排列特征,再基于该特征序列进行特征选择;以分类器作为评估系统,以KDD Cup 99为数据源的仿真结果验证了该算法能在不影响效率的同时降低时间复杂度。论文还以提高IDS中分类挖掘的效率为目标,提出了一种适用于IDS中数据分类的数值归约算法,该算法一方面用值域来减少特征值数目,一方面将孤立的点放大为一个区域以预测类似行为;以KDD Cup 99数据集为数据源、以决策树分类算法为例的仿真实验结果表明,该算法能在降低已有分类算法的时间复杂度的同时使分类准确率有所提升。聚类分析常被用于IDS的入侵检测阶段。本文针对经典模糊C-均值算法FCM的缺陷,提出了一种基于层次聚类的模糊聚类算法HFC,该算法采用凝聚的层次聚类方法,快速地发现高度聚集的数据区域,并对这些高密度区域进一步分析与合并,通过评估函数的评估,找到最优的聚类方案;仿真实验结果表明,该算法具有较高的聚类精确度和较强的排除噪声的能力;论文还通过基于KDD Cup 99数据集的仿真实验,分析了该算法对IDS中入侵检测的适用性。为了提高基于规则的IDS的检测能力,论文提出了基于CBR (Case-Based Reasoning,基于案例的推理)的入侵检测方法;描述了实现CBR的步骤;给出了由规则设计和构造案例库的启发式方法;设计了适用于IDS的CBR引擎及案例匹配算法;分别通过基于Snort的规则集、自行开发的攻击平台及离线检测系统的实验和基于在线数据包的实验,验证了CBR对基于规则的IDS检测能力的增强作用。最后,总结了所做的工作,分析了存在的不足,提出了进一步研究的目标。论文对数据挖掘技术在入侵检测系统中的应用做了有益的研究。
[50]宋旭东.企业集团数据仓库系统关键技术研究[D].导师：刘晓冰.大连理工大学,2010.
关键词:数据仓库系统,统一视图模型,联机分析处理,数据挖掘,企业集团
摘要:企业集团信息化运营过程中积累了大量的设计、生产、库存、销售、采购和财务等业务数据,如何将企业集团海量业务数据转化为决策信息已成为目前企业集团信息化难点和热点问题,数据仓库系统被认为是最好的解决方案。企业集团数据仓库系统是一个复杂的系统,涉及众多复杂的概念和技术。本文就企业集团数据仓库系统中的几个关键技术进行了研究,本文的研究成果为企业集团实施数据仓库系统提供了很好的借鉴作用,有着重要的理论和现实意义。本文的主要工作如下：(1)企业集团数据仓库系统的概念及体系结构的研究。给出了企业集团数据仓库系统的定义,提出了统一视图模型的基本概念,提出了一个基于统一视图模型的数据仓库系统体系结构。(2)数据仓库系统ETL技术的研究。给出了一种新的基于统一视图模型的数据仓库ETL体系结构,提出了一种基于统一视图模型的ETL过程建模和实现方法。同时,针对数据仓库ETL任务调度问题,以数据仓库总的ETL执行时间最短为调度目标,建立了ETL任务调度模型,提出基于同层划分的遗传算法进行模型求解的算法流程。(3)企业集团数据仓库技术的研究。给出了企业集团分布式数据仓库分层结构,提出了一种面向企业集团的分布式数据仓库模型,并总结了分布式数据仓库的实施策略及其关键技术,同时将模型驱动的方法应用到数据仓库模型开发中。(4)企业集团OLAP技术的研究。将模型驱动体系架构的软件开发方法应用到OLAP开发中,该方法在数据仓库系统统一建模框架下,将OLAP设计从逻辑层提升到概念层,在概念层实现OLAP的PIM建模,通过PIM模型到PSM模型及PSM模型到SQL代码转换实现OLAP开发。(5)企业集团数据挖掘技术的研究。提出了一种基于抽样的决策树分类改进算法,使得这种算法在大数据集的情况下也能挖掘出正确的分类规则。将该算法应用到企业生产成本关键工序挖掘上,挖掘出工艺路线中的关键工序和影响钢铁企业成本的分类规则。同时,针对大数据集下的关联规则挖掘,提出了有向项集图的三叉链表式存储结构和基于有向项集图的关联规则挖掘改进算法,通过东北特钢钢企业集团的客户数据关联规则挖掘应用,挖掘出的客户的购买行为和潜在需求规律。(6)企业集团决策支持技术的研究。给出了基于分布式数据仓库的企业集团决策支持系统整体框架,通过定义决策方案层和决策任务模型层,采用分层策略,降低了决策支持系统的复杂性,采用面向对象的软构件方法,将数据和决策算法有效集成,增强了系统的重用性和扩展性。
[51]杜伟.机器学习及数据挖掘在生物信息学中的应用研究[D].导师：梁艳春.吉林大学,2011.
关键词:机器学习,数据挖掘,操纵子预测,系统发生树构建,基因芯片数据,特征选择
摘要:本文采用机器学习和数据挖掘方法,针对生物信息学中操纵子预测、系统发生树的构建和微阵列数据中特征选择等三个问题做了较为深入的研究:1.提出了一种使用神经网络作为分类器,融合基因组内基因间距离、基因的直系同源簇功能、保守基因对和基因的系统进化谱等四种信息的操纵子预测方法;2.提出了一种使用马尔科夫聚类算法的图聚类模型(OPMC)进行操纵子预测,这种模型使用基因间距离、保守基因簇、基因本体相似性和基因间序列等四种基因组通用的属性信息,并结合图聚类算法进行操纵子预测;3.提出了一种推断原核生物系统发生关系和构建系统发生树的新方法。该方法基于全基因组的连续直系同源基因信息构建系统发生树,使用连续直系同源基因的数目度量两个基因组之间的进化距离;4.提出了一种新颖的系统发生树构建方法,该方法利用多物种的全基因组信息构建原核生物系统发生树,在剔除水平基因转移事件的影响之后,根据两个物种间保守基因簇中的直系同源基因的数目计算两个基因组间的直系同源基因簇距离,从而构建系统发生树;5.提出了一种用于微阵列数据无关基因剔除的全局标准化信噪比方法(gn-SNR),该方法通过估计不同样本的全局标准化均值和标准差来剔除无关基因;6.提出了一种能够处理原始微阵列数据集中所有四种类型基因的多阶段特征选择算法。该方法在算法的不同阶段分别剔除无关基因、噪声基因和冗余基因,之后对相关的信息基因进行排序;7.提出了一种基于局部支持向量机和递归特征剔除方法的双向局部化特征选择算法CL-SVM-RFE。该算法使用局部标准化信噪比方法剔除无关基因,使用SVC-KM方法对剩余基因进行聚类并剔除冗余基因,使用一个基于局部支持向量机(Local SVM)的反向特征剔除过程选择特征基因。使用提出的方法在相关数据集上进行实验验证。实验结果表明,提出的方法对于解决相关生物信息学问题具有很好的效果,从而验证了机器学习算法和数据挖掘技术在解决生物学问题上的有效性和可行性。
[52]胡俊.数据挖掘可视化模型及其应用研究[D].导师：黄厚宽.北京交通大学,2009.
关键词:数据挖掘可视化,度量模型,可视计算,数据可视化,可视化技术,图标技术,平行坐标技术,多边形技术
摘要:数据挖掘是从大数据集中自动或方便地发现知识模式。可视化技术是一种表示数据对象的技术,在数据挖掘中主要可以应用于数据对象与数据挖掘过程可视化等方面,常常需要处理大数据集。目前,可视化技术一般是用于数据挖掘中的数据对象可视化,而数据分析方法及挖掘过程本身常常没有进行有效的可视化。可视化与数据挖掘技术之间的关系是松散的。将可视化技术应用于数据挖掘中,或者建立可视挖掘方法是有关可视化与数据挖掘的一个交叉研究课题。这种研究需要建立在合理的认知基础和依据之上。一方面需要分析研究这种方法的理论与技术基础,另一方面还需要考虑到挖掘对象的属性的可视特征与人们对可视特征的认知基础和依据。将可视化技术用于数据挖掘时主要可以考虑两个方面,一个是挖掘算法运行过程的可分性,也就是算法运行过程分解对结果不产生变异的可行性;另一个是确定算法及度量标准中的关键因素,并找出其对挖掘结果的影响。为了更好地说明多维数据的可视化效果,应该使对可视化对象的处理能够对应到对数据对象的处理,这样可以在一定程度上实现在可视化应用中引进必要的度量指标。引进合适的应用于量化的度量指标,有助于改进可视化技术,并设计适用的可视化技术的评测指标,建立实用的评测模型。基于度量指标的可视化技术在对可视对象的分析处理上可以借助适用的数学方法建模与评测,这有助于数据挖掘可视化的研究与应用。基于可视化度量指标的数据挖掘算法的应用,提供了一种可视的数据挖掘方法。在数据挖掘过程中,通过可视化技术的应用,有助于发现数据的特征。将度量指标作为一种评测指标,通过改进参数与过程,可以改进挖掘结果。本论文针对数据与数据挖掘可视化模型的形式表示、可视化技术的度量模型及其应用方法等作了研究。本论文的主要工作包括以下方面:(1)分析研究数据挖掘中可视化技术应用的特点与方法。给出了数据对象与数据挖掘过程的可视化表示的一般数学形式,即数据对象的转换模型、关联可视化模型、关联统计可视化以及过程可视化模型。(2)提出了描述数据属性间特征的影响度概念,基于图标技术,提出相应的可视化表示及可视计算方法,并将概念与方法应用于数据对象及与数据属性相关统计信息的可视化表示。实验表明,该方法用于数据可视化与数据分析是简单有效的。(3)提出了一种基于平行坐标技术的度量模型及相应的指标体系,证明了其中的相关性质与结论,形成了一套基于平行坐标技术的度量模型量化理论,并研究了度量指标在聚类分析算法K-means中的应用方法。实验表明,提出的度量模型和度量指标在数据与数据挖掘可视化应用中是有效的。(4)介绍了八叉树在数据挖掘中的运用以及设计实现的三维数据可视化平台。介绍了基于平行坐标技术的关联规则的可视化方法,以及基于多边形技术在多维数据可视化中的应用方法。
[53]储兵,吴陈,杨习贝.基于RBF神经网络与粗糙集的数据挖掘算法[J].计算机技术与发展,2013, 07:87-91.
关键词:RBF神经网络,粗糙集,数据挖掘
摘要:随着数据挖掘技术的兴起,为了提高数据挖掘的准确性,提出了很多数据挖掘算法。神经网络与粗糙集理论结合的数据挖掘算法一直是基于粗糙集理论数据挖掘研究的热点之一。文中提出利用RBF神经网络收敛速度快、泛化能力强等优势先对数据进行训练,优化数据后传递给粗糙集进行数据挖掘的新思路。并通过对比与未经过RBF神经网络训练的数据挖掘结果,发现RBF神经网络与粗糙集结合算法挖掘的精度有明显的提高,证明了RBF神经网络与粗糙集理论结合的数据挖掘算法是有效的、可行的。
[54]曾小青,徐秦,张丹,林大瀚.基于消费数据挖掘的多指标客户细分新方法[J].计算机应用研究,2013, 10:2944-2947.
关键词:客户细分,消费行为,数据挖掘,聚类
摘要:提出一种过程完整的针对消费数据挖掘的客户细分新方法。设计了包含3种类型10个指标的客户细分模型,并采用因子分析法从中提取细分变量,再使用基于划分的聚类算法进行客户细分。通过对某大型纸巾生产企业100万销售数据的计算分析,得出了有效客户类别,表明了本方法具有更强的客户细分能力和客户行为特征的解释能力。
[55]卢硕.数据仓库和数据挖掘在决策支持系统中的应用研究[D].导师：王保保.西安电子科技大学,2006.
关键词:决策支持,数据仓库,数据挖掘
摘要:随着计算机的普及和关系数据库系统的巨大成功，各种数据库系统以前所未有的速度开发出来并在各行业广泛应用，使得事务处理变得更加准确、高效，积累的数据更是以指数级的速度增长，但数据泛滥、信息贫乏仍困扰着决策者。作为新的数据库应用技术和工具，数据仓库和数据挖掘技术日益盛行并成为决策支持系统的技术支柱。本文从决策支持系统发展和需求出发，全面介绍了数据仓库设计理论和数据挖掘概念及其应用。重点讨论了数据仓库的构建和数据挖掘中的关联规则算法，并运用高校教师相关数据，初步分析了高校教师数据仓库的设计和关键技术，完成了相关主题的多维数据模型的设计，并用三种不同方法示例OLAP分析结果，特别是对MDX处理过程及扩展作了详细说明。运用Apriori算法实现基于教师素质主题数据立方体的关联规则挖掘模型的构建，通过对挖掘结果分析发现教师引进相关知识，协助决策者找到学校教师引进的决策支持信息。最后提出进一步建设基于Web的数据仓库以实时挖掘知识和支持决策。
[56]关大伟.数据挖掘中的数据预处理[D].导师：李雄飞.吉林大学,2006.
关键词:数据挖掘,数据预处理,维规约,聚集,过滤异常值,重复记录处理
摘要:随着社会的发展和数据库的应用,各领域的应用数据库中都积累了大量的历史数据。如何利用这些有潜在价值的数据,从中提取出有用的信息和知识,是应用者日益关注的问题,也是数据挖掘技术的关键所在。要进行数据挖掘,首先要保证数据质量,良好的数据能提高数据挖掘效果和效率,数据预处理逐渐成为数据挖掘不可缺少的重要前提。在数据挖掘的过程中如果只着眼于数据挖掘算法的探讨,而忽视了对数据预处理的研究,在一定程度上往往会失去数据挖掘的某些重要意义。因为实际系统中的数据一般都具有不完整性、冗余性和模糊性,很少能直接满足数据挖掘算法的要求。另外,海量的数据中无意义的成分很多,严重影响了数据挖掘算法的执行效率,而且由于其中的噪音干扰还会造成挖掘结果的偏差。因此,对不理想的原始数据进行有效的归纳和预处理,已经成为数据挖掘系统实现过程中的关键问题。本文通过对数据挖掘、数据预处理技术和理论的学习,以及对国内外数据挖掘与数据预处理系统的发展情况的研究,归纳总结了国内、外数据挖掘系统中数据预处理的特点,根据当今数据挖掘技术和数据挖掘系统的发展趋势,设计了一个数据预处理系统,该软件设计实现的预处理系统主要包括数据预处理过程中最常用、最直接、最有效的和有一定通用价值的维规约、聚集、过滤异常值、去掉重复记录处理,软件在一定程度上实现了对大量数据的清洗工作,为进一步数据挖掘提供了可靠的数据保障。
[57]周东华.数据挖掘中聚类分析的研究与应用[D].导师：梁洪峻.天津大学,2006.
关键词:数据挖掘,聚类分析,k-平均算法,DBSCAN算法,异常点
摘要:数据挖掘是目前信息领域和数据库技术的前沿研究课题,被公认为是最具发展前景的关键技术之一。数据挖掘涉及到统计学、人工智能(特别是机器学习)、模糊理论和数据库技术等多种技术,它强调的是大量数据和算法的可伸缩性,是一门很接近实用的技术,其技术含量比较高,实现难度也较大。聚类分析是数据挖掘的重要功能之一,近年来在该领域的研究取得了长足的发展,出现了许多聚类分析方法,如划分聚类方法、层次聚类方法、基于密度的聚类方法、基于网格的聚类方法、基于模型的聚类方法等。这些方法所涉及的领域几乎遍及人工智能科学的方方面面,而且在特定的领域中,特定的情形下取得了良好的效果。但是当处理数大量数据、具有复杂数据类型的数据集时,仍存在若干尚未解决的问题。本文系统地研究了数据挖掘的概念、功能、处理过程及技术算法,数据挖掘的核心技术是数据挖掘的算法,本文就数据挖掘的算法做了分析和比较,选取了K-平均算法和DBSCAN算法做了深入的研究,并给出了一种基于距离的异常数据挖掘算法。本文以山西省一所高职院校的学生成绩数据为背景,通过数据预处理工作,应用以上几种算法对上述数据进行了聚类分析,实现了可视化,最终挖掘到一定价值的信息。
[58]陈文文.图书馆使用者行为模式的数据挖掘研究[D].导师：余建桥.西南大学,2007.
关键词:数据挖掘,图书馆,行为模式,书目挖掘
摘要:在数字化的时代里，数据收集与数据挖掘，被视为是单位制订政策与决策建立时的一项具有高度参考价值的信息。图书馆经营的目的就是要能够更符合读者的需求。主动发掘读者的需求，主动提供读者所需要的信息，便是现今图书馆重要的工作项目，而图书馆自动化系统便是读者积极满足个人信息需求的行为结果，也是读者使用图书馆资源的最佳证据。对图书馆的借阅历史记录进行数据挖掘和分析，以变图书馆的被动服务为主动服务，提高图书馆在校园里的整体形象。在数据挖掘的过程中，首先要先确定研究主题，本研究是以西南大学图书馆用户，在图书馆自动化系统中的借阅记录为轴心，并加入用户的基本数据来当作挖掘时的特性区分，经过数据的整理与数据的转换，建立数据仓库。针对所建立的数据仓库，作聚类分析、分类分析与关联规则分析的数据挖掘探勘，挖掘的项目以四个维度「图书」、「读者」、「时间」、「读者单位」做交叉分析，最后所得的结果即是用户使用图书馆的一个行为模式。这些行为模式除了是直接反映出用户使用图书馆的行为模式之外，同时针对这些模式来作分析，可以提供图书馆在做经营决策时，一个重要的而且客观的参考依据，这些经营决策包含了馆藏政策、图书推荐、预算分配以及图书馆经营等工作。本论文是利用数据挖掘技术探讨读者的行为模式，以西南大学图书馆的“金盘信息管理系统”中的历史借阅记录、西南大学图书馆馆藏、读者信息库为基础数据来源，运用数据挖掘技术来探索西南大学读者的社群特性，并运用数据挖掘的成果来提升图书馆的经营与服务，期望能使西南大学图书馆在西南大学的读者学术、知识吸收和运用中扮演更积极的角色。本论文拟探索的读者社群关系包含：1．馆藏借阅的共同性：有类似兴趣的读者通常所借阅的馆藏也会很类似，如果利用数据挖掘技术把馆藏借阅的共同性找出来?2．馆藏借阅的顺序：读者借阅馆藏可能会先借入门的再借深入的，如何用数据挖掘方法把读者借阅馆藏的顺序特性找出来?。当我们挖掘出读者的社群关系后，希望能运用这些社群关系和数据挖掘的相关技术达到以下的目的：1．吸引读者到管借阅：我们发现很多读者从未借阅过馆藏，要如何增加借阅的读者人数?2．提升馆藏的借阅率：我们发现有很多馆藏是未曾或极少被借阅的，要如何才能把这些馆藏推销出去呢?3．提升读者忠诚度：我们发现有很多读者只借一、两次就不再借阅，要如何提升读者的忠诚度，使读者能够持续地借阅?4．协助馆藏副本采购：图书馆针对一本书所采购的副本数往往有限，但有些热门书读者常常要预约很久才能借到，很多甚至是借不到，很多读者因此而放弃借阅。要如何找出哪些是热门的书?哪些该多买一本?5．促进馆藏流通率：过期还书对图书馆经营来说，是一个令人棘手的工作。很多热门的馆藏往往过期才归还，其他读者要借阅预约很久才能借到。因此针对读者逾期的状况来分析，找出经常逾期还书的特殊群体，可以在事前多做预防。6．时间序列的分析：对于开管时间是利用时间序列分析，找出是否于每周、每月甚至每季、每年中读者使用图书馆的时间规律性，一旦规则可以找出，将可作为图书馆开管时间延长或缩短的参考，这样的资讯尤其在寒、暑假，将更加重要，以数据挖掘技术所得的资讯，将可水副学校决策单位提供适当的人力，同时对于图书馆工作人员也更可以接受开管的时间。
[59]马红伟.粒子群算法改进及其在数据挖掘中的应用研究[D].导师：郑向伟.山东师范大学,2014.
关键词:粒子群算法,数据挖掘,K-means聚类,教学评价,中医医案
摘要:当前，数据的急剧增长和人们对数据理解的困难形成了强烈的反差，数据挖掘技术便应运而生。聚类分析是一种最重要的数据挖掘技术，根据数据的内在特性将数据对象划分到不同的类中，使得同一类中的数据对象具有最大的相似性，而不同类中的数据对象具有最大的相异性。由MacQueen提出的K-means算法是解决聚类问题的一种经典算法，广泛应用于数据挖掘与知识发现领域。但是，K-means算法存在两大缺陷，一是K-means算法的聚类结果依赖于初始值的选取，二是基于梯度下降进行搜索常常使K-means算法陷入局部最优。在分析相关研究的基础上，提出一种基于粒子群和模拟退火(SimulatedAnnealing，SA)协同的K-means聚类算法，简称PSK-means算法，并将新改进的PSK-means算法应用在两个不同的系统中，本论文主要工作包括：(1)针对K-means算法和粒子群算法的缺陷，利用模拟退火算法的概率突跳性，提出一种基于粒子群和模拟退火协同的K-means聚类算法，克服粒子群算法易陷入局部最优的缺陷，优化全体粒子的历史最优解，进而优化聚类中心达到最优的聚类结果，并进行了仿真实验，验证算法具有良好全局收敛性。(2)将PSK-means算法应用在计算机实验辅助教学与质量评价系统中。在系统评价模块产生许多评价数据，包括对教师的评价和对学生的评价。论文以对学生的评价为例，先对评价数据进行预处理，得出学生的最终评分。再使用PSK-means算法对数据进行聚类，并对聚类结果进行具体分析。针对每一类学生在学习中存在的问题进行针对性的指导，可以大大节省时间，有效提高教学质量。(3)将PSK-means算法应用在山东省名老中医医案数据中。山东省名老中医医案系统中医案数据杂乱，包括冠心病和高血压等多种疾病。先对医案数据按疾病种类进行选择性提取，再对同一种病的药方数据使用PSK-means算法进行聚类，将药方按中医上的证型分类。聚类后的数据使用Apriori算法进行强关联规则挖掘，挖掘出不同证型的核心药方，为年轻中医医生提供学习参考，且对中成药的制作具有一定的价值。
[60]孙国萍.基于数据挖掘技术的电信客户维系系统设计与实现[D].导师：夏侯建兵.厦门大学,2014.
关键词:数据挖掘,客户关系管理,客户维系
摘要:数据挖掘是目前人工智能和数据库研究领域的一个热点问题,企业数据经过高度自动化地分析,运用归纳法进行推理,挖掘出潜在的模式,帮助决策人员调整市场策略,降低风险,做出符合市场的决策。中国通信业在经历了多次拆分重组后,打破了垄断格局,形成了三家竞争的格局。在移动通信市场竞争日益白热化的环境下,各电信运营商在积极抢夺市场份额的过程中,一方面千方百计发展新增市场,另一方面高度重视存量市场的稳定,将数据挖掘技术应用于客户关系管理,深入开展存量客户的流失预警、关怀维系及价值提升活动。本文基于对目前我国通信行业市场发展、客户维系现状以及数据挖掘技术在各领域客户关系管理中的主要应用,对某省电信运营商的客户维系现状进行了调研分析,针对企业在客户维系工作中存在的三个主要问题,即维系哪些目标客户?用什么来维系?维系的效果如何?结合实际需求,提出了基于数据挖掘技术的客户维系系统设计及实现方案,实现了客户理解功能、营销策划功能和营销评估功能等三个主要功能,并以某省电信运营商C网用户数据为例,提出了针对性营销方案,进行了效果评估。本文设计并实现的某省电信运营商客户维系系统,为企业提供了规范化和系统化的管理平台,便于管理人员更加便捷、高效、精准地进行客户数据采集与分析,锁定需要重点关怀维系的目标客户,通过管理平台较为精准地开展套餐和营销政策推荐,实现营销资源合理利用和客户忠诚度提升,为企业创造了显著的经济效益,具有较强的实际应用和推广价值。
[61]黄玲.在电子商务中应用Web数据挖掘的研究[D].导师：王树林;胡觉生.湖南大学,2014.
关键词:Web数据挖掘,电子商务,Apriori算法,推荐系统
摘要:互联网的应用使数据增长速度惊人,智能手机、平板电脑、云空间、物联网的推进,促使数据膨胀问题更加严峻。经济全球化需企业家敢于表现,吸引客户注意力,服务好客户,与客户达到互利共赢。而这表现的平台便是利用互联网的电子商务网站。可是平台里依旧有历史遗留问题,即“数据亿万万,价值找不到”。数据如同改革开放,也需要开放,即流通。流通应该顺应时代与技术发展要求,因为拒绝数据意味着拒绝财富。数据“4V”时代已经来临,即数据的“大量化(Volume)、多样化(Vaviety)、快速化(Velocity)、价值化(Value)"、门户站点商情广告、网上银行支付结算、搜索引擎社交网络等多种类型的电子商务以数据的形式正改变着人们的生活。对于激增的存储数据量,剧增的数据复杂度,数据的分析研究者们突破重重困境,找到行之可行的方法,将数据的价值挖掘出来,以帮助数据拥有者能从大量的数据中寻找某些规律性以辅助决策。这个方法便是数据挖掘技术。电子商务是未来经济发动机,在电子商务中运用数据挖掘推荐页面是企业向世界全面展示形象和产品、寻找合作伙伴和扩大销售规模的最佳途径。本文通过数据挖掘技术在新兴的电子商务推荐系统领域的应用进行了初步研究。本人主要完成如下工作：一是系统的论述了目前国内外数据挖掘、电子商务及推荐系统研究的现状。二是简述了在电子商务企业中应用Web数据挖掘技术。三是阐述了在推荐系统中运用的推荐算法与技术。四是改进推荐Apriori算法,设计了一个基于Web数据挖掘的电子商务推荐系统。推荐系统是本论文的重点。在推荐系统设计之前,先是对推荐系统进行可行性分析,然后是分三大模块对推荐系统进行设计。这三大模块分别是数据访问模块、系统架构应用模块和交互用户模块。接下来对这三大模块进行细分,详细设计了组成数据访问模块的数据收集模块和数据预处理模块,组成系统架构应用模块的OLAP系统架构模块和基于B/S服务的数据挖掘系统模块,及组成交互用户模块的在线推荐模块与模式应用模块。在系统架构应用模块中运用了改进后的Apriori算法,实现关联规则的推理,确定关联页面,形成推荐集。在用户交互模块中显示运行算法后的运行界面,展示推荐系统的个性化服务。虽然在电子商务推荐系统中运用数据挖掘技术能够为商家带来大量的经济价值和利益,但它也是一把双刃剑。商家在收集大量的数据的同时,又面临着数据处理、使用、保管和安全等方面的新挑战。如何有效保护消费者个人的隐私安全等,如何真正利用数据挖掘提升企业的价值,如何在移动互联网时代让更多的数据以非结构化的形式出现,数据挖掘发展还任重而道远。
[62]常凯.基于神经网络的数据挖掘分类算法比较和分析研究[D].导师：王爱平.安徽大学,2014.
关键词:数据挖掘,分类,人工神经网络,BP神经网络,支持向量机,极限学习机
摘要:随着信息技术的发展,人们生产数据和采集数据的能力愈来愈高,但是,我们在数据分析和知识获取方面,能力还相对滞后。因此,从收集数据、创建数据库,管理数据,到数据分析,数据挖掘技术渐渐产生和发展。数据挖掘(Data Mining, DM)是一门跨学科的课题,涉及许多领域,包括统计学(Statistics)、数据库(Database)、机器学习(Machine Learning)和人工智能(Artificial Intelligence)等。数据挖掘,也被称为数据库中的知识发现,是从“海洋般”的大量数据中获取新颖的、有用的、有效的、可理解的模式的非平凡过程,也就是从大量数据里提取知识。分类(Classification)问题是数据挖掘技术中非常重要的研究课题,利用分类技术,可以从数据集中提取出描述数据类相同的模型或函数,并且能够顺利把数据集中每一个未知类别的数据划归到某个已知的类别中去。目前,常用的数据挖掘分类算法主要有：统计分类法、决策树、人工神经网络方法等。不同的算法会产生不同的分类器,而不同的分类器又会影响数据挖掘的准确率和数据挖掘的效率。因此,当面对数据量庞大的分类问题时,选择适当的分类算法是非常有必要的。人工神经网络(Artificial Neural Network, ANN)是数据挖掘常用的方法之一,该方法通过模拟人脑生物神经网络,将若干个具有处理功能的神经元(neurone)节点,按照一定的网络结构连接起来,使它能够处理不精确数据、模糊数据或者复杂的非线性映射问题。人工神经网络能够识别的模式是由网络的连接权值、拓扑结构及神经元阈值决定的。通过优化人工神经网络的拓扑结构及网络的权值、阈值,可以达到优化人工神经网络模型的目的。本文针对实际应用中的分类问题,详细介绍了三种人工神经网络算法的网络结构和算法描述,以及三种算法的优缺点,重点阐述了极限学习机的理论基础。将极限学习机算法应用于六个真实的数据集中,实现分类应用试验,并对实验结果与支持向量机和BP算法实验结果进行比较分析。通过实验结果发现,极限学习机在分类时间和准确率等反面,均具有明显的优势。
[63]张晶晶.数据挖掘在车险客户关系管理中的应用研究[D].导师：曹妍;董乃鑫.大连海事大学,2014.
关键词:数据挖掘,客户关系管理,车险
摘要:保险行业在正常的业务处理过程中留下了大量的车险客户和产品销售等业务数据,而这海量的数据中往往存在着很多有价值的信息和规则,这些用传统的查询和分析工具往往不能识别。在行业信息化程度不断加深,企业间竞争十分剧烈的情况下,谁能充分利用这些资源,将其转化为可以指导公司决策的知识,谁就能在市场竞争中增加一分竞争力。而这一过程就需要数据挖掘技术在其中发挥重要的作用,因此研究数据挖掘技术在车险CRM中的应用成为保险行业十分关注的话题,也是本文研究的意义所在。客户关系管理在车险经营中占据重要的地位,而强有力的数据分析又是进行有效客户关系管理的基础。车险业务拥有海量的数据,既成为保险公司进行数据分析的基础,同时又为分析增大了难度,因为数据中包含着许多干扰数据需要我们识别出来并做出正确的处理。本文的工作重点就是通过对车险业务以及业务数据的理解,设计了车辆投保特征分析和车辆承保风险分析的数据挖掘模型及算法,并使用SPSS Clementine数据挖掘工具实现数据挖掘的全过程,其中数据仓库的建立、对数据挖掘算法的理解和选择、对数据进行清洗都是本文得以实现的重要过程。本文得到了有助于车险决策的一些结论,在车险营销时推荐有针对性的车险险种以及在承保时计算保费都有实际的应用。本文具有一定的参考价值,但是在实际中进行数据挖掘时,必须根据数据获取的实际情况设计属性值。
[64]陈雪萍.数据挖掘技术在高校教务管理中的应用研究[D].导师：朱新华.广西师范大学,2014.
关键词:数据挖掘,教务管理系统,关联规则,Apriori,C4.5
摘要:高校教务管理工作对高校管理是非常重要的,甚至可以说,高校的教务管理工作直接关系着高校的教学成果。高校教务管理的工作内容包括了高校管理的各个方面的工作,主要有高效的组织结构、人力资源的分配、信息控制及教务管理流程等诸多方面。伴随着全国教育的普及,高校进行了大规模地扩招,学生数量急速增长,高校学分制的订立,高校教务管理工作会更加困难和复杂。为了提高高校教务管理工作的质量和效率,国内的各大高校普遍建设了教务管理系统。本文在对国内多所高校的教务管理系统进行了研究后,从中发现这些教务管理系统总体上都有教学评价模块、网上选课模块、成绩管理模块、毕业审核模块、网上注册模块等,从功能角度讲,这些系统都已经具备了基本的功能,但在效率方面,这些已有的系统都还不够高效,另外,从决策分析上讲,这些系统都不够完善。这些不足就经常会引起了高校的教务管理工作的延迟。因此,本文重点任务是如何通过数据挖掘技术提高教务管理系统的效率。通过对数据挖掘的相关知识的深入了解及分析,本文采用数据挖掘的相关方法解决高校校务管理系统的问题,从而使得相关管理人员能够及时在复杂问题中了解到相关信息,为进一步的决策提供方案。本文的主要工作是首先研究了数据挖掘的相关理论和算法,重点对聚类算法、分类算法、关联规则进行了研究。本文努力将数据挖掘的相关算法在数据处理方面的优势充分利用到高校教务管理系统中的海量数据进行分析,从而发挥了数据挖掘的优势,在高校教务管理中的数据支持下发现问题和规律来,最终为教务管理工作服务,在此基础上实现了教务管理系统中的数据分析功能。并且在对高校的学生信息的管理中,使用数据挖掘的工具,设计和实现了能够挖掘出培养新一代学生的管理系统。教务管理系统中高校课程成绩对培养优秀人才有着重要的意义。所以,在高校课程成绩的数据挖掘是非常重要的。在本文实现的教务管理系统中,针对课程的三次考试成绩进行数据挖掘以分析学生在每张试卷各个知识点中的掌握情况进而建立一个分类模型,最后将该分类模型应用于新生的课程模拟考试中。并可以依据学生掌握知识点情况来对新生因材施教,从而达到更有效的提高该门课程的教学质量。本文最后完成了高校教务管理系统的构建工作,结合C/S和B/S模式的优点,该系统的体系结构将使用C/S和B/S混合的模式,这种混合的结构不但能够提升高校教务管理系统的决策水平,还能最大限度地利用高校内部的各类资源,从而达到建设一个现代化的高科技的校园环境。本文还将经典的APriori算法用于教务管理系统中,从而为合理地安排高校众多教师、课程和教室的先后次序提供了根据。重点分析了教务管理系统中高校课程成绩的数据挖掘过程。当今,高校教务管理系统的应用是非常重要的,因此本课题有着非常重大的应用意义。本文通过使用数据挖掘方法改进高校教务管理系统,提高了高校的校务管理的决策能力。通过对数据挖掘技术在高校教务管理中的实践,从而也对数据挖掘进行了更深入的探索。
[65]颜雪松,李宏,王欣.用SQL Server2000构建数据挖掘解决方案[J].计算机与现代化,2001, 05:26-31.
关键词:数据挖掘,联机分析处理,数据转换服务,分析服务
摘要:Microsoft的 SQL Server 2 0 0 0第一次包含了数据挖掘特性。 Microsoft的数据挖掘解决方案是基于针对指定的数据挖掘的 OL E DB上的。OL E DB是 Microsoft制定的工业标准并被一系列数据挖掘 ISV所支持。这种指定为数据挖掘提出了一种新的类 SQL 语言 ,这种语言使数据库开发者能更好地建立数据挖掘的应用。本文给出了一个关于运用 SQL Server 2 0 0 0构建数据挖掘应用的示例。
[66]糜元根.数据挖掘方法的评述[J].南京化工大学学报(自然科学版),2001, 05:105-110.
关键词:数据挖掘,神经网络,决策树,粗集,遗传算法,云模型
摘要:决策离不开知识 ,从数据库中采掘知识 ,是解决从大信息量中获取有用知识的有效途径。但是在实际数据库中 ,数据的复杂性 (如信息量大、噪声等 )对数据挖掘方法提出了比机器学习更高的要求 ,这方面的研究正受到越来越多的关注。本文就当前数据挖掘的几种主要方法 ,即神经网络、决策树、粗集和云模型等方法的研究现状进行了评述 ,指出其存在的问题。从总体上看 ,这些方法都有局限性 ,但它们的有机组合具有互补性 ,多方法融合将成为数据挖掘的发展趋势 ,最后指出数据挖掘方法面临的挑战
[67]杜鷁,李德毅.一种测试数据挖掘算法的数据源生成方法[J].计算机研究与发展,2000, 07:776-782.
关键词:数据挖掘,云模型,云发生器
摘要:随着数字时代的来临 ,数据挖掘成为知识领域中的研究热点 .但由于保密、数据多样性等问题 ,测试数据源的获取一直困扰着数据挖掘算法的研究 .为此 ,提出一种基于云模型的测试数据源生成方法 ,利用此方法 ,给出了数量型数据的生成算法 ,对范畴型数据的生成进行了讨论 .由于云模型中随机性与模糊性的特点 ,各属性的数据之间除了包含已知的先验知识以外 ,数据的分布、各属性之间的关系也会存在一定的随机和模糊 ,使得构造的数据源中又隐含了许多潜在知识 .利用此方法 ,研究人员可根据自己的实际情况进行不同类型、不同量级数据源的构造 ,加速数据挖掘算法的研究进程
[68]赵丹群.数据挖掘:原理、方法及其应用[J].现代图书情报技术,2000, 06:41-44.
关键词:数据挖掘,数据采掘,知识发现,KDD
摘要:数据挖掘是当前数据库和信息决策领域的最前沿研究方向之一。首先介绍了数据挖掘的基本概念和处理过程 ,然后分别分析了数据挖掘所发现的主要知识类型和使用的技术方法 ,最后对基于 Web的几个数据挖掘应用系统进行了较为细致的剖析 ,并指出数据挖掘技术和搜索引擎技术的结合对网络信息的发现、搜集和管理、利用具有巨大的发展前景
[69]余英泽,廖里,吴渝.一种新型数据分析技术——数据挖掘[J].计算机与现代化,2000, 01:27-31.
关键词:数据挖掘,数据仓库,知识发现
摘要:首先介绍了数据挖掘的体系结构 ,并在此基础上提出了数据挖掘工程的一般方法和步骤 ,最后介绍了数据挖掘的应用前景
[70]邓博.基于数据挖掘技术构建电信4G客户预测模型的研究[D].导师：张瑞生.兰州大学,2015.
关键词:数据挖掘,电信大数据,4G客户预测模型,决策树算法,Logistic回归,SVM算法,Hadoop
摘要:2013年12月,中国正式进入4G时代。与此同时,运营商之间的4G客户竞争也进入白热化阶段。随着数据挖掘技术的广泛应用和运营商积累的越来越多的数据,如何利用数据挖掘技术手段处理电信大数据,受到越来愈多人的关注与研究。4G时代,针对电信业客户关系管理的需要,在现有的数据仓库技术和数据挖掘技术基础上,帮助运营商找出潜在的4G客户,扩大其市场占有份额,对电信运营商来讲具有很重大的现实意义和经济效益。本文研究的4G客户预测问题正是在这样一个时代背景下旨在为扩大运营商的4G客户规模而提出的。本文所采用的数据集来自于某电信公司。最主要的目标是建立一个准确率高的、实用性强的电信4G客户预测模型。模型的建立以数据挖掘的CRISP-DM方法论为基础。首先,在模型构建的准备阶段,本文对原始的电信数据进行了集成、清洗、规约、转换、分割等一系列的数据预处理工作,初步筛选并构建了模型的预测指标体系。然后,建立决策树、Logistics回归、SVM这三种4G客户预测模型,经过多次的模型训练与对比,最终选择出效果最好的决策树模型应用于电信4G客户预测。在模型应用阶段,参照预测模型计算出的所有客户得分情况,重点关注的对象是那些得分较高的客户,对这部分潜在的4G客户进行有针对性的业务推广和精确营销,从而达到扩大4G客户规模的目的。最后,本文还搭建了一个具有9个节点的Hadoop集群,实现了决策树C4.5算法的并行化,有效地解决了单机无法处理大规模数据的问题,验证了Hadoop平台在处理电信大数据方面的高效性与可扩展性。本文是把数据挖掘理论和实际项目相结合一个典型案例,利用数据挖掘的相关技术建立了电信4G客户预测模型。结果表明,所建立的模型是基本符合电信实际需求的,能够提供有价值的预测信息给相关的决策人员和市场营销人员,对电信运营商扩大4G客户规模具有重大的现实意义。
[71]刘欢.数据挖掘在淘宝客户评价方面的研究与应用[D].导师：张景祥.济南大学,2014.
关键词:数据挖掘,关联规则,文本分析,分词,词频统计
摘要:数据挖掘（Data Mining，简称DM）主要是将众多的、冗杂的、存储在数据库中的数据转化成对人们有使用意义的信息的一系列过程。这些潜藏在数据中的信息大多是不可预测的。DM的聚类算法、分类算法、关联规则等算法在各个领域得到广泛应用，例如本文所提到的在电子商务、教育系统、医学领域中的应用。近些年，将DM技术应用到电子商务领域是倍受大家关注的一个研究方向。这也是本文选取数据挖掘在淘宝客户评价方面的研究与应用为题的原因。课题中主要运用到数据挖掘技术中的关联规则挖掘找出淘宝客户评价中描述产品属性的特征词。本文首先分析淘宝网信誉评价体系特点，了解其评价指标以及每个指标具有的实时性和评分标准，以及店铺综合评分的评判指标和评分计算方法。随后从淘宝网用户具体评价入手，利用ICTCLAS汉语分词系统对SQL Server数据库中的用户评价进行逐句分词处理。随即，运用关联规则挖掘算法找出客户评价中描述产品特性的词汇，并提取出与该产品特性词汇相关联的观点词以及观点词的极性。最后，统计出客户对产品以及与产品相关的服务的满意度，为管理者和经营者提供真实可靠的宝贵信息。客户在评价中提到的描述产品特性的高频词汇可视为客户比较在乎的产品属性，对于经销商来说极具有参考价值。同时这也描述产品特性的词汇也是潜在客户比较关注的方面，可以提高客户购买效率也防止电子商务平台的营销欺骗。在本文的最后一章，我们依据以上几章的理论基础和实际考察。选取Visual Studio（简称VS）作为开发环境，C#语言作为开发语言，在winForm中建造UI界面，对于用户来说具有较强的可用性，系统操作简单，且方便易懂。在系统实现的整个过程中，全方位考虑系统的可用性，整个系统分为五个模块：旗舰店信誉提取、客户评价提取、评价文本分析、分析结果展示和旗舰店信用对比。文本分析模块将分类算法与关联规则算法相结合，找出最优分词和词性标注算法，提高系统的准确率。分析结果展示又分为两个模块，来提高软件的可靠性。在本文最后，文本做出总结并对数据挖掘技术和电子商务的发展做出展望。
[72]张伟,杨炳儒,宋威.多关系数据挖掘研究综述[J].计算机工程与应用,2006, 02:1-6.
关键词:多关系数据挖掘,归纳逻辑程序设计,多关系决策树,关系距离测度,多关系关联规则,统计关系学习
摘要:多关系数据挖掘是近年来快速发展的重要的数据挖掘领域之一。传统的数据挖掘方法只能完成单一关系中的模式发现,多关系数据挖掘能够从复杂结构化数据中发现涉及多个关系的复杂模式。该文综述了多关系数据挖掘的研究状况。首先分析了多关系数据挖掘领域发生的原因和背景,其次总结了多关系数据挖掘研究的一般方法,然后介绍、分析了最具代表性的多关系数据挖掘算法。最后,总结了多关系数据挖掘将来发展需重点解决的问题和面临的挑战。
[73]李志明,胡森树.数据挖掘及其在现代化图书馆中的应用[J].图书馆学研究,2006, 06:39-41.
关键词:数据挖掘,图书馆,信息服务
摘要:数据挖掘技术是一种新兴的信息处理技术,在信息的利用和提取中发挥着日益重要的作用。本文介绍了数据挖掘的概念、功能和分类,在此基础上列举了数据挖掘技术在图书馆信息采集、信息咨询、个性化服务、读者导读、书库管理、数字图书馆建设中的应用。
[74]贾俊杰.基于关联规则的数据挖掘算法研究[D].导师：王治和.西北师范大学,2005.
关键词:数据挖掘,关联规则,事务树,事务规则树
摘要:关联规则揭示项集间有趣的相联关系,可广泛应用于购物篮分析、相关分析、分类、网络个性化服务等领域,是数据挖掘的重要研究课题。自1993年R.Agrawal,R.srikant首次提出该问题以来,已出现了许多关联规则挖掘算法。这些算法大多基于Apriori算法,在挖掘频繁模式时需要产生大量候选项集,多次扫描数据库,时空复杂度过高。本文提出的第一种频繁集挖掘算法—Suppoqui算法,扫描1遍数据库,查找出频繁1-项集,然后只扫描1遍最大频繁集长度的结点集合,就可查找出所有的无冗余的频繁集。传统的关联规则挖掘都是基于频繁集来进行的,往往生成过多的规则,使用户很难进行取舍。为此,本文又提出了第二种关联规则挖掘算法—SG算法,SG算法避开了频繁集的求解而直接挖掘出无冗余的关联规则。与基于Apriori算法的传统算法相比,Suppoqui算法和SG算法无论从时间上还是从空间上来说都以数量级减少,因此都是高效、可行的。
[75]曹煜.高校教学质量测评系统的开发及数据仓库与数据挖掘技术在其中的应用[D].导师：许宝栋.东北大学,2005.
关键词:数据仓库,教学质量测评,联机分析OLAP,数据挖掘,Apriori算法
摘要:基于对教学质量的重视,以充分利用教学资源、调动教师积极性、制订合理的教学改革措施为出发点,首钢工学院提出,利用校园网和现有的教学基础数据,建立一个较为完善的、网络化、信息化程度较高、具备综合分析、辅助决策支持的教学质量综合评价系统,适应社会对优质教育资源的需求。本学位论文对现行的高校教学质量评价工作进行了调查分析,并在首钢工学院进行了实际评价调查,获得了第一手的数据和相关信息。针对目前教学质量测评中需要解决的实际问题,首先实现了客户机/服务器(C/S)系统下的学生测评和数据处理。该软件系统已安装在首钢工学院教务处教学督导室,并连续使用了两个学期。在首钢工学院教学测评活动中,发挥了很好的作用,也积累了一定量的基础数据。本文从理论上研究了在积累了大量的原始数据后,如何实现基于Web的数据仓库,给教学质量测评系统添加辅助决策的功能。较为深入地研究了实现此功能所面临的主要技术问题:数据仓库数据建模技术、基于Web的数据仓库应用系统的实现方法、系统的体系结构、数据装载和控制机制、OLAP分析、数据挖掘算法、预测模型等。建立了数据仓库的主题域,设计了相关的维度、指标。通过分析教学测评管理系统中的数据结构,确定了教学测评数据仓库的雪花型数据模型和维表、各个事实表的结构组成。根据目前基础数据的情况,提出采用基于关系型数据库的ROLAP方法,实现对数据仓库多维数据的访问。研究了教学测评管理软件和校园网的架构,确定了基于Web的教学测评数据仓库应用系统的实现方法,充分合理地利用现有的网络环境和历史数据资源。本文特别对教学测评系统中教师工作量与教学效果之间的关联提出了一种基于SQL SERVER数据库管理系统的Aptiori算法,以提高算法执行速度和效率。
[76]张慧萍.数据挖掘技术与应用研究[D].导师：程耕国.武汉科技大学,2005.
关键词:数据挖掘,关联规则,FP-growth算法,频繁项集
摘要:本课题旨在研究数据挖掘技术及其应用,包括对数据挖掘算法的理论研究及数据挖掘技术的应用研究等内容。数据挖掘是兴起于九十年代的一项用于决策支持的新技术。作为数据库中知识发现的一个重要步骤,它主要对数据进行微观、中观乃至宏观的统计、分析、综合和推理,以指导实际问题的求解,企图发现事件间的相互关联,甚至利用已有的数据对未来的活动进行预测。数据挖掘是一门广义的交叉学科,涉及数据库、人工智能、数理统计、并行计算等多方面的知识,由于数据挖掘算法的好坏直接影响到所发现知识的质量,因此挖掘算法是数据挖掘的一个研究重点。本文首先对数据挖掘的概念及应用进行了较详尽的阐述,然后重点研究分析数据挖掘的一个重要方面一一关联规则挖掘,对其概念、算法进行了分析,并且着重研究了FP-growth算法。最后本文具体分析了一个数据挖掘在房地产行业中的应用实例来说明数据挖掘的应用过程。在课题的研究过程中,我通过阅读大量国内外著作、论文,对数据挖掘技术的理论和应用有了一个较为全面的了解,在理论上对关联规则的挖掘算法进行了深入的研究;对于数据挖掘的应用通过实现具体的实例进行研究,并且对挖掘结果进行评价,从而对数据挖掘的应用步骤有了更加深刻的理解。数据挖掘是一种基于应用的技术,因此很多知识和经验还需要我们在实践中进一步总结和发现。
[77]周艳山.数据挖掘中关联规则算法的研究及应用[D].导师：滕春贤.哈尔滨理工大学,2005.
关键词:数据挖掘,关联规则,Apriori 算法
摘要:近年来,数据挖掘己经引起了信息产业界的极大关注,这是快速增长的数据量和日益贫乏的信息量之间矛盾运动的必然结果,对数据挖掘技术进行系统、深入、全面、详尽地研究是全球信息化发展的客观需要。本文对数据挖掘技术,尤其是关联规则数据挖掘技术进行了系统、深入、全面、详尽地分析和研究,主要包括以下一些内容:数据挖掘技术的分析与研究。对数据挖掘技术的国内外研究现状进行了广泛而全面地归纳、分析和研究,对数据挖掘技术的未来发展趋势和热点研究领域进行了总结和探讨,对数据挖掘的定义及定位进行了简要的回顾,在数据挖掘基本概念的基础上,对数据挖掘常使用的技术和研究的对象进行了详细地分类、归纳和总结。为本文的全面展开奠定了基础。关联规则数据挖掘技术的分析与研究。在介绍关联规则基本概念的基础上,对关联规则的Apriori 算法进行了详细地分析和研究,并就目前针对提高该算法效率的各种优化技术也进行了详细地描述,在此基础上提出了基于筛选压缩的Apriori 挖掘算法。并进行了模拟实验,比较结果显示基于筛选压缩的Apriori挖掘算法极大的提高了效率。
[78]丁元明.数据挖掘技术在高校教学质量评估中的应用研究[D].导师：吉根林.华东师范大学,2006.
关键词:数据挖掘,决策树,关联规则,数据仓库
摘要:本文介绍了数据挖掘的相关概念,探讨了数据挖掘技术及其挖掘算法,重点研究决策树方法及其改进算法、关联规则挖掘算法及其在教学质量评估系统中的应用。通过对南京财经大学本科生的评教数据和部分教师的档案数据进行数据挖掘,利用关联规则挖掘算法挖掘影响教学质量的关键因素,并对挖掘结果进行了分析,验证其有效性。本文结合教学质量评估中的实际数据,研究分析了决策树方法中ID3算法的实现过程。对于关联规则挖掘算法中的经典算法——Apriori算法进行了详细描述,给出了全部伪代码。结合参考文献给出的生成关联规则的方法以及由频繁k-1项集生成候选k项集的方法,提出了首先生成规则的前件再去找出规则的后件、从而生成相应的关联规则的算法,并在教学质量评估数据挖掘模块中成功实现了该算法。本文探讨了教学质量评估数据挖掘系统的实现方法,给出了基于SQL Server的两种数据挖掘的解决方案。第一种方案,将原始数据经过清理后导入SQL Server 2000,构建相应的数据仓库,然后调用SQL Server分析服务模块所提供的数据挖掘算法来构建数据挖掘模型。第二种方案,采用VB6.0编制实现Apriori算法的数据挖掘模块,数据源与挖掘结果均保存在SQL Server中。该数据挖掘模块既可单独被用户调用,也可以通过修改注册表的方法,将其外挂于SQL Server中,与SQL Server分析服务模块一起供用户直接调用。南京财经大学教学质量评估系统目前正处于开发调试中,学生网上评教系统是其主要的子系统,学生将通过校园网对各任课教师的教学质量进行评价。作为教学质量评估系统的另一子系统——教学质量评估数据挖掘系统,其主要功能是对学生的评教数据及教师档案数据进行数据挖掘工作,采用数据仓库作为学生评教数据的组织工具,使用决策树方法和关联规则算法进行数据挖掘。本文给出了教学质量评估数据挖掘系统的软件框架,并使用相关数据进行了关联规则算法的实验,对结果进行了初步分析。
[79]曹丹阳.数据挖掘在教务系统中的应用研究[D].导师：李晋宏.北方工业大学,2006.
关键词:数据挖掘,数据仓库,决策树,聚类分析,教务系统
摘要:数据仓库和数据挖掘是数据库研究、开发和应用最活跃的分支之一,也是决策支持系统的关键因素,数据仓库是一个支持管理决策过程的、面向主题的、随时间而变的数据集合,它是集成的,也是稳定的。数据挖掘是采用人工智能的方法对数据库和数据仓库中的数据进行分析、获取知识的过程。它们的结合能更好地为企业或有关部门不同范围的决策分析提供有力的依据。纵观以往的教学管理系统,多半是OLTP系统,缺乏综合分析、辅助决策的能力;并且对其历史积累的海量信息中隐含知识的利用无能为力。对教学管理进行分析是教学评估的重要手段,采用数据挖掘技术对教务数据进行多层次、多角度的分析与挖掘,利用挖掘结果辅助教学决策是保证教学质量、提高学生素质的必然要求。本文主要探讨了基于数据仓库的数据挖掘技术的基本理论和实施方法,探索了数据挖掘分类方法和聚类方法。结合教务系统,改进分类方法中的决策树算法并应用于英语四级成绩分析,实现聚类方法中的K-平均算法和k-中心点算法并应用于学生毕业情况分析,从而实现了基于教务的数据挖掘系统。本文首先从决策分析需求出发构建教务系统数据仓库;接着对数据进行预处理并改进概念分层方法,使概念分层更适合教务系统数据挖掘;而后对预处理后的数据以图、表的形式分析统计;最后利用改进的数据挖掘算法对数据进行挖掘,得出有效结果并运用于实践中。通过在教务系统中的具体挖掘实践,得到了许多有价值的信息,这些知识在帮助学校更好地进行学生的培养,对学生表现情况的掌握以及课程的安排等方面无疑具有重要的指导意义。
[80]方洪鹰.数据挖掘中数据预处理的方法研究[D].导师：张俊容.西南大学,2009.
关键词:数据挖掘,数据预处理,统计方法,非线性相关分析
摘要:在现代的科研和实际工作中,各行各业都需要对采集到的各种各样的数据进行处理。如何从这些海量的数据之中发现更深层次、更重要的信息,使之能够描述数据的整体特征,可以预测发展趋势,从而生成决策。这就需要进行数据挖掘。数据挖掘与知识发现过程中的第一个步骤就是数据预处理。统计发现,在数据挖掘与知识发现的过程中,数据预处理占到了整个工作量的60%。因为现实世界的数据往往是不完整的、含噪声的和不一致的,数据预处理能有效提高数据质量,为数据挖掘内核提供更有针对性的可用数据,不仅可以节约大量的时间和空间,而且得到的挖掘结果能更好地起到决策和预测作用。目前数据预处理的常用步骤包括:数据清理、数据集成、数据变换以及数据归约。本文总结了目前数据预处理的常刚方法,并对其分析和思考。发现有些方法可以在数据预处理的不同阶段使用,分别达到相应阶段的预处理效果。在预处理中用到了许多的统计方法,但需要与实际的数据特征和专业知识相结合才能有效地应用。强调了在预处理的每一个步骤都要与专业知识和实际应用相结合。考虑到若在数据获得初期就有一定的指导,可以减少数据获取的盲目性以及不必要的噪声引入,且为后期的工作节约大量的时间和空间,因此认为应该把数据源的获取作为预处理的一个步骤。在预处理的实际应用过程中,上述步骤并不是相互独立的,而是相关联的,因而提倡对数据预处理采取循环的模式。最后针对银行房贷信用风险评估课题中所遇到的数据预处理问题,结合数据特征,考虑到与之相关的各个因素的内在相关性,使用一种基于全局的非线性相关分析技术,这是一种统计方法,来对该问题进行讨论,并且实证研究。
[81]张立美.基于数据挖掘的电信客户细分模型的研究与应用[D].导师：李毅;牟向峰.电子科技大学,2010.
关键词:数据挖掘,聚类分析,客户关系管理系统,客户细分
摘要:数据挖掘也称为数据库中的知识发现(KDD:Knowledge Discovery in Databases)。用数据库来存储数据,用机器学习的方法来分析数据,挖掘大量数据背后的知识,这两者的结合促成了数据挖掘的产生。目前数据挖掘逐渐发展成为一个多学科领域,涉及到多方面的技术,特别是和计算智能方法的结合越来越紧密。客户关系管理是一种新型管理方法,其重点是改善企业与客户的关系。随着电信行业的竞争日益激烈,电信运营商先后实现战略转型,纷纷引入客户关系管理理念,提高企业的竞争力。客户细分是有效运行CRM的基础,对客户进行合理细分,提供个性化、差异化服务,提高企业的竞争力。本文针对基于数据挖掘的客户关系管理系统中的客户细分,做了如下的工作:文章的绪论部分主要介绍了数据挖掘的基本理念,对数据挖掘技术的发展前景进行了展望,介绍了客户关系管理系统的国内外及淄博市张店区现状,介绍了论文的主要研究内容及论文的整体组织结构。本文第二章主要介绍了论文中实例研究所用到的关键技术,介绍了数据挖掘的功能、典型工具和常用分类,介绍了数据挖掘中的聚类分析算法,介绍了客户关系管理系统的主要内容。本文的案例实施要根据需求进行,因此在第三章对案例的需求分析进行了详细的介绍。本文的第四章和第五章主要介绍了数据挖掘在电信行业CRM中的主要应用,介绍了数据挖掘的工作流程,并以山东淄博张店区移动分公司的实际项目为依托,按照数据挖掘的基本流程,进行总体设计。在详细设计部分主要工作是提出了一种新的客户分群方法,创建了基于聚类分析的客户细分模型,并对模型进行了有效评估,根据分析结果,制定相应的推广计划和营销策略。本文最后讨论了数据挖掘的发展状况和进一步的研究方向。
[82]王丽娜.基于粗糙集的数据挖掘改进的属性约简算法研究[D].导师：祝峰.电子科技大学,2012.
关键词:数据挖掘,粗糙集,属性约简
摘要:目前数据挖掘的方法有很多，本文主要研究了数据挖掘中的粗糙集方法，重点研究了基于粗糙集的属性约简算法在数据挖掘规则提取阶段的应用。粗糙集在数据挖掘中通常被用于知识的约简，从而进行规则的提取。属性约简是粗糙集理论研究的核心内容之一。本文对传统的基于粗糙集的属性约简算法深入研究的同时进行了改进，并针对大规模数据集的数据挖掘，提出了一种新的属性约简算法。粗糙集理论是一种新的处理模糊和不精确问题的重要数学工具，是一种新的数据挖掘技术。传统的属性约简算法要么空间复杂度比较高，要么约简不够精确，本文提出的新的属性约简算法很好的解决了空间复杂度的问题，适合对数据挖掘中的大表、大文件进行约简，从而得出具体的规则，这是传统的属性约简算法不能做到的。本文的主要研究内容如下：（1）对基于粗糙集的数据挖掘研究现状进行了分析；深入研究了粗糙集相关理论知识和数据挖掘相关技术；将粗糙集与数据挖掘相结合，着重研究了基于粗糙集的数据挖掘模型，对粗糙集在数据挖掘中的应用进行了系统分析。（2）对几种传统的基于粗糙集的属性约简算法进行了深入研究，并分析其各自的优缺点。在此基础上，提出了一种改进的基于差别矩阵的属性约简算法，并通过实验验证其有效性。（3）针对传统属性约简算法在应用中暴露出的问题，本文借助数据结构中的树型结构建立了多叉树理论，并在此基础上提出了一种新的基于多叉树的属性约简算法。该算法相对于传统属性约简算法来说空间复杂度较低，适合对数据挖掘中的大表、大文件进行约简，从而得出具体的规则，较传统的属性约简算法有很大优势。（4）在UCI中选取三个不同规模的数据集作为测试训练集，通过对两个对比算法进行详细的仿真实验，验证了基于多叉树算法的可行性和有效性。
[83]卢明泰.WEB数据挖掘及其在社交网络的应用研究[D].导师：刘贵松.电子科技大学,2012.
关键词:WEB数据挖掘,社交网络,标签,内容挖掘,数据预处理
摘要:随着WEB2.0技术的不断发展和成熟，互联网已经变得越来越智能化人性化和社会化它开始逐渐渗透到人们生活的方方面面，影响并改变着人们的生活方式作为WEB2.0时代的代表性产品——社交网络已经以迅雷不及掩耳之势席卷了全球社交网络平台上用户的交互信息开始呈现出爆发式的增长趋势然而，人们却面临着信息爆炸但是智慧贫瘠的尴尬局面[1]互联网WEB2.0时代的核心概念便是以用户为中心，重视用户体验和用户交互因此，如何有效地收集和利用社交网络平台上海量的用户交互信息，并从中挖掘出有价值的知识，以此来提高社交网络的用户体验，成为了互联网行业研究和讨论的热点为了提高社交网络海量用户交互数据的使用率，本文尝试性地将WEB数据挖掘技术引入到社交网络的应用中去通过对WEB数据挖掘技术社交网络特性以及个人标签云的相关理论的深入研究和探索，创新性地提出了基于社交网络平台的个人标签云的概念，并设计和实现了社交网络个人标签云系统本文的主要工作包括以下两个方面：第一理论研究部分，首先详细的分析了数据挖掘和WEB数据挖掘的相关理论，总结了当前它们的主要技术分类数据源功能处理流程以及面临的关键问题等，为后文在实践中使用WEB数据挖掘打下了很好的技术理论基础其次细致地概括和研究了社交网络的相关特性，分析了社交网络的组成元素主要内容结构表达方式主要特点和功能等帮助我们全面地了解到了社交网络的发展状况体系结构用户需求模型以及面临的主要问题为后文开发基于社交网络的个人标签云提供了很好的平台理论基础第二实践研究部分，主要体现在设计和实现了基于社交网络的个人标签云系统首先深入地研究并设计了社交网络数据预处理的方法，主要分成日志预处理和文本内容预处理两部分来进行详细说明，为后文文本挖掘提供了高质量的数据源其次分步骤细致地介绍了个人标签云的设计与实现，并总结了创建基于社交网络的个人标签云的现实意义，为未来的研究工作指明了方向
[84]朱博雅.一种基于数据挖掘的量化投资系统的设计与实现[D].导师：汪卫.复旦大学,2012.
关键词:量化投资,数据挖掘,金融市场,交易序列,计算机软件,自动交易
摘要:量化投资产生于1970年代末,在此后的30多年中,其得到了长足的发展。根据Bloomberg数据统计,从1998年至2008年,全球量化基金从21只发展到1184只。全球范围内,越来越多的投资者进入量化投资这个领域,量化投资已经成为一种主流的投资方式。当前,只要是对金融产品买卖投资行为的一个环节以上使用了量化技术(采用模型化、模式化、算法化、计算机程序化、自动化之一)就认为是量化投资了。因此在市场上有各种量化投资的说法,包括：量化选择金融产品、量化选择交易时间、算法交易、自动套利交易等等。相对于传统采用抽样技术建立数学模型的方法,数据挖掘技术更能反映具体金融产品交易的规律。针对金融产品投资的几个环节(研究市场和金融产品信息、研究该金融产品的历史交易、研究当前交易情况、预测未来交易、做出投资决定(买、卖、不行动)、分析交易效果),本文研究采用数据挖掘技术实现量化投资的方法,包括金融产品历史交易规律分析、交易序列模式库建设、产品交易价格的发展趋势预测、下单交易策略实现等金融产品投资主要环节的量化工作。本文的主要研发成果为：设计了一种基于数据挖掘的量化投资软件的框架,包括金融产品历史交易数据整合与挖掘、交易模式挖掘和模式库管理、产品交易价格预测与交易决定以及自动下单交易策略等内容,系统地实现了金融产品投资主要环节的量化工作。在原子交易模式的基础上,设计了TOP-K原子交易模式数据挖掘程序,设计实现了基于交易模式的金融产品聚类算法,实现了一种自动下单交易的方法,开发了一个基于数据挖掘技术的量化投资系统。
[85]陈伟莲.基于数据挖掘技术的某学院成绩分析应用[D].导师：黄翰;杨卫峰.华南理工大学,2012.
关键词:学生成绩分析,数据挖掘,基于关联规则的算法
摘要:高职院校为适应规模发展以及信息技术的进步，纷纷建起自已的学生成绩管理系统，系统的应用逐步提高了教学及管理的水平并且积累了大量的学生成绩数据。但是，目前这些系统多半是参与事务处理，基本缺乏综合分析和辅助决策能力，更不能对积存的数据进行归纳与深层次挖掘，使得管理人员在决策时缺少切实的数据支持，而数据仓库和数据挖掘技术的结合为学生成绩分析提供了必要的技术手段。为此，本文是在搜集并深入了解了大量的数据仓库和有关的数据挖掘的相关文献基础上，探讨了数据仓库和数据挖掘的基本理论和方法，运用数据挖掘的相关技术（如关联规则、决策树等），结合成绩管理中积累的大量数据，通过构建实用数据仓库并采用数据挖掘技术，构建了一个学生成绩数据挖掘模型，在此模型基础上，初步对学生成绩数据进行一次多层次的、多角度的分析和挖掘。经测试，在应用学生成绩挖掘模型的具体实践中，得到了一些有价值的信息，这些信息对学校学生理解课程发展的知识程度和课程需要加强开发提供指导和分析，假设相同一致的课程，教师可以了解什么知识点用怎么样的问题考核，分析了影响程度的知识点互相联系，在不同的课程之间，可以知道相互联系课程之间的影响程度，以及不同的知识点和不同的课题在不同技术职务的教师取得的不同的教学效果等。从而使学校更好地利用挖掘结果来辅助教学决策，从而促进教学质量提高、学生素质提升。
[86]段录平.基于RBF神经网络的数据挖掘研究[D].导师：周丽娟.哈尔滨理工大学,2007.
关键词:数据挖掘,RBF神经网络,分类,聚类
摘要:随着数据库技术的成熟应用和Internet的迅速发展,人们利用信息技术生产和搜集数据的能力大幅度提高,使得从大量数据中挖掘出有用的信息或知识成为一个迫切需要解决的问题。正是这种需求推动了数据挖掘兴起和数据挖掘技术的发展。数据挖掘经常要面对一些有噪声、杂乱、非线性的数据,而神经网络具有良好的鲁棒性、自适应性、并行处理、分布存储和高度容错性等特点,因此神经网络非常适合用来解决数据挖掘的一些问题。本文简单阐述了数据挖掘和人工神经网络的基本理论。在分析数据挖掘各种技术的基础上,对神经网络方法在数据挖掘中的应用进行了研究分析,接着着重研究了基于RBF神经网络的分类数据挖掘方法。在梯度算法基础推导出一种增量式的学习算法,在训练过程中该算法可以自适应调整网络参数。然后在IRIS数据库上进行分类实验,仿真实验结果表明该算法性能较好。在对RBF神经网络训练算法深入研究的基础上,本文采用了两阶段学习策略来加速学习收敛;提出动静相结合的隐含层设计方法来构造出较优的隐含层结构;提出采用误差校正的思想来改进RBF网络输出精度,并给出了其实现算法。并对这些改进算法在UCI数据库上进行了实验和对比分析,实验结果表明改进后的算法其性能均有明显提高。基于对数据挖掘和神经网络技术的研究,开发了一个主要用作实验平台的集成了本文各种算法的数据挖掘系统。本论文研究的基于RBF神经网络的数据挖掘方法具有一定的理论深度和实用价值,尤其创新的学习算法可以为相关的科研工作提供有益的参考。
[87]吴瑕.数据挖掘技术在教学管理中的应用研究[D].导师：黄凤岗.哈尔滨工程大学,2007.
关键词:数据挖掘,关联规则,Apriori算法,决策树,聚类
摘要:随着高等学校招生规模的不断扩大和信息技术的不断发展，各高校都建立了自己的教务管理信息系统，这些系统很大程度上提高了教学和管理的水平，同时也积累了大量的教学和管理数据。但是目前这些信息系统多半是联机事务处理系统，缺乏综合分析和辅助决策的能力。不能提供对所采集数据进行归类与深层次分析的功能，这使得管理人员在面对复杂情况时不能及时了解相关信息，领导在决策时也没有切实的数据支持。对教学管理进行分析是教学评估的重要手段，本文在搜集和阅读了大量有关数据挖掘的论文后，采用数据挖掘技术对教务数据进行多层次、多角度的分析与挖掘，利用挖掘结果辅助教学决策，从而保证教学质量、提高学生素质。本文主要探讨了数据挖掘技术的基本理论和主要算法；研究了数据挖掘中的关联规则、分类算法和聚类算法。运用改进的Apriori算法分析了学生英语成绩与四级考试成绩的隐藏关系；使用了决策树算法对学生的就业方向进行指导；运用了k-均值算法来评测试卷质量。通过在教务系统中的具体挖掘实践，得到了许多有价值的信息，这些信息在帮助学校更好地进行学生的培养，对学生表现情况的掌握以及课程的教学等方面无疑具有重要的指导意义。
[88]潘洁珠.基于数据挖掘的预警技术研究[D].导师：胡学钢.合肥工业大学,2007.
关键词:预警,数据挖掘,预警知识挖掘,教育信息,成绩预警
摘要:危机的发生具有必然性和客观性。面对危机，最好的办法就是在危机发生之前进行事先的预警预控，把危机消灭在萌芽状态。因此，采取合适的预警理论和方法进行预先警报并在此基础上采取针对性的措施就显得非常重要。危机预警是一类带有大量不确定因素的半结构化问题或非结构化问题。很多因素没有历史数据和相应的统计资料，很难进行科学地计算和评估。传统的分析方法存在很多的局限性，分析和预测的结果也不够准确。数据挖掘技术是目前人工智能和数据库领域研究的热点问题，它能自动地分析数据仓库的海量数据，挖掘出丰富和客观的预警知识，并运用于危机预警。将数据挖掘技术运用于危机预警领域，具有重要的理论意义与应用价值。本文的主要工作如下：(1)分析传统的预警理论、方法和应用领域。提出了一种基于数据挖掘技术的预警机制。(2)设计了一种基于领域知识约束的预警知识表示方法，在分析关联规则挖掘方法的基础上，提出了一种基于领域知识约束的预警知识挖掘方法。(3)设计了一步预警方法和迭代预警方法，以根据挖掘出的预警知识生成预警信息。(4)以教育数据挖掘为背景，应用本文提出的预警机制、预警知识挖掘方法和预警方法，针对高校教学教务系统中的成绩预警问题的解决开展了有益的探索研究。
[89]艾萍,倪伟新.我国水文数据挖掘技术研究的回顾与展望[J].计算机工程与应用,2003, 28:13-17.
关键词:水文学,水文数据挖掘,模式
摘要:水文科学研究的领域面临来自许多方面的不确定性和非确知问题。引入数据挖掘的理论与技术,结合水文科学发展的需要,充分应用以计算机技术为基础的现代信息技术,研究水文数据挖掘的理论、技术和方法,为解决水文科学研究面临的问题提供了新的思路。当前,水文数据挖掘研究还处于起步阶段,研究内容多集中在水文数据的单项和局部数据的模拟与处理方面,对基于水文数据库的全局性多因素数据挖掘涉及很少,在数据挖掘技术与水文数据适应性方面所进行的研究也还很不够。为了充分发挥数据挖掘发现知识的作用,需要在水文主题数据库和多维数据立方、水文序列的分类、聚类和关联规则挖掘技术及优化算法以及水文序列的相似性、周期性和其它序列模式挖掘方面开展进一步研究,并向形成水文数据挖掘软件及数据平台方向发展。
[90]赵广社,张希仁.数据挖掘中的统计方法概述[J].计算机测量与控制,2003, 12:914-917.
关键词:数据挖掘,回归分析,主成分分析,判别分析,聚类分析,模糊集,粗糙集,支持向量机
摘要:统计方法有成熟的数学基础,可以很好的对数据进行解释,在数据挖掘中有着大量的运用。文章回顾了数据挖掘中常用的统计方法,包括传统的统计方法(回归分析、主成分分析、判别分析和聚类分析)和其他一些非机器学习的方法(模糊集、粗糙集和统计学习理论),分析了各种统计方法的优缺点。
[91]张春华,王阳.数据挖掘技术、应用及发展趋势[J].现代情报,2003, 04:47-48+50.
关键词:KDD,数据挖掘,知识
摘要:数据挖掘是当前数据库和信息决策领域的最前沿研究方向之一。本文从知识发现和数据挖掘的概念出发 ,总结了数据挖掘常采用的技术方法 ,同时对数据挖掘的应用及发展进行了阐述。
[92]刘志鹏.移动通信数据挖掘关键应用技术研究[D].导师：皮德常.南京航空航天大学,2015.
关键词:移动数据,恶意节点检测,社会影响力,位置挖掘,密码安全,移动通信数据存储
摘要:随着移动互联网智能终端、移动网络和应用服务的不断发展,移动互联网数据的收集和传输能力不断增强。针对移动数据开发的应用逐渐增多,其中典型的应用包括团体检测、灾难抢救、位置预测和情感分析等。这些移动应用正悄然改变人们的日常生活,移动数据挖掘近年来成为数据挖掘中的热点领域。本文重点讨论移动数据挖掘算法,包括:移动通信恶意通话节点检测、移动通信节点间影响力检测、移动轨迹异常检测、移动应用密码强度分析以及移动通信数据存储实现。其目的在于有效利用采集到的移动数据,为人们提供更优质的移动互联网服务。本文的研究成果包含以下几个方面:1.研究了移动通信恶意通话问题。本文提出了一种基于通话记录的恶意节点检测算法(Call Log Rank Algorithm,CLRank)。该算法将挖掘恶意通话节点当做经典的分类问题,将移动通话日志按照某个特定的时间间隔分割为多个移动通话日志区段,针对每个通话日志区段构建基于时间的通信社交网络,使用基于排序和分类的方法检测潜在的恶意节点。与现有方法相比,该算法仅使用链接信息,在最大程度上保护了用户隐私。实验结果表明,CLRank可以从通话日志中动态、自动和高效地检测恶意节点。2.研究了移动通信节点间的影响力检测问题。针对短信日志数据提出了基于时间的影响力图模型(Time-based Influence Graph,TIG)。TIG是一种全局节点影响力算法,该算法首先将短信日志数据转换为接触序列,同时考虑时间信息对影响力检测的作用,采用动态、基于时间的排序方法计算网络节点间的影响力。针对通话日志数据提出了基于Edge Rank算法的影响力图模型(Edge Rank-based Influence Graph,ERIG)。ERIG是一种局部节点影响力算法。该算法首先将通话日志数据转换为区间图,计算动态的基于时间的影响力值,并依据该值对节点影响力进行排序。实验结果表明TIG和ERIG能够自动、高效地计算移动数据节点影响力。3.研究了移动轨迹异常检测问题。针对现有异常轨迹检测算法采用基于距离的方法测算轨迹分量间的距离,用户需要选取某个全局距离阈值,因此处理局部稠密的移动轨迹效果不佳,且算法结果对参数值敏感的问题,本文提出了基于密度的移动轨迹数据异常检测算法(Density-based Mobile Trajectory Outlier Detection,DMTOD)。该算法由分割和检测两个阶段组成。在分割阶段,算法将移动用户的轨迹数据分为若干区间;在检测阶段,算法使用基于密度的异常检测算法计算结果。实验结果表明DMTOD能够更好地检测异常移动轨迹。4.研究了中国移动互联网应用的密码设置习惯问题。目前缺乏大规模中国移动应用密码设置的研究。本文收集了网络入侵者公布在网上的两千万中国网络用户密码信息,使用统计学和机器学习方法研究密码设置习惯。针对当前缺乏适用于中国互联网用户密码字典的现状,提出了基于训练集扩展的字典(Training set Extension Based Dictionary,TEBD)生成算法。该算法使用概率上下文无关文法,构建4层密码分布树(Training Set Distribution Tree,TSDT),使用基于遗传算子的算法生成新的密码集合。实验结果表明该算法是有效的,可以检验用户密码的安全性。5.实现了移动通信数据单机存储。在数据规模不到PB级别时,可以使用基于PC机的移动通信数据存储。它具有实现简单、成本较低等优点。构建并优化了基于Graph Chi的单机移动通信数据存储(Mobile Communication Data Storage,MCDS)。MCDS从数据格式、分片机制和内存置换算法等三方面改进了Graph Chi。实验结果验证了MCDS的有效性,为移动通信数据挖掘提供了切实可行的实验环境。
[93]李学明,刘志军,秦东霞.隐私保护数据挖掘[J].计算机应用研究,2008, 12:3550-3555.
关键词:数据挖掘,隐私保护,启发式技术,安全多方技术,重构技术
摘要:隐私保护数据挖掘的目标是寻找一种数据集变换方法,使得敏感数据或敏感知识在实施数据挖掘的过程中不被发现。近年出现了大量相关算法,按照隐私保持技术可将它们分为基于启发式技术、基于安全多方技术和基于重构技术三种。结合目前研究的热点对关联规则和分类规则的隐私保护数据挖掘进行介绍,并给出算法的评估方法,最后提出了关联规则隐私保护数据挖掘未来研究工作的方向。
[94]刘柱文,李丽琳.关联规则技术在数据挖掘中的应用[J].科学技术与工程,2008, 06:1593-1597.
关键词:数据挖掘,关联规则,算法
摘要:数据挖掘技术的诞生,使我们能从大量的数据中提取对决策者有用的信息,20世纪90年代初,R.Agrawal等提出了关联规则挖掘技术。关联规则挖掘是为了发现大量数据中项目集之间感兴趣的相关性信息。经过十余年的发展,关联规则挖掘已经成为数据挖掘技术中较为成熟并很重要的一种方法。文中系统描述了关联规则挖掘所涉及的概念、关联规则挖掘算法和关联规则应用领域等。
[95]杨兰仓.数据挖掘中聚类和孤立点检测算法的研究[D].导师：石冰.山东大学,2008.
关键词:数据挖掘,聚类分析,孤立点检测,粗糙集,遗传算法
摘要:随着计算机应用的普及,信息系统产生的数据量日益增大,如何有效地利用巨量的原始数据分析现状和预测未来,已经成为人类面临的一大挑战。数据挖掘技术应运而生并得以迅猛发展,这是快速增长的数据量和日益贫乏的信息量之间矛盾运动的必然结果。数据挖掘,又称为数据库中的知识发现,是从大量数据中提取可信的、新颖的、有效的并能被人们理解的模式的处理过程。数据挖掘是一门新兴的技术,它以数据库技术作为基础,把逻辑学、统计学、机器学习、模糊学、可视化计算等多门学科的成果综合在一起,进行如何从数据库中得到有用信息的研究。数据挖掘技术得到了人们的普遍关注,广泛应用于银行金融、保险、公共设施、政府、教育、远程通讯、软件开发、运输等各个企事业单位及国防科研上。聚类分析是数据挖掘中的一个重要研究领域。所谓聚类,就是把没有类别标记的样本集按某种准则划分成若干类,使类内样本的相似性尽可能大,类间样本的相似性尽可能小,是一种无监督的学习方法。聚类分析通常是在没有先验知识支持的前提下进行的,它所要解决的就是在这种前提下,实现满足要求的类的聚合。聚类分析的研究主要集中在聚类算法上,产生性能好而且实用的聚类算法是其终极目的。迄今为止,人们提出了很多不同的适用于数据挖掘的聚类算法,但这些算法仅适用于特定的问题及用户,而且它们在理论和方法上仍不完善,甚至还有严重的不足之处。对聚类算法的进一步优化研究将不仅有助于算法理论的完善,更有助于算法的推广和应用。本文在分析了当前各种聚类算法的思想和方法的同时,针对目前基于划分的聚类算法存在的一些缺陷和不足,提出了基于粗糙集理论的聚类改进算法。解决了划分问题中不能准确设定聚类个数和只能用于挖掘球形聚类的问题,使得划分方法也可以用于发现任意形状的聚类。绝大多数现实世界中的数据库都包含了“噪声”和孤立点数据。一些聚类算法对于这样的数据敏感,可能导致低质量的聚类结果。因此,本文在分析研究现有基于距离的孤立点检测算法的基础上,针对其性能和精度上的不足,定义了一个新的相异度函数来度量孤立点的强弱,从而使孤立点的“孤立”程度有了一个量化的尺度,然后将该相异度函数作为遗传算法的适应度函数,提出了基于遗传算法的孤立点检测改进算法。在本算法中,用户只需指定要找的孤立点的个数,其他的一切均由该算法自动完成,这不仅减轻了用户的负担,也使得外界的影响达到最小。在综合数据集和真实数据集上的大量对比实验结果验证了该算法的正确性,同时在性能和质量上也比其它的孤立点检测算法更加合理有效。
[96]吴辉.数据挖掘技术的研究与应用[D].导师：熊前兴.武汉理工大学,2009.
关键词:数据挖掘,关联规则,信息系统,Apriori算法
摘要:随着数据库技术的逐渐成熟和计算机网络的迅速普及,人们采集数据的能力得到了极大的提高,导致全球范围的信息急剧膨胀,为了对这些海量信息的隐藏知识进行开发,数据挖掘技术应运而生。目前,数据挖掘技术愈来愈成熟,应用范围也日趋广阔,但是,在港口信息领域还缺乏专门的研究。伴随着我国经济的发展,我国港口的规模也不断扩大,货物吞吐量也跟随着急剧增长。在各大港口采取信息化运作的背景下,港口信息已经由以往的手工操作转化为目前依靠网络技术的自动化操作,并且已经积累了一定数量的信息。跟其它领域一样,港口信息中也蕴含着潜在的有价值的知识有待于发现,这些知识能够为企业良好经营和决策部门做出重要决策提供帮助,所以对数据挖掘技术在港口信息管理中应用的研究就成为了当务之急。本文是数据挖掘技术在港口信息管理系统领域的一个初步尝试,试图验证数据挖掘技术在这个领域中的可行性。首先,介绍了数据挖掘技术的基本原理与概念,以及数据挖掘的任务,方法和步骤。着重研究了关联规则挖掘技术,本文在原始Apriori算法的基础上进行了改进,在生成新的项集的同时,减小原始数据库的规模,降低了算法扫描数据库的次数,有效地提高了算法的效率。其次,介绍了本文的数据挖掘对象—航道养护费征稽管理系统的设计模型和数据库结构,讨论了基于信息管理系统的数据挖掘应用,并分析了在关系型数据库中进行数据挖掘的可能性以及方法。最后,论文按照数据挖掘的标准步骤,对数据库原始表依次进行了数据选取,数据清洗,数据转化,使其成为适合于数据挖掘的文本数据源。并用Apriori算法进行挖掘,输入最小支持度阈值和最小置信度阈值,输出所有的频繁项集和强关联规则。根据强关联规则,发现了隐藏在港口信息中的一些规律。
[97]杨华.数据挖掘在高校图书馆个性化推荐中的应用研究[D].导师：段钢.电子科技大学,2009.
关键词:关联规则,个性化推荐,数据挖掘,高校图书馆
摘要:随着信息技术和Internet技术的高速发展,lib 2.0技术的出现和流行,使得高校图书馆的服务空间日益扩大,个性化信息服务也逐渐成为新型服务模式的主流。个性化信息服务改变传统图书馆被动服务方式,能根据用户的兴趣偏好主动地向用户推荐图书。本课題的目的是通过对数据挖掘技术理论及个性化推荐系统理论的学习研究,将数据挖掘技术引入到高校图书馆的读者服务中,实现个性化图书推荐。本文通过对当前大多数高校图书馆采用的图书馆集成系统进行了解后发现,这些系统都不具备数据分析挖掘功能,本文拟在图书馆集成系统的基础上设计配套的个性化推荐系统,在作了详细的需求分析、借阅流程分析后,从理论研究的角度建立起推荐系统模型,并对模型的各个模块作了阐述。由于各种条件和时间的限制,本文在后面的具体实现研究中只针对个性化服务层中的数据采集模块和挖掘模块作了详细的研究,对推荐模块未进行深入的探讨。在具体实现研究中,本文以某高校图书馆的历史借阅记录为具体挖掘对象,应用数据挖掘技术,研究了高校图书馆个性化推荐系统中的数据采集和挖掘分析的具体实现。主要从两个方面实施挖掘分析,再根据分析结果进行个性化推荐。一方面采用关联规则挖掘对借阅记录数据进行挖掘,挖掘出各专业、各年级、各学历层次的读者对图书馆图书资源利用的关联规则,找出具有强关联性的各类图书,主动为读者提供相关借阅的其它书籍信息,以各种方式主动地向读者推荐图书。另一方面采用聚类分析,将该图书馆的读者进行有效的群分类,总结出不同群的特点进行针对性的图书推荐,提高馆藏图书的借阅率。并对图书馆优化馆藏建设、建立馆藏图书的科学合理结构提出了一些建议,这些建议对于其他高校图书馆也具有借鉴意义。最后,对本文研究进行了全面总结,展望了未来进一步研究的方向。
[98]齐金鹏.数据挖掘模型可视化研究及其应用实例[D].导师：赵宏伟.吉林大学,2004.
关键词:数据仓库, 数据挖掘 ,联机事务处理, 联机分析处理, 科学计算可视化,单查询,提升到从数据中挖
摘要:我们现在已经生活在一个网络化的时代，通信、计算机和网络技术正改变着整个人类和社会。大量信息在给人们带来方便的同时也带来了一些问题：第一是信息过量，难以消化；第二是信息真假难以辨识；第三是信息安全难以保证；第四是信息形式不一致，难以统一处理。人们开始考虑：“如何才能不被信息淹没，而是从中及时发现有用的知识、提高信息利用率？” 面对这一挑战，数据挖掘（Data Mining）和知识发现（Knowledge Discovery）技术应运而生。随着数据库技术的迅速发展以及数据库管理系统的广泛应用，积累的数据越来越多。激增的数据背后隐藏着许多重要的信息，人们希望能够对其进行更高层次的分析，以便更好地利用这些数据。目前的数据库系统可以高效地实现数据的录入、查询、统计等功能，但无法发现数据中存在的关系或规则，无法根据现有的数据预测未来的发展趋势。数据挖掘（Data Mining）是人们长期对数据库技术进行研究和开发的结果。数据挖掘技术是新兴的研究领域之一，它结合了数据库技术、人工智能（AI）和统计分析等多项技术，其主要特点是对商业数据库中的大量业务数据进行抽取、转换、分析和其他模型化处理，从中提取辅助商业决策的关键性数据。数据挖掘使数据库技术进入了一个更高级的阶段，它不仅能对过去的数据进行查询和遍历，并且能够找出过去数据之间的潜在联系，从而促进信息的传递。数据挖掘技术的运用能从大量的、不完全的、有噪声的、模糊的、随机的应用数据中提取出隐藏于数据背后的信息和知识。  决策支持系统（Decision Support System）是在管理信息系统的基础上发展起来的，目前开发的综合DSS是以数据仓库（DataWarehouse）技术为基础，以联机分析处理（OLAP）和数据挖掘（DataMining）工具为手段进行实施的一整套解决方案, 而数据挖掘是决策支持工具中的重要组成部分。数据仓库直接为联机分析处理和数据挖掘提供数据源。在数据仓库基础上挖掘的知识通常以图表、可视化、类自然语言等形式表示出来，但所挖掘的知识并不都是有意义的，必须进行评价、筛选和验证，把有意义的知识放到知识库中，随着时间的推移将积累更多的知识。知识库根据挖掘的知识类型包括总结性知识、关联性知识、分类模型知识、聚类模型知识，这些知识通过相应挖掘算法得到。本论文是在长春康达智控公司软件研发部完成的。在公司期间参与了通化钢铁集团公司决策支持系统（TGDSS1.0）的研发工作。该软件系统分为联机分析处理（OLAP）和数据挖掘（DM）两个子系统，OLAP子系统的主要功能是通过IE（微软的INTERNET EXPLORE）或NETSCAPE等浏览器随时随地查阅商业数据，在线创建各类数据报表，及时发布和传递各种数据文件；DM子系统主要分析商业数据为高层决策提供及时而有价值的信息，其功能包括对底层商业数据预处理、挖掘模型建立、知识可视化呈现等。整个系统集成了数据挖掘（DM）、联机分析处理（OLAP）、可视化、WEB等技术。整个软件系统分四个层次体系，包括数据仓服务器层、数据挖掘服务器层、WEB服务器层和用户层等四个层次的体系结构。数据挖掘子系统主要基于微软的数据挖掘核心技术，以SQL Server Analysis Services为数据挖掘的服务平台，分别针对底层的关系型数据库和数据仓库中的多维数据立方体两种数据源建立可视化的挖掘模型，并将得到的挖掘模型以两种可视化形式展现给客户。本论文主要阐述与数据挖掘子系统相关的研究内容。针对通化钢铁集团公司决策支持系统（TGDSS1.0）中的数据挖掘子系统，主要做了以下方面的工作：首先阐述了数据挖掘的一些相关概念、模型结构、挖掘算法等内容，对数据挖掘的模型和算法等理论作了深入的研究，针对实际的业务需求将决策树算法应用到数据挖掘分类模型中；将可视化技术引入数据挖掘领域，从数据预处理、挖掘模型建立、模型验证与评估等整个数据挖掘流程中抽象出数据挖掘模型可视化的体系结构，并将其应用于数据挖掘子系统的研发过程中。其次根据数据挖掘模型可视化建立过程，针对关系型数据源开发客户端数据挖掘可视化分析工具---RDDMT（Relation Database Date Ming Tool）。在该挖掘工具的实现过程中，主要依托于Microsoft SQL Analysis Services 提供的数据挖掘服务，并集成多种可视化技术实现数据预处理、挖掘模型建立、模型展现等系统功能。最后基于多维数据立方体数据源开发了数据挖掘子系统---MDDMT（Muti-dimension Data cube Data Mining Tool）。该挖掘工具以Microsoft SQL Analysis Services 作为数据仓服务器，利用RDDMT预处理过的关系型数据建立多维数据立方体。第三方客户端数据挖掘分析工具DBMiner 2.0通过Analysis Services提供的联机数据分析服务接口（OLE DB FOR OLAP）与多维数据立方体数据源建立连接通道，对数仓库中的多维数据立方体建立可视化的挖掘模型。在系统的实现过程中，通过DBMiner可以方便地对多维数据立方体进行联机分析处理和挖掘模型的可视化创建过程。在本论文中，主要提出了数据挖掘模型可视化的体系结构等；并严格依据数据挖掘系统的开发规程，针对通用的业务模型，完成了基于关系型数据和?