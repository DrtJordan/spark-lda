[1]赵川源,何东健,乔永亮.基于多光谱图像和数据挖掘的多特征杂草识别方法[J].农业工程学报,2013, 02:192-198.
关键词:数据挖掘,聚类算法,图像处理,杂草识别,多光谱图像,多特征识别
摘要:为满足变量喷洒对杂草识别正确率的要求,提出一种基于多光谱图像和数据挖掘的杂草多特征识别方法。首先对多光谱成像仪获取的玉米与杂草图像从CIR转换到Lab颜色空间,用K-means聚类算法将图像分为土壤和绿色植物,随后用形态学处理提取出植物叶片图像,在此基础上提取叶片形状、纹理及分形维数3类特征,并基于C4.5算法对杂草分别进行单特征和多特征组合的分类识别。试验结果表明,多特征识别率比单特征识别率高,3类特征组合后的识别率最高达到96.3%。为验证该文提出方法的有效性,将C4.5算法与BP算法以及SVM算法进行比较,试验结果表明C4.5算法的平均识别率高于另2种算法,该文提出的田间杂草快速识别方法是有效可行的。该文为玉米苗期精确喷洒除草剂提供技术依据。
[2]丁岩,杨庆平,钱煜明.基于云计算的数据挖掘平台架构及其关键技术研究[J].中兴通讯技术,2013, 01:53-56+60.
关键词:数据挖掘平台,云计算,数据挖掘云,海量数据
摘要:随着云计算时代的到来,传统数据挖掘系统在海量数据的分析挖掘方面存在性能瓶颈。文章提出了基于云计算的数据挖掘平台,该平台与传统的数据挖掘系统架构相比有高可扩展性、海量数据处理能力、面向服务、硬件成本低廉等优越性,可以支持大范围分布式数据挖掘的设计和应用。该平台能极大减少运营商、企业在数据挖掘技术上的投入并能加快其挖掘业务的推出,缩短研发周期,进一步提高产品收益。
[3]黄斌,许舒人,蒲卫.基于MapReduce的数据挖掘平台设计与实现[J].计算机工程与设计,2013, 02:495-501.
关键词:MapReduce编程模型,数据挖掘,Hadoop平台,模型驱动,可视化
摘要:MapReduce编程模型的简单性和高性价比使得其适用于海量数据的并行处理。然而,MapReduce欠缺对多数据源、组件复用以及数据可视化支持,这些缺点使用户在运用MapReduce框架进行数据挖掘时暴露出开发效率低下,重复开发等问题。提出了一种基于MapReduce的数据挖掘平台的设计与实现,该设计思想为Hadoop作为大规模数据计算平台在数据挖掘、数据可视化以及商业智能应用方面的不足提供了参考与弥补。同时,基于该方法实现了一个大规模数据挖掘工具。
[4]王树良,丁刚毅,钟鸣.大数据下的空间数据挖掘思考[J].中国电子科学研究院学报,2013, 01:8-17.
关键词:大数据,空间数据挖掘,数据智能
摘要:对大数据背景下思考空间数据挖掘,分析了空间数据在大数据中的基础地位,综述了国际学术界、企业界和政界对大数据的关注;分析了空间大数据面临的垃圾多、污染重、利用难的现状,剖析了空间大数据蕴含的价值;探讨了从空间大数据中挖掘知识的技术,以及知识变为数据智能的途径。
[5]刘大有,陈慧灵,齐红,杨博.时空数据挖掘研究进展[J].计算机研究与发展,2013, 02:225-239.
关键词:时空数据挖掘,时空模式发现,时空聚类,时空异常检测,时空预测和分类
摘要:近年来,随着全球定位系统、传感器网络和移动设备等的普遍使用,非时空数据和时空数据急剧增加,加之时空数据处理更为复杂,使数据处理任务日趋繁重的形势更加严峻.因此,寻找有效的时空数据挖掘方法具有十分重要的意义.针对这一背景,主要围绕时空模式发现、时空聚类、时空异常检测、时空预测、时空分类、时空数据挖掘与推理的结合等方面,对时空数据挖掘研究的现状进行了详细介绍,对其当前所面临的一些主要问题及可能的解决方案进行了探讨.
[6]贺瑶,王文庆,薛飞.基于云计算的海量数据挖掘研究[J].计算机技术与发展,2013, 02:69-72.
关键词:云计算,数据挖掘,海量数据,MapReduce,数据预处理
摘要:为了实现高效率低成本的海量数据挖掘,为企业决策提供参考,提出了基于云计算的海量数据挖掘模型。该模型中海量数据的处理和存储都是在云计算环境中进行的,首先对海量的数据进行一定的预处理,形成结构一致的数据后,应用云计算平台上的MapReduce模型进行高效的并行数据处理,最后得到所需的数据挖掘结果。基于云计算的海量数据挖掘的效率明显高于传统的数据挖掘,并且数据挖掘结果的准确性有了一定的提高,而且随着数据量的增多,该模型的优势会愈发明显。
[7]杨来,史忠植,梁帆,齐保元.基于Hadoop云平台的并行数据挖掘方法[J].系统仿真学报,2013, 05:936-944.
关键词:并行数据挖掘,决策树算法,KD树算法,JPA,云计算
摘要:业界已经开始运用云平台来处理海量高维数据,将各种异构系统仿真为一个系统,其中在Hadoop环境进行数据挖掘会遇到数据模型的全局性、HDFS的文件随机写操作、数据生命周期短等问题。为解决这些问题,在Hadoop上实现高效海量数据挖掘,提出了在Hadoop上一种高效数据挖掘框架,利用数据库来模拟链表结构,管理挖掘出来的知识,提供了树形结构、图模型的分布式计算方法;在此基础上实现一个统计算法——Yscore分箱算法,以及决策树和KD树的建树算法;并利用Vega云对Hadoop集群进行仿真。实验数据表明该框架和算法实用可行,且可能拓展与数据挖掘之外的其他领域。
[8]李海林,郭崇慧.时间序列数据挖掘中特征表示与相似性度量研究综述[J].计算机应用研究,2013, 05:1285-1291.
关键词:时间序列,数据挖掘,特征表示,相似性度量
摘要:分别分析了时间序列特征表示和相似性度量在数据挖掘中的作用和意义,对目前已有的主要方法进行了综述,分析各自存在的优缺点;同时,探讨了将来值得关注的问题,为进一步研究时间序列数据的特征表示和相似性度量提供了方向。
[9]徐国虎,孙凌,许芳.基于大数据的线上线下电商用户数据挖掘研究[J].中南民族大学学报(自然科学版),2013, 02:100-105.
关键词:数据挖掘,O2O电商,用户数据,大数据
摘要:分析了大数据环境下的O2O电商用户数据特征,提出O2O电商用户数据挖掘框架,并探讨数据挖掘流程和主要的数据挖掘方法,分别从O2O电商平台、O2O用户和O2O商家三者角度探讨了O2O电商用户数据挖掘的应用问题.研究认为:O2O用户数据挖掘框架包括数据来源层、数据收集层、数据组织层、数据分析层与数据应用层等层级;数据挖掘流程主要包括数据收集、数据预处理、数据挖掘及数据应用4个过程;O2O电商用户数据的挖掘应用包括精准营销、平台网站优化、欺诈分析与防范、个性化推荐、增值服务开发与产品创新等方面.
[10]王元卓,靳小龙,程学旗.网络大数据:现状与展望[J].计算机学报,2013, 06:1125-1138.
关键词:大数据,网络大数据,网络空间感知,大数据存储,数据挖掘,社会计算
摘要:网络大数据是指"人、机、物"三元世界在网络空间(Cyberspace)中交互、融合所产生并在互联网上可获得的大数据.网络大数据的规模和复杂度的增长超出了硬件能力增长的摩尔定律,给现有的IT架构以及机器处理和计算能力带来了极大挑战.同时,也为人们深度挖掘和充分利用网络大数据的大价值带来了巨大机遇.因此,迫切需要探讨大数据的科学问题,发现网络大数据的共性规律,研究网络大数据定性、定量分析的基础理论与基本方法.文中分析了网络大数据的复杂性、不确定性和涌现性,总结了网络空间感知与数据表示、网络大数据存储与管理体系、网络大数据挖掘和社会计算以及网络数据平台系统与应用等方面的主要问题与研究现状,并对大数据科学、数据计算需要的新模式与新范式、新型的IT基础架构和数据的安全与隐私等方面的发展趋势进行了展望.
[11]储兵,吴陈,杨习贝.基于RBF神经网络与粗糙集的数据挖掘算法[J].计算机技术与发展,2013, 07:87-91.
关键词:RBF神经网络,粗糙集,数据挖掘
摘要:随着数据挖掘技术的兴起,为了提高数据挖掘的准确性,提出了很多数据挖掘算法。神经网络与粗糙集理论结合的数据挖掘算法一直是基于粗糙集理论数据挖掘研究的热点之一。文中提出利用RBF神经网络收敛速度快、泛化能力强等优势先对数据进行训练,优化数据后传递给粗糙集进行数据挖掘的新思路。并通过对比与未经过RBF神经网络训练的数据挖掘结果,发现RBF神经网络与粗糙集结合算法挖掘的精度有明显的提高,证明了RBF神经网络与粗糙集理论结合的数据挖掘算法是有效的、可行的。
[12]顾倩.数据挖掘应用于高校图书馆个性化服务的探讨[J].图书馆杂志,2013, 08:63-65.
关键词:数据挖掘,高校图书馆,个性化服务
摘要:图书馆作为信息资源收集、加工和服务的中心,随着信息技术的不断发展,在图书馆积累了丰富的数字信息资源。在图书馆服务工作中,采用数据挖掘技术对读者以及读者访问等数据进行分析和挖掘,从中发现读者兴趣和资源的关联,为读者提供个性化服务,这对图书信息资源的有效利用有着重要的理论和实践意义,图书馆的潜力和价值也将被更大程度地释放。
[13]何清,庄福振.基于云计算的大数据挖掘平台[J].中兴通讯技术,2013, 04:32-38.
关键词:云计算,分布式并行数据挖掘,海量数据
摘要:开发了一个基于云计算的并行分布式大数据挖掘平台——PDMiner。PDMiner实现了各种并行数据挖掘算法,如数据预处理、关联规则分析以及分类、聚类等算法。实验结果表明,并行分布式数据挖掘平台PDMiner中实现的并行算法,能够处理大规模数据集,达到太字节级;具有很好的加速比性能;实现的并行算法可以在商用机器构建的并行平台上稳定运行,整合了已有的计算资源,提高了计算资源的利用效率;可以有效地应用到实际海量数据挖掘中。在PDMiner中还开发了工作流子系统,提供友好统一的接口界面方便用户定义数据挖掘任务。
[14]李伟卫,赵航,张阳,王勇.基于MapReduce的海量数据挖掘技术研究[J].计算机工程与应用,2013, 20:112-117.
关键词:云计算,数据挖掘,Hadoop,MapReduce
摘要:MapReduce是一种编程模型,可以运行在异构环境下,编程简单,不必关心底层实现细节,用于大规模数据集的并行运算。将MapReduce应用在数据挖掘的三个算法中:朴素贝叶斯分类算法、K-modes聚类算法和ECLAT频繁项集挖掘算法。实验结果表明,在保证算法准确率的前提下,MapReduce可以有效提高海量数据挖掘工作的效率。
[15]李善青,赵辉,宋立荣.基于大数据挖掘的科技项目查重模型研究[J].图书馆论坛,2014, 02:78-83.
关键词:大数据挖掘,多源信息整合,科技项目查重,Hadoop架构
摘要:科技项目查重是避免重复立项、重复建设的重要措施之一,目前缺乏行之有效的方法。文章提出基于大数据挖掘和多源信息整合的项目查重方法,以科技项目的基本信息、发表论文信息、关键词、负责人信息和承担机构等要素构建的大数据网络为研究对象,利用多源信息整合方法构建科技项目的相似度判别模型,并采用Hadoop框架实现海量数据的快速挖掘。文章介绍项目查重模型,重点讨论需要解决的关键问题,为解决项目查重问题提供一种全新的思路和方法。
[16]吕婉琪,钟诚,唐印浒,陈志朕.Hadoop分布式架构下大数据集的并行挖掘[J].计算机技术与发展,2014, 01:22-25+30.
关键词:数据挖掘,大数据集,并行算法,Hadoop
摘要:基于Hadoop分布式计算平台,给出一种适用于大数据集的并行挖掘算法。该算法对非结构化的原始大数据集以及中间结果文件进行垂直划分以确保能够获得完整的频繁项集,将各个垂直分块数据分配给不同的Hadoop计算节点进行处理,以减少各个计算节点的存储数据,进而减少各个计算节点执行交集操作的次数,提高并行挖掘效率。实验结果表明,给出的并行挖掘算法解决了大数据集挖掘过程中产生的大量数据通信、中间数据以及执行大量交集操作的问题,算法高效、可扩展。
[17]熊平,朱天清,王晓峰.差分隐私保护及其应用[J].计算机学报,2014, 01:101-122.
关键词:差分隐私,数据发布,数据挖掘,机器学习,统计查询,隐私保护
摘要:数据发布与数据挖掘中的隐私保护问题是目前信息安全领域的一个研究热点.作为一种严格的和可证明的隐私定义,差分隐私近年来受到了极大关注并被广泛研究.文中分析了差分隐私保护模型相对于传统安全模型的优势,对差分隐私基础理论及其在数据发布与数据挖掘中的应用研究进行综述.在数据发布方面,介绍了各种交互式和非交互式的差分隐私保护发布方法,并着重从精确度和样本复杂度的角度对这些方法进行了比较.在数据挖掘方面,阐述了差分隐私保护数据挖掘算法在接口模式和完全访问模式下的实现方式,并对这些算法的执行性能进行了分析.最后,介绍了差分隐私保护在其它领域的应用,并展望未来的研究方向.
[18]吴嘉瑞,郭位先,张冰,张晓朦,杨冰,盛晓光.基于数据挖掘的国医大师颜正华含陈皮处方用药规律研究[J].中国中药杂志,2014, 04:618-622.
关键词:陈皮,数据挖掘,关联规则
摘要:该研究在收集处方的基础上,基于中医传承辅助系统构建数据库,进而应用关联规则apriori算法等数据挖掘方法,分析常用单味药物频次、药物组合频次、关联规则与核心药物组合等。研究显示,含陈皮处方常用于治疗胃痛、咳嗽等病证,高频次药物组合包括"陈皮-茯苓"、"赤芍-陈皮"等,置信度为1的关联规则包括"甘草→陈皮"、"白芍-香附→陈皮"、"茯苓→陈皮"等,处方所用药物多具理气活血等功效,用药较为集中,组方法度清晰。
[19]吴嘉瑞,唐仕欢,郭位先,张晓朦,张冰.基于数据挖掘的名老中医经验传承研究述评[J].中国中药杂志,2014, 04:614-617.
关键词:数据挖掘,名老中医,经验传承
摘要:数据挖掘又称数据库知识发现,是从海量数据中揭示出隐含的、先前未知的并有潜在价值的信息的非平凡过程。近年来,数据挖掘在中医药研究领域的应用日益广泛,特别是在名老中医经验传承领域发挥着重要作用。该文对关联规则、贝叶斯网络、神经网络、决策树、复杂系统熵方法等数据挖掘方法在名老中医经验传承研究中的应用进行总结,并对常用研究方法的优势和不足进行剖析,指出将数据挖掘方法进行集成而开发相应的软件,是其重要的研究方向。
[20]郭迟,刘经南,方媛,罗梦,崔竞松.位置大数据的价值提取与协同挖掘方法[J].软件学报,2014, 04:713-730.
关键词:大数据,轨迹移动模式,位置服务,泛在测绘,数据挖掘
摘要:随着位置服务和车联网应用的不断普及,由地理数据、车辆轨迹和应用记录等所构成的位置大数据已成为当前用来感知人类社群活动规律、分析地理国情和构建智慧城市的重要战略性资源,是大数据科学研究极其重要的一部分.与传统小样统计不同,大规模位置数据存在明显的混杂性、复杂性和稀疏性,需要对其进行价值提取和协同挖掘,才能获得更为准确的移动行为模式和区域局部特征,从而还原和生成满足关联应用分析的整体数据模型.因此,着重从以下3个方面系统综述了针对位置大数据的分析方法,包括:(1)针对数据混杂性,如何先从局部提取出移动对象的二阶行为模式和区域交通动力学特征;(2)针对数据复杂性,如何从时间和空间尺度上分别对位置复杂网络进行降维分析,从而建立有关社群整体移动性的学习和推测方法;(3)针对数据的稀疏性,如何通过协同过滤、概率图分析等方法构建位置大数据全局模型.最后,从软件工程角度提出了位置大数据分析的整体框架.在这一框架下,位置数据将不仅被用来进行交通问题的分析,还能够提升人们对更为广泛的人类社会经济活动和自然环境的认识,从而体现位置大数据的真正价值.
[21]吉根林,赵斌.面向大数据的时空数据挖掘综述[J].南京师大学报(自然科学版),2014, 01:1-7.
关键词:时空数据挖掘,时空大数据,时空模式发现,时空聚类,时空分类,时空异常检测
摘要:时空数据挖掘是数据挖掘领域的前沿研究课题,正致力于开发和应用新兴的计算技术来分析海量、高维的时空数据,揭示时空数据中的有价值知识.本文以时空大数据为背景,介绍数据挖掘技术产生的背景与发展、时空数据挖掘的研究现状、研究内容、应用领域、面向大数据的时空数据挖掘系统架构以及实现技术,为相关领域的研究者提供参考.
[22]刘新海.大数据挖掘助力未来金融服务业[J].金融市场研究,2014, 02:117-126.
关键词:大数据,数据挖掘,金融服务业
摘要:大数据是IT技术发展到一定阶段的产物,其内涵和外延还在发展中。通过对大数据的深度和广度的挖掘,大数据的价值可以被充分利用。大数据在金融服务业的应用不仅会带来新的商业机遇,还可以带来新的商业模式的变革。本文讨论了金融大数据挖掘所面临的挑战,以及国内金融业大数据挖掘的现状,并对金融大数据和云计算、互联网金融的关系进行了梳理,最后对未来金融大数据挖掘进行了展望。
[23]张海涛,黄慧慧,徐亮,高莎莎.隐私保护数据挖掘研究进展[J].计算机应用研究,2013, 12:3529-3535.
关键词:隐私保护数据挖掘,新型分布式系统,高维数据,时空数据
摘要:近年来隐私保护数据挖掘已经成为数据挖掘的研究热点,并取得了丰富的研究成果。但是,随着移动通信、嵌入式、定位等技术的发展与物联网、位置服务、基于位置的社交网络等应用的出现,具有个人隐私的信息内容更加丰富,利用数据挖掘工具对数据进行综合分析更容易侵犯个人隐私。针对新的应用需求,对隐私保护数据挖掘方法进行深入研究具有重要的现实意义。在分析现有的隐私保护数据挖掘方法分类与技术特点的基础上,提出现有方法并应用于新型分布式系统架构应用系统、高维数据及时空数据等领域存在的挑战性问题,并指出了今后研究的方向。
[24]张引,陈敏,廖小飞.大数据应用的现状与展望[J].计算机研究与发展,2013, S2:216-233.
关键词:大数据,数据分析,数据挖掘,非结构化数据,物联网,社交网络数据,众包
摘要:大数据具有规模大、种类多、生成速度快、价值巨大但密度低的特点.大数据应用就是利用数据分析的方法,从大数据中挖掘有效信息,为用户提供辅助决策,实现大数据价值的过程.主要介绍了大数据分析方法、分析模式以及常用的分析工具,将大数据应用归纳为6个关键领域———结构化数据分析、文本分析、Web分析、多媒体分析、社交网络分析和移动分析,并列举了6个大数据的典型应用.最后,从基础理论、关键技术、应用实践以及数据安全4个方面总结了大数据的研究现状,并对大数据应用未来的研究进行展望.
[25]刘太安.基于支持向量机的空间数据挖掘方法及其在旅游地理经济分析中的应用[D].导师：汪云甲.中国矿业大学,2012.
关键词:MC-COLS-SVM,COLS-BSVR,空间数据分类或回归,时政指数,景区景点分布指数,预测模型,风险管理模型,数据挖掘软件
摘要:本论文根据旅游地理经济分析预测管理需求，就基于支持向量机的空间数据挖掘分类或回归的理论与方法以及在旅游地理经济管理中的应用展开了系统研究，建立了基于支持向量机的空间数据分类或回归挖掘模型与算法、特征选择算法，设计实现了面向旅游地理经济应用的数据挖掘软件。主要内容如下：（1）提出了SVM若干算法。通过组合优化方法和最小二乘方法，以及多分类支持向量机方法，提出了MC-COLS-SVM分类机算法；通过组合优化方法，以及减少约束，降低问题复杂度，提出了组合优化COLS-BSVR回归机算法。提出了对于支持向量回归机特征选择的算法，并进行了实证分析。（2）构建了基于支持向量机的空间数据挖掘理论与方法体系。研究设计了基于支持向量机的空间数据挖掘工作流程与框架以及实现方法；基于MC-COLS-SVM多分类组合优化思路，设计了空间数据分类算法；基于COLS-BSVR组合优化最小二乘支持向量回归机思路，设计了空间数据回归算法。（3）提出了时政指数、景区景点分布指数，并成功应用于旅游地理经济分析之中。通过对旅游收入、游客人数、时政指数、景区景点分布指数、GDP、CPI等变量时间序列的统计描述分析及其它们对旅游地理经济影响分析，提取了旅游地理经济数据特征，设计了相应的旅游地理经济数据库。（4）建立了基于支持向量机的旅游地理经济预测模型。基于提出的COLS-BSVR支持向量回归机算法，建立了基于支持向量机的旅游地理经济分析预测数学模型；设计了数据挖掘中的数据构造模式，验证了模型与模式的有效性。（5）建立了基于支持向量机的旅游地理经济风险管理模型。基于设计的空间数据分类算法、回归算法以及特征选择算法，结合旅游地理经济特征敏感性分析，建立了风险管理数学模型，验证了模型的有效性。（6）设计并实现了基于支持向量机的旅游地理经济数据挖掘软件。该数据挖掘软件分三层结构构建；各种数据采集预处理后，存入旅游地理经济数据库，通过基于支持向量回归机的算法运算，生成预测信息，供分析决策参考。该论文有图51幅，表44个，参考文献116篇。
[26]袁冠.移动对象轨迹数据挖掘方法研究[D].导师：夏士雄.中国矿业大学,2012.
关键词:移动对象,轨迹数据,结构特征,活动发现,时间粒度,周期模式
摘要:近年来，随着GPS设备、RFID传感器、卫星和无线通信等技术的快速发展，全球范围内的各种大小的移动对象都可以得到有效跟踪，由此产生了越来越多的移动对象轨迹数据被收集并存储在移动对象数据库中。这些数据蕴含着大量的信息，迫切需要研究人员对其进行有效地分析。本课题以移动对象轨迹数据为研究对象，以移动对象的活动模式发现为研究的主要目标。本课题研究的工作主要包括如下几个方面：1．以移动对象轨迹数据挖掘的目标和任务为驱动，在分析现有移动对象数据挖掘系统的目标和特点的基础上，深入研究现有移动对象数据挖掘相关理论、方法，提出了一种新的移动对象周期行为活动挖掘系统框架，能够从不同层次对移动对象轨迹数据展开分析和挖掘，并发现移动对象的活动特点。2．针对现有移动对象数据挖掘方法过分追求效率而忽略轨迹运动特征问题，提出了一种基于结构特征的轨迹分析方法，该方法从微观角度对移动对象的运动模式和轨迹特征进行分析。通过抽取轨迹的结构特征对移动对象的运动轨迹进行比较，能够从更全面的角度分析对象的运动特点，此外，通过设置轨迹的结构权重，可以灵活地调整轨迹结构的敏感程度，从而快速、高效、灵活地对移动对象的运动轨迹进行分析。3．为深入分析移动对象的活动特点，提出了一种基于协同过滤的移动对象兴趣活动发现算法。该方法从宏观角度对移动对象的兴趣活动以及兴趣路径进行发现。该方法首先对移动对象的轨迹数据进行建模，给出了移动对象活动的热点区域发现算法，解决了对象活动发现和表示的问题。通过借助协同过滤算法，发现在兴趣活动上较为相似的对象，并以近邻的历史活动为基础推荐对象潜在的兴趣活动。在对象兴趣活动的基础上，引入时间标记的最大公共子模式方法，发现近邻对象之间的兴趣活动路径。4．通过对移动对象活动的时空特点进行分析，研究移动对象活动的周期特性，提出一种基于多粒度的移动对象周期活动发现方法，用于在多种时空粒度下对移动对象活动进行周期活动发现。该方法对对象的活动进行时空建模，并给出多粒度活动发现算法，对移动对象的活动进行多粒度表示。该方法不仅能在能够在周期未知的情况下发现单对象的活动周期，还能够发现关联活动的周期。5．通过构建移动对象轨迹数据挖掘原型系统，实现了移动对象轨迹数据的一系列分析，并结合煤矿领域关于人员定位相关的需求，给出了移动对象数据挖掘在煤矿领域的启发式应用，有效地将移动对象数据挖掘方法与实践进行了结合，印证了移动对象轨迹数据挖掘相关方法的可行性和有效性，为多领域移动对象数据挖掘理论和方法提出了新的思路和新的探索。
[27]赵春.基于数据挖掘技术的财务风险分析与预警研究[D].导师：朱群雄.北京化工大学,2012.
关键词:数据挖掘,关联规则,交互挖掘,增量挖掘,动态维护,时间序列,风险分析,危机预警
摘要:随着信息技术的快速发展和管理理论研究取得重大进展，信息技术在企业管理决策领域中的应用受到越来越多的关注。面对残酷的市场竞争环境，企业对风险管理的要求日益提高，如何客观评价企业管理过程中存在的财务风险，并对其进行及时预警是企业管理层始终追求的目标。传统的企业财务风险分析与预警研究方法主要包括统计分析和人工智能模型。随着企业规模的扩大和信息披露越来越频繁，统计分析模型已经不能适应海量数据分析的要求，人工智能模型没有考虑到财务数据的时间延续性。另外，企业财务风险分析与预警研究受企业内外部多种因素影响，不确定性非常高，而数据挖掘技术在不确定性理论研究中的优秀表现让两者紧密联系起来。因此，针对传统方法无法解决的问题，本文深入研究关联规则数据挖掘方法，提出了三种新的关联规则改进型算法，极大提高了数据挖掘的效率；同时，将这些算法应用于企业财务风险分析与危机预警的研究，提出了企业财务风险概念层次树模型和时间序列动态维护的财务危机预警模型。主要研究内容如下：1.基于Hash结构的关联规则交互挖掘算法HIUA,现有的关联规则挖掘算法主要基于支持度-置信度框架，同一数据库在不同的支持度和置信度阈值下，算法产生的频繁项集和关联规则的数目是不同的。由于用户事先无法确定合适的支持度和置信度阈值，需要不断尝试不同的阈值才能得到理想的频繁项集和关联规则。本文针对支持度阈值变化时的关联规则维护问题，即当用户调整阈值时存在多次遍历数据库和重复计算问题，提出了基于Hash结构的关联规则交互挖掘算法HIUA，该算法改进了原始IUA算法的剪枝过程，并通过Hash结构快速存取算法执行过程中得到的支持度计数，提高算法运行效率。2.基于部分支持度树的关联规则增量式更新算法IUPS_Miner,关联规则的挖掘算法通常假定数据库是静态的，在阈值固定的情况下，如果数据库发生变化，算法需要通过重新进行数据库扫描和计算来得到新的规则。本文针对阈值不变而数据库发生变化时的关联规则维护问题，提出了基于部分支持度树PS_Tree结构的关联规则增量式更新算法IUPS_Miner，该算法只需对新增数据库进行挖掘，通过合并已有的和新增的部分支持度树生成新的部分支持度树，来减少对原数据库的扫描和重复计算，有效地维护了已挖掘的关联规则，提高算法的效率。3.关联规则的动态维护算法ARDM,关联规则的动态维护是指当数据库和支持度阈值同时发生变化的情况下，关联规则的维护与更新问题。现有的挖掘方法普遍存在多次扫描数据库或重复遍历复杂数据结构的问题。本文针对数据库与支持度阈值同时发生变化的情况，提出一种基于关联规则交互挖掘和增量挖掘的动态维护算法ARDM，该算法利用已有的挖掘结果进行交互挖掘和增量挖掘，即在原来的数据库中使用新的支持度阈值进行交互挖掘；然后在新增加的数据库中使用新的支持度阈值进行增量挖掘，并通过Hash结构与模式增长方法进行优化，进一步提高算法的效率。4.关联规则交互挖掘算法在企业财务风险分析中的应用,企业财务风险分析的研究是通过建立财务风险指标体系，寻找指标体系中具有信任度高的规则，为企业的管理决策提供帮助。传统的财务风险分析方法通常采用统计分析模型，存在的缺点是假设条件多，无法处理海量数据。本文针对上述问题，提出了关联规则交互挖掘的方法，更加广泛的选择多个方面的财务指标，通过挖掘所有财务指标之间的规则，最终确定选择更具有代表性的财务风险指标。首先，构建财务风险分析指标体系，通过变量相关性分析进行指标筛选；然后，提出企业财务风险概念层次树模型，并采用递减支持度阈值的交互挖掘策略，寻找财务风险指标之间的规则；最后，选择国内上市企业中的ST公司进行企业财务风险分析的实证研究，提出了影响企业财务风险的十个关键指标和防范财务风险的建议。5.时间序列动态维护挖掘算法在企业财务危机预警中的应用企业财务危机预警的研究主要是跟踪财务指标波动和变化趋势，当指标波动超出一定的范围，系统就应该发出危机预警。现有的企业财务危机预警的方法主要是基于人工智能数据挖掘模型，存在的缺点是没有考虑到财务指标数据的时间延续性。本文针对财务指标数据具有时间序列特征，提出了基于时间序列动态维护的企业财务危机预警模型。首先，构建时间序列财务数据挖掘模型；然后，采用时间序列增量挖掘和交互挖掘策略，进行关联规则的动态维护挖掘，寻找财务指标之间的规则和预测危机企业的发展趋势；最后，选择国内上市企业中的ST公司进行财务危机预警的实证研究，提出了定性和定量进行财务危机预警的方法，并给出了危机企业不同阶段的关键指标。
[28]朱林.基于特征加权与特征选择的数据挖掘算法研究[D].导师：杨杰.上海交通大学,2013.
关键词:数据挖掘,特征加权,聚类分析,特征选择,生物信息学
摘要:数据挖掘是目前人工智能和数据库领域的研究热点。几十年来各种不同的数据挖掘方法得到了广泛的研究。数据挖掘不仅是数据库知识发现中的一个重要步骤，从数据库的大量数据中，自动搜索隐藏于其中有价值的规律信息；也是一种决策支持的过程，利用人工智能、机器学习、模式识别、统计学、可视化等技术，分析各种类型的数据，从中挖掘出潜在的模式，帮助各个领域的专家及研究和开发人员做出正确的决策判断。目前，数据挖掘作为一门迅速发展的研究领域，面临着越来越多新的问题和挑战。首先，数据的规模越来越大，也就是所谓的大规模数据的问题；其次，数据特征的维数不断增加，导致出现所谓的维数灾难的问题；最后，数据挖掘越来越强调多学科的交叉，不仅需要灵活运用统计学、计算机、数学等建模技术，同时还需要具有生物学、脑科学、证券金融等学科的知识背景。针对上述的挑战，人们提出了针对大规模数据的流数据分析方法；针对高维数据的特征加权和特征选择方法；同时，生物信息学等交叉学科也成为目前数据挖掘领域的研究重点。本文围绕特征加权和特征选择这一主题，在研究和借鉴现有算法的基础上，针对上述问题，提出了一系列新算法、改进算法、以及新的应用。文本所研究的内容主要涉及两个方面，即针对特征加权技术的软子空间聚类算法的研究与改进，以及利用特征选择方法的分类技术的研究与应用。特别是针对当前数据挖掘领域所面临的大规模数据的问题、高维数据特征加权和特征选择的问题，以及多学科交叉的问题，都进入了深入地研究和探讨。本文提出的算法被成功应用于信息检索中的文本聚类、基因表达数据聚类、人脸识别与分类以及生物信息学中二硫键连接模式预测等实际问题，很好地验证了所提算法和技术的有效性。具体而言，本文的研究内容和创新性成果主要在于：1)本文针对高维大规模数据或者流数据的子空间聚类问题，利用在线学习策略和模糊可扩展聚类技术，与现有的软子空间聚类算法相结合，提出了两种在线软子空间聚类算法（OFWSC、OEWSC）和两种流数据软子空间聚类算法（FuStreCA、EnStreCA）。2)本文提出了一种新颖的多目标优化软子空间聚类算法（MOSSC），利用多目标优化技术，分别优化软子空间聚类方法中的类内、类间两个目标函数，并利用加权子空间二部图划分方法对所得的非占优Pareto最优解集进行分析，推导出最终的聚类划分结果。3)本文针对软子空间聚类算法面临的数据簇数目不确定和聚类中心初始化两个问题，将模糊和熵加权软子空间聚类算法与竞争合并策略相结合，提出了基于竞争合并策略的模糊加权软子空间聚类算法（FWSCA）和熵加权软子空间聚类算法（EWSCA）。4)本文利用稀疏表示的思想和L1范数最小化的方法，提出了一种新颖的基于稀疏分数（Sparse Score）的特征选择方法，通过构造样本间的稀疏表示重构系数矩阵，计算数据集中各个特征的稀疏表示保留能力，从而对数据集的特征重要性进行排序。5)本文针对生物信息学中二硫键结构模式的预测问题，通过利用四种基于分数方程的特征选择方法得到蛋白序列全局特征和局部特征的特征子集，并利用SVR方法在得到的特征子集上进行二硫键连接模式的预测。同时，本文利用得到的特征选择结果分析了蛋白序列全局特征和局部特征的重要性。
[29]宝腾飞.面向移动用户数据的情境识别与挖掘[D].导师：陈恩红.中国科学技术大学,2013.
关键词:移动设备,情境建模,情境识别,关键地点,情境挖掘
摘要:随着移动互联网的兴起,移动设备成为用户使用互联网服务的新途径。通过挖掘移动设备上的情境数据对用户建模是一种新颖的理解用户需求的方案,从而能为互联网服务方提供个性化、情境感知化的服务奠定基础。这里的情境数据指移动设备上的众多传感器探测到的环境和用户行为信息。本文的研究主题是面向移动用户数据的情境识别与挖掘,主要成果如下：1.提出了使用非监督学习模型对用户情境建模的技术方案：对于用户情境建模问题,由于难以获取情境标识,因而监督学习模型难以适用。鉴于此,本文使用非监督学习模型通过情境数据自身性质挖掘用户的情境。本文提出的方案包括两个步骤。在数据预处理步骤中,对用户情境数据日志提取情境会话,由于情境会话间没有明显的分界标识,本文使用了一种最小熵算法来切分情境数据日志；在数据建模步骤中,本文使用了聚类和概率主题模型来挖掘用户情境。通过聚类模型挖掘用户情境的方式为,首先将情境会话映射到情境特征-值组合空间上,然后对情境会话使用K-means算法聚类,最后从聚类结果提取用户情境。通过概率主题模型挖掘用户情境的方式为,首先对其进行扩展从而适应情境数据的结构化特性,然后将情境会话表示成概率主题模型中的变量,最后通过Gibbs采样算法求解模型从而学习用户情境。在真实用户情境数据集上的实验分析表明了该技术方案的有效性。2.提出了通过基站标识数据挖掘用户关键地点的技术方案：关键地点是用户最重要的情境。以往的研究工作主要集中于通过GPS数据挖掘关键地点,然而由于常时间开启GPS传感器会比较耗电,从而影响设备续航时间。鉴于此,本文提出通过基站标识数据挖掘用户关键地点。根据基站的地理位置信息,以及利用基站覆盖范围彼此重叠的特性,本文提出了一个两阶段的关键地点挖掘算法。在在线阶段,检测用户的停留状态,并计算停留区域以及更新停留区域中的地理格栅的热度值；在离线阶段,通过一个递归方法挖掘出用户关键地点。为验证该技术方案的实际应用性,本文还开发了一个演示系统。最后,实验结果表明该方案在用户关键地点的查全率和查准率均高于基准方法。3.监督式情境识别方案的难点在于难以获得大量高质量的情境标识数据。本文提出了结合时间管理软件实现用户情境识别的技术方案。时间管理用户经常面临记录反复发生的情境状态的情况,很多用户厌烦这种重复操作因而放弃了时间管理。本文提出了一种半监督学习方案,通过结合用户时间管理应用中的情境状态记录数据,使用HMM模型来实现用户情境识别,并提出了DP-MUC模型来自动化确定用户情境数目和加速HMM模型的训练时间。最后,同基准算法相比,在真实用户的情境状态记录数据上的实验结果表明该方法具有较好的效果和较高的效率。
[30]李楠.基于关联数据的知识发现研究[D].导师：张学福.中国农业科学院,2012.
关键词:关联数据,知识发现,关联发现,关联数据查询,数据挖掘
摘要:网络资源环境面向结构化、语义化和智能化的方向不断地发展，最终目标是实现语义网。近年来，关联数据已经被W3C推荐为语义网的最佳实践，它实质性地促进了面向语义网的网络变革。关联数据的发展和广泛应用使得“数据网络（关联数据网络）”资源环境呈现在我们面前。这一网络资源环境具有明显地特点和优势，并且为人工智能、知识发现等领域的应用提供了巨大地潜力。但如何发挥这些潜力和优势实现知识发现的应用，是当前研究需要解决的问题。本研究按照文献调研、分析思考、理论研究、应用研究和实践验证的思路，首先识别了基于关联数据的知识发现问题，继而采用综合分析的方法，通过相关基础理论的分析与讨论，解析了基于关联数据的知识发现过程，建立了基于关联数据的知识发现的模型；然后，面向知识发现的应用，分析了基于关联数据的知识发现应用中的主要功能和它们之间的关系，构建了基于关联数据的知识发现应用体系；最后，根据综合分析和应用体系的研究成果，设计了基于关联数据的应用系统模型，并且针对基于关联数据的知识发现应用进行了实验与验证。基于关联数据的知识发现问题源于充分利用关联数据资源和实现知识发现，以及通过知识发现促进网络发展的双重需求。知识发现活动和关联数据网络的发展需要两个领域的理论和应用体系的融合和扩展。在基于关联数据的知识发现综合体系中，关联数据是数据、是网络资源环境、是数据发现工具，为知识发现注入新的活力；知识发现是一般规律、是解决问题的支点和方法、是关联数据网络资源环境上知识活动的目标，帮助实现关联数据的最佳潜力。基于关联数据的知识发现问题研究从知识发现理论研究和关联数据应用研究两个方面入手，结合对科学研究的一般规律和应用发展的特殊需求的分析展开。本研究通过对关联数据基本特征和应用特征的分析，识别了关联数据对知识发现的影响和为知识发现提供的潜力，推知了基于关联数据的知识发现的基本特征和潜力；根据特征的分析，结合知识发现的一般规律，分析了基于关联数据的知识发现过程，并且在此基础上，进一步分析和构建了基于关联数据的知识发现模型。知识发现与关联数据都是重要的实践方法，二者结合的目标也在于指导新的网络环境下的知识发现活动，因此相关应用体系的研究具有重要的实践意义。本研究分析了基于关联数据的知识发现的主要任务，从而构建了综合应用体系模型。通过应用体系，明确了基于关联数据的知识发现应用的层次、结构、目标、主要功能以及各要素之间的关系。在基本规律分析和应用体系研究基础上，本研究进行了基于关联数据的知识发现应用系统原型的设计，并且根据原型进行了系统实现与验证。应用系统原型设计充分利用了理论分析和应用体系研究的成果，提出了一个以模式整合为核心的应用系统模型，能够更好地支持基于关联数据的知识发现活动。本研究构建了以关联数据为底层支撑和逻辑控制，以知识发现作为流程和结构的控制，以关联数据的应用功能为关键操作控制的基于关联数据的知识发现模型。该模型抽象了基于关联数据的知识发现活动的新规律。本研究也面向知识发现的应用和实现，分析和构建了基于关联数据的知识发现应用体系，这一体系可以作为整合已有研究和应用成果和未来相关工作的框架。在基本规律分析和应用体系研究的基础上，本研究设计了基于关联数据的知识发现应用系统的原型。原型设计可以作为知识发现系统开发的框架，并且为相关研究工作提供借鉴。根据研究的结果，本研究组织了实验环境并且实现了基于关联数据的知识发现实验系统，并且使用系统实现了关联数据挖掘和关联规则的发现，验证了本研究的理论和系统设计框架及部分功能。基于关联数据的知识发现研究延伸了知识发现研究的理论体系，同时也加强了关联数据的应用研究。通过综合分析和研究揭示了基于关联数据的知识发现的新规律，为未来的应用开发和实践提供了基础和借鉴。本研究的目标是解析关联数据对于知识发现效率和能力的影响，实现关联数据背景下的知识发现。同时促进二者之间的相辅相成和不断优化，实现对关联数据发展乃至语义网发展的促进。
[31]申彦.大规模数据集高效数据挖掘算法研究[D].导师：宋顺林.江苏大学,2013.
关键词:大规模数据集,关联规则,磁盘FPTP.EE,大规模数据集挖掘,半监督学习,大规模可扩展EM算法,概率聚类
摘要:信息技术的飞速发展以及广泛应用使得企业、政府部门以及其他各种形式的组织积累了大量的数据。过去简单的查询、统计技术仅仅能对数据进行基本的处理,不能进行更高层次的分析,从而自动和智能地将待处理的数据转化为有用的知识。数据挖掘正是在这样的背景之下得到广泛重视和深入研究并取得重大进展的重要研究领域。数据挖掘(Data Mining)是一个从数据中提取隐含在其中的、人们事先不知道的、具有潜在价值的知识的过程。数据挖掘被称为未来信息处理的骨干技术之一。目前,数据挖掘不仅被许多研究人员看作是模式识别以及机器学习等领域的重要研究课题之一,而且被许多产业界人士看作是一个能带来巨大回报的重要研究领域。数据是相当庞杂的,但是从中发现的模式、知识却是非常有意义的,并能产生一定的经济效益。随着信息技术更进一步的发展,数据库应用的规模、范围不断地扩大,加之数据采集技术的更新,企业和政府利用计算机管理事务能力的增强,产生了更加庞大的大规模数据集。大规模数据集的出现使得有些原本有效的数据挖掘算法在处理这样的数据集时出现了很多新的问题,有待进一步研究加以解决。比如原本很多数据挖掘算法在数据集规模较小时尚能取得不错的挖掘结果。但是针对大规模数据集,计算量太大以至于不能在可接受的时间内获得挖掘结果。甚至会出现由于大规模数据集无法整体读入内存或者是算法执行过程中对内存的占用超过系统可用内存,而使得许多原本有效的挖掘算法不能成功执行的情况。为了提高挖掘效率而采用的一些技术手段比如采样、特征概括等等又使挖掘结果的质量产生了一定程度的下降。本文在对现有数据挖掘算法相关研究进行总结的基础之上,着重针对在处理大规模数据集时关联规则挖掘算法的内存瓶颈问题以及聚类算法的挖掘质量和效率较低的问题进行了详细的分析和研究。论文的研究工作主要包含以下几个方面：(1)介绍了数据挖掘领域的聚类以及关联规则挖掘的重要研究成果。追踪了现有大规模数据集挖掘的聚类以及关联规则挖掘研究的最新进展、现存的关键问题以及发展方向。在研究总结的基础之上,对比了现有算法的特点以及各自的优缺点,得出了现在该领域所面临的新挑战。(2)针对大规模数据集关联规则挖掘时的内存瓶颈问题,提出了一种基于磁盘表存储FPTREE的大规模数据集关联规则挖掘算法(disk table resident fptree growth,简称DTRFP_GROWTH).该算法改进FPGROWTH,借助于轻量级数据库在挖掘过程中对中间过程的FPTREE进行了存储,降低了内存的占用,实现对大规模数据集、低用户支持度的关联规则挖掘。(3)进一步优化存储机制、提高挖掘效率,直接利用B+树对磁盘FPTREE进行部分存储,提出了一种基于B+树磁盘存储部分FPTREE的大规模数据集关联规则挖掘算法(disk resident B+tree fptree mining,简称DRBFP_MINE).该算法实现了部分FPTREE的B+树索引,提高了FPTREE结点的存取效率,可在内存不够时进行FPTREE的部分存储,降低挖掘过程中的内存占用。除此之外,该算法还进一步优化了FPTREE的存储机制和存储策略,不再对整个FPTREE进行存储,而是采用后进先出的方式,自下而上地对FPTREE进行部分存储,进一步提高了算法的执行效率。(4)针对大规模数据集聚类挖掘结果质量不高、不稳定以及收敛较慢的问题,提出了一种基于标记集指导的半监督一遍扫描K均值聚类算法(semi-supervised labels onescan kmeans,简称SSLOKmeans).以往处理大规模数据集的聚类算法,由于受到核心算法的内在局限性以及为了处理大规模数据集而采用的特征概括以及采样等技术的限制,往往会存在聚类结果质量不高、聚类结果质量不稳定以及算法收敛较慢等问题。本研究工作吸收半监督学习的思想,把LABELS标记集和大规模数据集聚类框架进行整合,提出了SSLOKmeans算法。该算法利用驻留主存的标记集辅助指导整个聚类过程,使得大规模数据集的聚类效率以及聚类结果的质量得到了进一步的提高。(5)在前面的研究基础之上,针对大规模数据集的概率聚类展开研究,提出了一种基于部分约束信息的大规模数据集EM概率聚类算法(Scalable EM probability clustering algorithm for massive data sets based on partial constraints information,简称PC_SEM).前期的研究工作主要针对确定性聚类,即某个数据仅能唯一归属于某一个类别。但在实际工作的聚类过程中,很多情况下某一个对象会以一定的概率同时归属于几个类别。反映到对应的数据集中往往表现为数据集分离得不是很明显,存在一定程度的重叠。以往的概率聚类研究主要针对较小规模的数据集,在处理大规模数据集时往往会出现聚类结果质量不稳定、聚类结果质量不高等问题,且算法收敛较慢,算法性能有待进一步的提高。融入半监督学习的思想,提出了PC SEM算法。该算法利用可以通过数据集自动获取的部分约束信息指导聚类过程,使得大规模数据集概率聚类的效率以及聚类结果的质量得到了进一步的提高。本文对大规模数据集挖掘进行的研究有助于解决关联规则挖掘时的内存瓶颈问题,提高聚类算法的执行效率以及结果的质量,对以后相关的研究工作也有一定的借鉴意义。
[32]李巍.半结构化数据挖掘若干问题研究[D].导师：李雄飞.吉林大学,2013.
关键词:数据挖掘,半结构化数据,频繁模式,动态频繁模式,文档聚类,民族织物模型
摘要:随着计算机网络的发展，半结构化数据因其层次性、自述性、动态可变性等特点，被广泛应用。网络上的HTML文档、XML文档、SGML文档、Web数据以及由异构数据集成而产生的数据等都是半结构化数据。半结构化数据编码方式与结构化数据（如关系型数据库中的数据、Excel数据等）不同。面对海量的半结构化数据，传统的数据挖掘算法不能够很好地利用其自述性、动态可变性和层次性等特点。传统的结构化数据处理技术并不适用于半结构化数据，所以，有必要研究挖掘半结构化数据的新方法。本文根据半结构化数据的特点，以XML文档和树形数据结构为例，主要研究半结构化频繁模式、动态频繁模式、聚类、动态数据集聚类和民族织物模型等领域，并提出解决半结构化数据挖掘若干问题的方法。为了有效的挖掘树形结构数据集频繁模式，本文首先提出压缩链结构，压缩链可映射为无序标签树，之后提出基于压缩链的压缩树模型，压缩树节点标签是一压缩链结构，因此可对压缩树进行压缩而不丢失原树信息。进一步，提出一种带有数据集压缩的频繁闭合诱导子树挖掘方法CITMinerC。CITMinerC算法基于模式增长策略，首先对原始数据集进行压缩树建模并进行剪边预处理，然后反复迭代数据集将最大频繁度的边压缩为单压缩节点并将边信息保存在压缩节点的压缩链中，最后对压缩链进行闭合化，得到原始数据集的频繁闭合诱导子树集。CITMinerC优点在于随最小频繁度阈值降低计算量成线性增长。实验表明，在人工数据集及真实数据集上进行频繁子树挖掘，CITMinerC算法均优于DryadeParent算法。XML数据在实际使用过程中不断发生改变，针对XML数据动态可变的特点，提出一种根据XML数据变化过程挖掘XML空间频繁变化结构SFCS（Spatial FrequentlyChanging Structure）的方法，首先提出XML子结构空间度量方法，通过结构空间变化度SSCD、版本空间变化度VSCD和空间变化程度SCD三个度量值衡量XML子结构的空间变化频繁性并提出SFCS定义。进一步，提出一种用于保存XML空间变化信息和发现SFCS的数据模型SC-DOM，论证了XML编辑操作对子结构空间的影响并据此提出SC-DOM状态动态迁移方式，最后提出根据SC-DOM发现SFCS的算法并讨论算法复杂度。实验结果表明SFCS是频繁的，使用SC-DOM模型进行SFCS挖掘是有效且可扩展的。以XML为代表的半结构化数据的处理与管理是比较热门的研究课题。目前关于XML文档数据集聚类的方法大多忽略XML层数特性，认为不同层数操作是等费用的。本文提出一种层数敏感的XML文档数据集聚类方法CXLI。首先提出结构表概念，消除XML文档的重复和嵌套结构。然后提出考虑层数信息的XML文档基本编辑操作约束。进一步给出考虑层数信息的XML文档间相似性度量方法。最后使用凝聚型层次聚类方法对XML文档数据集进行聚类。实验在ACM SIGMOD数据集和人工生成的数据集上进行，实验结果表明，在基本相同的时间消耗情况下，CXLI方法具有更好的精确度。在实际应用中，XML文档中的一些结构经常被改变。为了挖掘XML文档在历史变化过程中经常改变的结构所蕴含的知识，本文首先提出了发现频繁变化结构的方法，然后使用一组频繁变化结构组成的文档向量模型代表一个XML文档，将频繁变化结构在簇中的出现比例作为权值，使用加权余弦相似度对XML文档进行聚类。经过实验分析，根据XML文档历史变化过程中的频繁变化结构能够较好的将XML文档进行聚类。使用加权余弦相似度对XML文档进行聚类，聚类结果的正确率、召回率和簇内部距离均优于使用非加权余弦相似度对XML文档进行聚类得到的结果。所以使用加权余弦相似度对XML文档进行聚类是有效的。少数民族民间织物图案蕴含大量民族文化信息。目前，民族织物图案使用位图格式存储，进行精确的数据挖掘存在较大难度。本文首先讨论民族织物图案形状特点，提出带有文化信息的矢量图基因模型。进一步，讨论民族织物图案基因组成的构图模式，提出一种基于半结构化数据的民族织物图案模型，该模型描述民族织物图案的外形信息、文化信息和基因间关系信息。经实验证明，本文模型能够正确完备的描述以哈萨克族、柯尔克孜族、蒙古族和维吾尔族为例民族织物图案，并具备数据挖掘能力。
[33]王冠男.基于GPS轨迹和照片轨迹的时空数据挖掘[D].导师：王志忠.中南大学,2013.
关键词:时空数据挖掘,GPS轨迹,Geo-信息照片轨迹,轨迹相似度,重尾分布,隐半马尔可夫模型,生存分析
摘要:现代信息技术和位置感知技术迅猛发展,人们能够方便的获得各种移动物体的轨迹数据。通过分析轨迹数据可以获得很多有价值的信息,并且推断出新的知识。许多基于位置推荐的门户网站已经引起了大众和研究者的关注,关于轨迹数据挖掘的研究也逐渐变得炙手可热。轨迹数据时时空数据的重要分支,本文主要研究了基于GPS轨迹以及照片轨迹的时空数据挖掘方法,采用多种统计方法挖掘轨迹之间的相似度、旅游者的行走模式等有价值的信息,通过针对真实数据进行实验,证明了方法在实践中的高效性。本文的研究工作主要包含如下四个方面：1)提出度量GPS轨迹相似度的几何算法(GSAs)。轨迹相似度算法能够提炼移动轨迹之间的相似信息,这些信息在城市道路网、交通和地理信息系统中发挥着很重要的作用。首先提出LAR定义(Length-Angle Ratio),用来简化GPS轨迹并检测其中的重点区域(sig-region);然后按照重点区域将轨迹分段,分别使用向量法和面积法计算轨迹中各段之间的差异性；最后通过综合分析这些差异性得到GPS轨迹的相似度。算法的优势在于三方面,首先,当GPS点缺失时,算法仍然有效；其次,GSAs应用了真实距离,体现了轨迹的几何特征,并且在以往研究的基础上充分考虑了每个用户和轨迹的独特性以及交通网的特征；最后,试验证明GSAs在精确度和时间复杂度上均优于其它现有算法。2)提出路线还原方法,将非连续Geo照片轨迹(带有地理位置信息的照片轨迹)还原成连续的GPS轨迹。GPS轨迹占据存储空间大,不易处理,原始Geo照片轨迹虽然易储存,但是不能提供和GPS轨迹同样丰富的信息,将Geo照片轨迹还原为GPS轨迹可以同时解决以上难题。本文首先提出区域兴趣度比,将景点排序。然后应用隐半马尔可夫模型(HSMM)解释旅游者的迁移规律,得到重要区域序列,在此基础上,提出均值算法将重要区域序列还原成完整的GPS序列。最后,提出基于留一交叉检验(LOOCV)的试验方法,检验还原路线与GPS路线的契合性,并且证明得到的连续GPS轨迹符合人群行走基本规律。3)挖掘照片轨迹的统计特征以及时空规律。人群行走活动的基本规律在路线规划、目的地预测和推荐系统中具有举足轻重的作用。首先,通过挖掘行走活动的共同统计特征,发现照片轨迹的一些变量符合对数正态分布,继而服从重尾法则,这些变量包括LAR,重要区域间的距离以及用户在重要区域的停留时间。其次,照片轨迹表现出高度的时空规律,本文主要从三方面来进一步研究这一问题：①重要区域间的距离符合对数正态分布的原因；②影响用户选择目的地的因素；③均方位移在照片轨迹中的特征。真实数据结果证明这些共同的统计特征和时空规律在不同的区域中是相同的。4)用生存分析的方法解决轨迹问题中删失数据的问题。已知在轨迹数据挖掘中存在删失数据的问题,传统模型不适用于这类数据,需要建立相应的删失数据模型。照片轨迹中照片之间的时间间隔为右删失数据,本文以这一数据为例,首先用Kaplan-Meier估计建立非参数模型,研究相应的生存模型和危险率模型。然后建立时间间隔关于拍照停留时间的Buckley-James模型,并且用经验似然的方法估计参数的置信区间。最后建立时间间隔关于拍照停留时间以及用户个人信息的半参数模型,并且提出基于删失数据的经验似然方法,得到经验似然函数比,证明渐进分布为标准卡方分布,简化了置信区间的求解步骤。轨迹挖掘技术为快速发展的信息技术做出了杰出的贡献,而迅猛发展的信息技术又为轨迹数据挖掘提供了更广阔的发展空间,两者相辅相成。本文提供了高效易行的方法和技术,所得到的研究和技术成果并不仅仅可局限于轨迹数据挖掘领域,方法和技术的相关算法可以应用到其它研究领域。本文所做的相关分析研究不仅丰富了轨迹数据挖掘领域的技术,并且对很多现实问题具有指导意义。
[34]王乐.数据流模式挖掘算法及应用研究[D].导师：冯林.大连理工大学,2013.
关键词:数据挖掘,关联规则,频繁模式,高效用模式,不确定数据集,数据流,大数据集
摘要:随着各行业对数据越来越重视和信息技术的快速发展,产生的数据越来越全面,同时数据量也在快速的增长；并且各行业又要求能及时对已产生的数据进行挖掘和分析,这使得数据流挖掘技术愈发重要。由于数据流具有海量性、实时性和动态变化性的特点,这就要求数据流上的挖掘算法有较高的时空效率。尽管数据流上数据挖掘技术取得了一定的进展,但是挖掘算法的时空效率仍然是当前数据挖掘领域中的研究焦点之一。本文主要研究了数据流模式挖掘算法,包括传统数据集类型中的频繁模式挖掘以及大数据集下的频繁模式挖掘、不确定数据流中的频繁模式挖掘、和高效用模式挖掘。本文首先对已有的频繁模式和高效用模式挖掘算法进行了回顾,详细的介绍了算法Apriori和FP-Growth等；然后在对典型的挖掘算法和最新研究成果进行分析研究的基础上,深入研究了传统数据中的频繁模式挖掘、不确定数据上的频繁模式挖掘和具有效用值的数据中的高效用模式挖掘算法。本文取得了如下的创新性研究成果：(1)在传统数据的频繁模式挖掘算法研究中,提出新的尾节点数据结构和一种最多两次MapReduce的并行挖掘算法。针对数据流中的频繁模式挖掘问题,采用尾节点和尾节点表来提高窗口内数据更新的时间效率和维护的空间效率；并通过提高窗口内频繁模式挖掘算法的时间效率,进而提高数据流中模式挖掘的整体时间效率。针对大数据下的数据流频繁模式挖掘问题,首先通过一次MapReduce找到局部频繁模式做为候选项集,然后通过给出的剪枝策略对候选项集进行剪枝,最后进行第二次MapReduce对候选项集中剩余项集进行支持数统计；在多数情况下,该算法不需要第二次MapReduce就可以有效的挖掘到所有的频繁模式。(2)在不确定事务数据的频繁模式挖掘算法研究中,提出具有更高压缩率的树结构来改进不确定数据集及数据流上的频繁模式挖掘算法。首先利用数组来存储事务项集的概率,然后将事务概率在数组中的索引和事务项集映射到一棵树上,从而可以有效的降低维护不确定数据集的树节点个数。在此基础上,结合滑动窗口技术,同时给出两种新的树结构分别来维护窗口中数据和挖掘过程中的子数据集,保证在挖掘的过程中使窗口中事务项集的信息不会从树上丢失；从而使频繁模式挖掘算法的时空效率得到较大的提升。另外,本文还提出一种新的具有权重的频繁模式挖掘模型和算法；该模型主要是将项的权重值引入到频繁模式的挖掘过程中,将权重值大的模式考虑到挖掘结果中。(3)在高效用模式挖掘算法研究中,提出避免使用高估效用值的不产生候选项集的挖掘算法。首先本文提出一个新的树结构来维护事务项集及效用值信息,通过该树结构可以得到项集的准确效用值,而不是高估效用值,从而保证不通过候选项集就可以挖掘到所有的高效用模式,因此可以提高算法的时空效率。在此基础上,结合滑动窗口技术,同时给出一个新的树结构维护窗口中数据,可以使算法通过一遍数据集扫描,在不产生候选项集的前提下就可从数据流中挖掘高效用模式。相对KDD会议和TKDE期刊上最新发表论文UP-Growth算法,新提出的算法的时间效率提高1到2个数量级。
[35]王惠中,彭安群.数据挖掘研究现状及发展趋势[J].工矿自动化,2011, 02:29-32.
关键词:数据挖掘,挖掘算法,神经网络,决策树,粗糙集,模糊集,研究现状,发展趋势
摘要:从数据挖掘的定义出发,介绍了数据挖掘的神经网络法、决策树法、遗传算法、粗糙集法、模糊集法和关联规则法等概念及其各自的优缺点;详细总结了国内外数据挖掘的研究现状及研究热点,指出了数据挖掘的发展趋势。
[36]胡文瑜,孙志挥,吴英杰.数据挖掘取样方法研究[J].计算机研究与发展,2011, 01:45-54.
关键词:数据挖掘,均匀取样,偏倚取样,数据流,概要数据结构
摘要:取样是一种通用有效的近似技术.在数据挖掘研究中,取样方法可显著减小所处理数据集的规模,使得众多数据挖掘算法得以应用到大规模数据集以及数据流数据上.通过对应用于数据挖掘领域的代表性取样方法的比较研究和分析总结,提出了一个取样算法分类框架.在指出了均匀取样局限性的基础上阐述了某些应用场景中选用偏倚取样方法的必要性,综述了取样技术在数据挖掘领域的应用研究与应用发展,最后对数据流挖掘取样方法面临的挑战和发展方向进行了展望.
[37]程苗.基于云计算的Web数据挖掘[J].计算机科学,2011, S1:146-149.
关键词:云计算,数据挖掘,Map/Reduce,关联规则
摘要:因特网是一个巨大的、分布广泛的信息服务中心,其上产生的海量数据通常是地理上分布、异构、动态的,复杂性也越来越高,若用已有的集中式数据挖掘方法则不能满足应用的要求。为了解决这些问题,提出了一种基于云计算的Web数据挖掘方法:将海量数据和挖掘任务分解到多台服务器上并行处理。采用Hadoop开源平台,建立一个基于Apriori算法的并行关联规则挖掘算法来验证了该系统的高效性。还提出"计算向存储迁移"的设计思想,将计算在数据存储节点就地执行,从而避免了大量数据在网络上的传递,不会占用大量带宽。
[38]郁抒思,周水庚,关佶红.软件工程数据挖掘研究进展[J].计算机科学与探索,2012, 01:1-31.
关键词:软件工程,数据挖掘,数据表示,数据预处理,机器学习
摘要:随着计算机软件的规模不断扩大,手工获取、开发和维护软件所需的信息越来越困难。数据挖掘技术可从软件工程数据中自动发现所需信息,加快软件开发进程。对软件工程数据挖掘的研究进展进行了综述。概述了软件工程数据挖掘的基本概念与技术挑战;详细评述了在软件工程各个阶段,数据挖掘技术所能发现的信息/知识,以及获取这些信息/知识的意义、难点、步骤和方法,重点介绍了数据预处理和数据表示方法;对软件工程数据挖掘研究的发展趋势进行了展望。
[39]丁悦,张阳,李战怀,王勇.图数据挖掘技术的研究与进展[J].计算机应用,2012, 01:182-190.
关键词:数据挖掘,图数据,聚类,分类,频繁模式,不确定图
摘要:生物信息学(蛋白质结构分析、基因组识别)、社会网络(实体间的联系)、Web分析(Web链接结构分析、Web内容挖掘和Web日志搜索)以及文本信息检索等的迅速发展积累了大量图数据,对于图数据的挖掘逐渐成为研究领域的热点。一些诸如聚类、分类、频繁模式挖掘的传统数据挖掘研究逐渐拓展到图数据领域。通过介绍现阶段图数据挖掘技术的研究进展,总结了图数据挖掘的特点、现实意义、主要问题以及应用场景,讨论并预测了图数据,尤其是不确定图数据研究的发展趋势和热点。
[40]周涛,陆惠玲.数据挖掘中聚类算法研究进展[J].计算机工程与应用,2012, 12:100-111.
关键词:数据挖掘,聚类算法,聚类准则
摘要:聚类分析是数据挖掘中重要的研究内容之一,对聚类准则进行了总结,对五类传统的聚类算法的研究现状和进展进行了较为全面的总结,就一些新的聚类算法进行了梳理,根据样本归属关系、样本数据预处理、样本的相似性度量、样本的更新策略、样本的高维性和与其他学科的融合等六个方面对聚类中近20多个新算法,如粒度聚类、不确定聚类、量子聚类、核聚类、谱聚类、聚类集成、概念聚类、球壳聚类、仿射聚类、数据流聚类等,分别进行了详细的概括。这对聚类是一个很好的总结,对聚类的发展具有积极意义。
[41]葛道凯.E-Learning数据挖掘:模式与应用[J].中国高教研究,2012, 03:8-14.
关键词:教育信息化,E-Learning,数据挖掘,模式,应用
摘要:随着教育信息化的快速发展特别是数字化校园和网络高等教育的日益普及,教育领域中部署了众多的软件系统,在这些软件系统中存储着海量的教育数据。如何利用这些教育数据,使这些数据转变为信息、知识,并为教育决策、教学优化服务,可从E-Learning数据挖掘中找到一些答案。文章系统梳理了国内外E-Learning数据挖掘的研究进展,并采用格语法分析方法对"E-Learning"的关键要素和过程进行分析,提出可以"谁在学、学什么、怎么学、学得如何"这一系列问题为主线,开展E-Learning数据挖掘工作,从而获得对E-Learning现状的更加完整的认识。在尝试回答"谁在学、学什么、怎么学、学得如何"的过程中,分解出三类挖掘任务情境即用于回答"谁在学"的学习者特征挖掘,用于回答"学什么、怎么学"的学习过程挖掘以及用于回答"学得如何"的学习结果挖掘,并对应地构建出三种数据挖掘模式。对模式的应用结果表明,这三种数据挖掘模式在E-Learning要素和过程分析中是有效的,较好地拓展了对E-Learning关键要素认识的完整性,包括对"谁在学"有了更全面的认识、对"学什么、怎么学"有了更准确的认识和对"学习的结果如何"有了更深入的认识。
[42]张玉涛,李雷明子,王继民,王建冬.数据挖掘领域的科研合作网络分析[J].图书情报工作,2012, 06:117-122+134.
关键词:数据挖掘,科研合作网络,社会网络分析
摘要:基于SCI和SSCI数据库中以"数据挖掘"为主题的文献题录信息,构建三个科研合作网络(高校间、公司间、国家间),利用社会网络分析方法对这三个不同类型的网络特征进行对比分析。结果显示,数据挖掘领域的研究成果涉及众多研究方向,不同的机构实体有不同的研究重点,所构建的三个不同类型的科研合作网络在诸多网络特征上存在较大的差异,包括合作网络的密度、节点的平均度、最大成分的平均最短路径、最大成分的比重等。最后对部分高校与公司的研究重点进行具体分析。
[43]丁静,杨善林,罗贺,丁帅.云计算环境下的数据挖掘服务模式[J].计算机科学,2012, S1:217-219+237.
关键词:数据挖掘,服务,云计算
摘要:为了求解网络环境下分布式海量数据的分析处理、促进数据挖掘的开发集成和商业应用,提出了云计算环境下的数据挖掘解决方案,通过云环境计算能力和云计算服务模式,阐述了对数据挖掘服务问题的解决机理。云计算环境下的数据挖掘是一种网络环境下的信息资源服务模式。基于此,构建了数据挖掘服务的架构,设计了数据挖掘服务的创建流程,给出了数据挖掘服务模型的体系结构,并从生命周期的角度定义了数据挖掘的服务过程,从而形成了云计算环境下的数据挖掘服务模式。
[44]何清.物联网与数据挖掘云服务[J].智能系统学报,2012, 03:189-194.
关键词:物联网,云计算,数据挖掘,云服务
摘要:物联网与云计算是目前信息技术的研究热点,探讨数据挖掘在其中扮演的角色,以及与这2项技术相结合的方式.分析了数据挖掘在物联网中的地位和作用,指出了云计算是物联网的基石,剖析了分布式数据挖掘与并行数据挖掘的异同,说明了物联网中数据挖掘服务的提供方式.
[45]李海峰,章宁,朱建明,曹怀虎.时间敏感数据流上的频繁项集挖掘算法[J].计算机学报,2012, 11:2283-2293.
关键词:频繁项集,数据流,时间敏感,滑动窗口,数据挖掘
摘要:数据流中的数据分布随着时间动态变化,但传统基于事务的滑动窗口模型难以体现该特征,因此挖掘结果并不精确.首先提出时间敏感数据流处理中存在的问题,然后建立基于时间戳的滑动窗口模型,并转换为基于事务的可变滑动窗口进行处理,提出了频繁项集的挖掘算法FIMoTS.该算法引入了类型变化界限的概念,将项集进行动态分类,根据滑动窗口大小的变化对项集进行延迟处理,仅当项集的类型变化界限超出一定阈值的时候才进行支持度的重新计算,能够达到剪枝的目的.在4种不同密度的数据集上完成的实验结果显示,该算法能够在保证内存开销基本不变的情况下显著提高计算效率.
[46]李明江,唐颖,周力军.数据挖掘技术及应用[J].中国新通信,2012, 22:66-67+74.
关键词:数据挖掘,决策,统计分析
摘要:随着信息技术和数据库技术的快速发展和普及应用,信息化建设取得了长足的发展。信息收集能力得到提高,数据信息量快速增长,然而人们对这种大规模数据的分析、利用、决策能力却比较弱;仅仅依靠传统的数据查询和统计已经不能适应现代社会市场竞争的需要。而数据挖掘技术的出现满足了人们的需求,通过将海量的数据信息转化为有用的数据仓库,为各行各业的发展提供决策性的支持。
[47]万祥,胡念苏,韩鹏飞,张海石,黎师祺.大数据挖掘技术应用于汽轮机组运行性能优化的研究[J].中国电机工程学报,2016, 02:459-467.
关键词:大数据,Map Reduce,关联规则,性能优化,目标值,汽轮机组,运行
摘要:基于关联规则的数据挖掘方法已在火电厂汽轮机组的性能优化中取得了较好的应用,但随着大数据时代的来临,传统的数据挖掘方法由于自身缺陷已不能胜任海量数据的挖掘工作。针对此问题,在云计算环境下,基于引入粗糙集中属性约简的基础,在Hadoop平台的Map Reduce架构上对经典关联规则算法Apriori算法进行改进,实现计算并行化以形成能够应对海量数据挖掘任务的新算法。以某1000MW超超临界机组的运行数据为挖掘对象,利用新算法对典型负荷下的历史数据进行挖掘,挖掘出运行参数与性能指标之间的关系,并得到一些可调控参数的运行优化目标值以指导优化运行。挖掘结果表明,新算法可以应用于汽轮机优化目标值的确定,达到节能减排的目的,其所求出的优化目标值来源于机组实际运行数据,具有代表性,能够反映机组的最佳运行状态。
[48]潘定,沈钧毅.时态数据挖掘的相似性发现技术[J].软件学报,2007, 02:246-258.
关键词:数据挖掘,时态数据,相似性发现,时态规则
摘要:现实世界存在着大量的时态数据,时态数据挖掘(temporal data mining,简称TDM)是近年来学术界关注的一个重要研究课题.相似性发现技术关注数据的发展变化,试图从时态数据中发现事物动态演化的相似性规律.分析和比较了近年来TDM研究中涉及的主要相似性发现技术.首先区分定义了3类时态数据:时间序列、事件序列和交易序列;然后分类并讨论了各种与序列相关的主要方法和技术,涉及相似性度量、序列抽象表示和搜索,以及各类挖掘任务及其算法操作;最后展望进一步研究的方向.
[49]王伟平,李建中,张冬冬,郭龙江.一种有效的挖掘数据流近似频繁项算法[J].软件学报,2007, 04:884-892.
关键词:数据流,数据挖掘,频繁项,ε-近似
摘要:数据流频繁项是指在数据流中出现频率超出指定阈值的数据项.查找数据流频繁项在网络故障监测、流数据分析以及流数据挖掘等多个领域有着广泛的应用.在数据流模型下,算法只能一遍扫描数据,并且可用的存储空间远远小于数据流的规模,因此,挖掘出所有准确的数据流频繁项通常是不可能的.提出一种新的挖掘数据流近似频繁项的算法.该算法的空间复杂性为O(ε~(-1)),每个数据项的平均处理时间为O(1),输出结果的频率误差界限为ε(1-s+ε)N,在目前已有的同类算法中均为最优.
[50]陈星莺,张晓花,瞿峰,刘皓明,赵波.数据挖掘在电力系统中的应用综述[J].电力科学与技术学报,2007, 03:51-56.
关键词:数据挖掘,CRISP-DM模型,电力系统
摘要:电力系统各种数据现已呈现爆炸性增长态势,数据挖掘技术将会扮演越来越重要的角色.主要介绍数据挖掘技术及其相关的应用,以及数据挖掘的交叉产业标准(CRISP-DM)和主要方法.结合电力系统的自身特点,分析数据挖掘在电力系统当前的主要应用动态及应用前景.
[51]朱扬勇,熊赟.DNA序列数据挖掘技术[J].软件学报,2007, 11:2766-2781.
关键词:DNA序列,数据挖掘,生物信息学,序列模式,序列相似性
摘要:DNA序列数据是一类重要的生物数据.研究DNA序列数据解读其含义是后基因组时代的主要研究任务.数据挖掘是目前最有效的数据分析手段之一,用于发现大量数据所隐含的各种规律,也是生物信息学采用的主要数据分析技术.将数据挖掘技术用于DNA序列数据分析,已得到了广泛关注和快速发展,并取得了许多研究成果.综述了DNA序列数据挖掘领域的研究状况和进展,提出了3个研究阶段:基于统计的挖掘方法应用阶段、一般化挖掘方法应用阶段和专门的DNA序列数据挖掘方法设计阶段.阐述了DNA序列数据挖掘的基础是序列相似性,评述了DNA序列数据挖掘领域所采用的关键技术,包括DNA序列模式、关联、聚类、分类和异常挖掘等,分析讨论了其相应的生物应用背景和意义.最后给出DNA序列数据挖掘进一步研究的热点问题,包括DNA序列数据新的存储和索引机制的设计、根据生物领域知识的数据挖掘新模型和算法的设计等.
[52]祝恒书.面向移动商务的数据挖掘方法及应用研究[D].导师：陈恩红.中国科学技术大学,2014.
关键词:移动用户,移动商务,移动App,情境感知,推荐系统
摘要:近年来,随着移动互联网相关技术的高速发展,各种移动应用和服务在规模上呈现出前所未有的增长态势。种类繁多的移动应用和服务覆盖了诸如生活娱乐、在线社交、导航定位等各种功能层面,从而满足了移动用户在日常生活中各式各样的功能需求。与此同时,这些移动应用和服务也产生了海量的用户交互记录与历史商务数据,为研究者深入探索移动商务环境下的潜在价值、开发全新的移动商务应用和服务带来了全新的机遇和挑战。事实上,针对移动商务智能的研究方兴未艾,近年来在国际学术界和产业界均受到广泛的重视。基于以上背景,本文开展了针对移动商务的数据挖掘方法的一系列探索性研究。具体地,结合来自于智能移动应用程序(简称移动App)的新型商务数据,从用户理解、应用理解、应用孵化等三个层面开展了研究工作。基于这三个层面,分别提出了情境感知的移动用户个性化偏好挖掘方法、基于扩展信息的移动App分类方法、面向移动App的排名欺诈检测方法、面向移动App的流行度建模方法、安全隐私感知的移动App推荐方法等探索性工作。具体而言,本文的主要研究贡献总结如下：第一,通过分析来自于用户移动设备的丰富情境日志,提出了一种情境感知的移动用户个性化偏好挖掘方法,从而帮助实现基于情境感知的个性化移动推荐系统。针对情境日志缺乏显式评分、记录稀疏、特征复杂等挑战,设计了一种全新的基于多用户数据的偏好挖掘框架。在此框架下,首先通过对多用户情境数据的分析来挖掘移动用户的公共偏好。然后,将单个用户的个性化偏好表示为这些公共偏好上的概率分布。特别地,根据情境数据建模的需要,提出了两种不同的情境建模独立性假设,并且分别根据这两种假设设计了不同的方法来挖掘移动用户的个性化偏好。具体来说,当情境数据被认为是相互条件独立的,采用概率主题模型对情境数据和用户行为进行建模；如果情境数据被认为是相互依赖的,则采用行为模式挖掘算法和贝叶斯非负矩阵分解的办法来进行建模。最后,在一个真实世界的数据集上进行了实验,实验结果表明本文提出的方法相对于其他基准方法能够更好地为移动用户提供基于情境感知的个性化推荐。第二,通过扩展来自于Web和情境日志的辅助信息,提出了一种自动化的移动App分类方法,从而实现移动用户的行为理解以及移动App的管理需求。针对移动App缺乏必要的上下文信息训练分类器这一难题,提出了一个全新的分类框架。该框架可以利用外部的辅助信息扩充移动App本身稀少的上下文信息,从而使得我们能够对移动App进行有效的分类。具体来说,首先利用Web搜索引擎为移动App扩充必要的文本信息,并且基于此提出了多个有效的分类特征。其次,基于近年来在情境信息领域的研究成果,提出使用真实世界的情境日志来为移动App扩充上下文信息,并设计了多个有效的基于情境感知的分类特征。随后,将提取的各种特征整合到经典的最大熵分类模型中来训练一个高效的移动App分类器。最后,在一个真实的移动App数据集上测试了提出的分类方法,实验结果表明本文提出的方法相比其它基准方法能够更加有效地对移动App进行分类。第三,通过研究来自于在线移动App商店的长期商务数据,提出了一种面向移动App的排名欺诈检测方法,从而发现不良App开发商的恶意刷榜行为。具体而言,首先定义了面向移动App的排名欺诈问题,然后介绍和分析了解决这一问题所面临的诸多技术挑战,例如欺诈时间定位、欺诈自动化检测、欺诈证据提取等等。基于上述挑战,开发了一个全自动化的移动App排名欺诈检测系统。首先通过挖掘移动App在排行榜上的活跃周期来定位排名欺诈可能出现的时间段。然后通过对各个App在历史中的排名记录和用户评分、评论记录进行分析,提取出了三类共七种欺诈证据。进一步,提出了一种全新的非监督证据整合方法来实现最后的排名欺诈检测。最后,使用Apple Appstore中超过两年的App排行榜数据进行实验,结果证明本文提出的方法能够有效地检测出移动App排名欺诈现象。第四,通过整合来自于移动App的多种异构流行度信息,提出了一种面向移动App的流行度建模方法,从而帮助实现多种移动智能服务。目前基于移动App流行度的相关研究十分离散,主要分散在移动推荐系统、移动App异常检测等领域,缺乏一个综合的模型对相关信息和问题进行整合。针对这一挑战,提出了一种基于隐马尔科夫模型的扩展模型对App的排名、用户评分、用户评论等三种重要流行度信息进行综合建模。同时,提出了一种基于二部图聚类的模型参数估计方法,用以实现高效的模型训练。特别地,基于所提出的模型,展示了多种潜在的移动智能服务,比如基于趋势的移动App推荐等等。最后,在两个采集于Apple Appsotre的数据集中进行了丰富的实验,实验结果清晰地验证了本文所提出建模方法的有效性。最后,通过挖掘来自于移动App的数据访问权限和流行度信息,提出了一种安全隐私感知的移动App推荐方法,从而满足移动用户在安全隐私保护方面的需求,并促进移动App产业的健康发展。事实上,现有的移动App推荐系统仅仅考虑评分、下载量等流行度信息,而不考虑其潜在的安全隐私风险,因此很难满足移动用户对于安全隐私保护的需求。针对这一问题,设计了一种全新的移动App推荐系统,用来为用户推荐既流行又安全的移动App。首先,提出了一个扩展性良好的移动App安全隐私风险评估方法,这一方法可以自由整合各种关于安全隐私风险的先验信息,并且不需要任何的显式函数定义。紧接着,根据经济学中的投资组合理论,提出了一种全新的优化方法来实现移动App推荐时在流行度与用户安全偏好上的折中。特别地,进一步设计了一个新颖的数据存储结构App哈希树,用来实现海量移动App在不同类别和安全级别下的快速推荐和管理。最后,在一个采集自Google Play的大规模数据集上进行了实验,实验结果充分地验证了本文所提出的移动App安全风险评估方法,以及推荐算法的有效性。
[53]郭春.基于数据挖掘的网络入侵检测关键技术研究[D].导师：罗守山.北京邮电大学,2014.
关键词:入侵检测,数据挖掘,特征降维,异常检测,混合入侵检测模型
摘要:随着因特网的快速普及,网络已经渗透到了人们日常工作和生活的各个方面。然而,随之而来的各种安全威胁,对社会稳定和经济发展带来了不同程度的损害。作为主要安全技术之一,入侵检测技术能够在网络攻击造成广泛的破坏前检测到攻击行为,从而为防御策略的制定提供重要依据。而网络规模的不断扩大,各种新的安全漏洞和网络攻击手段层出不穷,对入侵检测系统的检测性能提出了更高的要求。数据挖掘是一种智能数据分析技术,能够从大量数据中发现有用的知识。本文综述了国内外在基于数据挖掘的入侵检测研究领域的最新进展,以基于数据挖掘的网络入侵检测关键技术为研究重点,对入侵检测中的特征降维及样本约简、基于离群点挖掘的异常检测方法、混合入侵检测模型等方面进行了研究。本文的主要研究工作可归纳如下：(1)研究了特征降维技术在入侵检测中的应用,设计了一种能够适用于入侵检测的特征提取方法。所谓特征降维,包含特征选择和特征提取两种方式,能够降低表征数据的特征向量的维数,从而使许多数据挖掘算法获得更好的效果。本文在分析入侵检测领域中的特征降维相关研究的基础上,提出了一种基于簇中心距离和的特征提取方法。该方法利用数据集中各数据样本与簇中心的一种特定关系——距离和,将表征数据样本的原始特征向量从高维空间转换到低维空间。文中的实验表明了该特征提取方法在入侵检测应用中的有效性。(2)研究了样本约简技术在入侵检测中的应用,设计了一种能够适用于入侵检测的样本约简方法。所谓样本约简,是数据约简中的一种方式,用于缩减数据集中的样本数量。与针对整个原始数据集的数据挖掘相比,使用约简后得到的子集能够降低数据挖掘成本和加快挖掘速度,有时甚至能够取得更好的效果。为了能够从原始数据集选出高质量的样本子集,本文提出了一种基于类中心的分层样本约简方法。该方法通过一个能够衡量数据集中样本相对于其所属类别代表能力大小的指标,和一种基于类中心的数据集等分划分策略,可以从原始训练集中选出一个样本子集,进而使用该子集来建立入侵检测模型。文中的实验结果表明该样本约简方法对入侵检测应用是有效的。(3)研究了离群点挖掘技术在入侵检测中的应用,设计了一种基于离群点挖掘的异常检测方法。通过离群点挖掘技术,能够发现数据集中偏离大部分数据的离群值。本文在分析离群点挖掘技术在入侵检测中相关研究的基础上,提出了一种基于簇中心位置变化的异常检测方法。该方法运用聚类算法从正常样本集中提取参考样本(簇中心)之后,通过目标样本(可为训练样本或待检测样本)增加前后簇中心位置的变化情况,为该目标样本赋予一个“离群程度分值”,并将离群程度分值大于一个异常阈值的待检测样本识别为异常样本。文中的实验结果表明该方法能够以较高的检测率完成网络异常检测任务。(4)研究了混合入侵检测模型的组成结构,设计了一种包含三个检测模块的两层混合入侵检测模型。混合入侵检测模型结合了误用检测和异常检测两种检测方法,因而其能够结合两者的优点。本文在分析现有的几类混合入侵检测模型的组成结构及优缺点的基础上,提出了一种包含两个异常检测模块和一个误用检测模块的两层混合入侵检测模型。在该混合入侵检测模型中,两个阶段的检测模块相互合作,阶段2的两个检测模块分别能够识别阶段1的检测模块所产生的误报和漏报。文中的实验结果表明,该混合入侵检测模型能够以较低的误报率和较高的检测率完成入侵检测任务。
[54]戴鹤忠.基于数据挖掘技术的证券投资决策研究[D].导师：刘澄.北京科技大学,2015.
关键词:数据挖掘技术,价值投资,投资组合,投资基金
摘要:本文在分析证券投资相关理论和相关研究的基础上,运用数据挖掘技术,从个股选择决策、证券投资组合决策和证券投资基金投资三个方面对证券投资决策问题进行了研究,主要完成了以下几方面的工作：(1)把粗糙集理论运用到证券价值投资选股实践中,通过历史数据来确定各财务指标与证券收益率之间的内在关系度,并运用主客观综合权重来进行多属性投资决策,依据多属性决策结果进行证券投资的价值选股。实证研究结果证明了基于粗糙集理论的价值投资选股方法具有较好的准确性和科学性。(2)充分考虑不同行业股票的差异,选取了五只来自不同行业的股票,并考虑了不同投资者对风险和收益的不同偏好程度,参照投资者效用函数构造新的投资组合目标函数,使得模型可以适用于不同类型的投资者。应用粒子群优化算法,通过生成粒子群的粒子进行不断地速度和位置更新,求解出最优的权重配比,以指导投资者进行投资组合的构建。(3)从基金经理择股能力和择时能力、以及基金在牛市和熊市不同盈利能力两个方面来对我国证券投资基金的绩效进行评价,用于指导投资者针对自身的收益要求与风险承担程度来选择合适的证券投资基金。通过多种模型的比较分析发现：大部分基金经理都具有正的择股能力和负的择时能力；且在牛市时基金普遍能取得高于市场收益的收益,而熊市时大部分基金并不能战胜市场。
[55]王元卓,贾岩涛,刘大伟,靳小龙,程学旗.基于开放网络知识的信息检索与数据挖掘[J].计算机研究与发展,2015, 02:456-474.
关键词:网络大数据,开放网络知识,本体,信息检索,数据挖掘
摘要:网络大数据是指"人、机、物"三元世界在网络空间(cyberspace)中交互、融合所产生并在互联网上可获得的大数据.这些数据具有多源异构、交互性、时效性、社会性、突发性和高噪声等特点,不但非结构化数据多,而且数据的实时性强.网络大数据背后蕴含着丰富的、复杂关联的知识.建立面向开放网络的知识库是获取网络大数据中的丰富知识的有效手段.对当前国内外主要的开放网络库进行了比较,分析了相应的构建方法、多源知识的融合以及知识库的更新等关键技术.进一步从用户意图理解、查询扩展、语义问答、线索挖据、关系推理以及关系和属性预测等方面出发,总结了基于开放网络知识库的信息检索、数据挖掘与系统应用的研究现状和主要问题.最后,对开放网络知识库的发展趋势和面临的主要挑战进行了展望.
[56]李德仁,李熙.论夜光遥感数据挖掘[J].测绘学报,2015, 06:591-601.
关键词:夜间灯光,遥感,数据挖掘
摘要:如果从地球上空观测夜间的地球,可以发现人类聚居区和经济带发出夺目的光芒。当夜间的天空无云时,遥感卫星能够捕捉到城镇灯光、渔船灯光、火点等可见光辐射源,这些夜间无云条件下获取的地球可见光的影像即夜光遥感影像。与日间遥感不同,夜光遥感对于反映人类社会活动具有独特的能力,因此被广泛应用于社会经济领域的空间数据挖掘。本文首先介绍能够观测夜间灯光的卫星遥感观测平台和传感器,然后从社会经济参数估算、城市化监测与评估、重大事件评估、环境及健康效应研究、渔业信息提取、流行病研究、油气田监测等方面总结了夜光遥感数据挖掘的现状和特点。最后,文章从新型数据源、知识发现、地面观测和地理国情—世情监测4个方面提出了夜光遥感及其数据挖掘的未来发展趋势。
[57]纪俊.一种基于云计算的数据挖掘平台架构设计与实现[D].导师：邵峰晶.青岛大学,2009.
关键词:数据挖掘,云计算,数据规约,分布式系统
摘要:网络技术在带给人们大量信息的同时,也极大地增加了人们从海量数据中发现有用知识的难度,而解决这一问题的努力促进了数据挖掘技术的出现和快速发展。目前,数据挖掘技术已在金融、医疗、军事、管理等诸多领域的决策分析方面被广泛应用。云计算是能提供动态资源池、虚拟化和高可用性的计算平台。云计算开发平台可被用来开发高性能应用程序,但数据本身具有噪声、异构等问题,而现有的云计算开发平台当前还没有数据规约功能,利用云计算进行数据挖掘的解决方案尚未被提出。针对上述问题,首先,扩展Google App Engine开发平台,设计与实现其数据规约功能,主要解决异构数据访问问题与未存在数据类型访问问题;然后,在扩展的Google App Engine开发平台基础上设计与实现一数据挖掘系统,通过实验验证数据规约功能的有效性及云计算平台执行数据挖掘操作的高效性。在数据规约模块设计过程中,通过采用可被扩展的元数据定义、数据集模板定义及数据集定义逐层抽象数据集的数据类型、数据结构、访问地址等信息,实现对异构数据集的抽象以及对未有数据类型的访问。在基于云计算的数据挖掘系统设计过程中,基于分层设计的思想,将该平台的层次自底向上划分为:算法层、任务层和用户层,其中,底层透明的为其上层提供服务,上层通过层间开放接口调用下层服务,使得层与层之间的功能相对独立,易于系统的二次开发。同时各层接口均以REST接口方式对外开放,可被开发者嵌入到其应用程序中。在算法层设计过程中,设计了多层插件框架结构,增加了算法实现与维护的灵活性。最后,在对系统开发环境及系统开发关键技术分析的基础上,给出了基于云计算的数据挖掘平台原型的实现过程。并通过实验数据分析,验证了目标的有效性与高效性。
[58]毛国君.数据挖掘技术与关联规则挖掘算法研究[D].导师：刘椿年.北京工业大学,2003.
关键词:数据挖掘,知识发现,关联规则,项目序列集,时态约束,数据分割
摘要:数据挖掘是致力于数据分析和理解、揭示数据内部蕴藏知识的技术，它成为未来信息技术应用的重要目标之一。经过十几年的努力，数据挖掘产生了许多新概念和方法。特别是最近几年，一些基本概念和方法趋于清晰，它的研究正向着更深入的方向发展。像其它新技术的发展历程一样，数据挖掘技术也必须经过概念提出、概念接受、广泛研究和探索、逐步应用和大量应用等阶段。从目前的现状看，大部分学者认为数据挖掘的研究仍然处于广泛研究和探索阶段，迫切需要在基础理论、应用模式、系统构架以及挖掘算法和挖掘语言等方面进行创新。关联规则挖掘是数据挖掘中成果颇丰而且比较活跃的研究分支，留给研究者的是更深入的课题。面对大型数据库，关联规则挖掘需要在挖掘效率、可用性、精确性等方面得到提升。因此，需要探索新的挖掘理论和模型；需要利用用户的约束等聚焦挖掘目标；需要对一些传统的算法进行改进；也需要研究新的更有效的算法等。鉴于目前数据挖掘技术和关联规则挖掘研究的现状和发展趋势，在各类基金的支持下，我们选择了这一课题开展相关工作。本文的研究主要包括数据挖掘应用系统体系结构、关联规则挖掘理论及其算法等。关于数据挖掘应用系统体系结构研究方面，我们设计了一个数据挖掘应用系统的原型体系结构，系统化地分析了知识发现的基本过程和系统的各部件功能。由于不同的源数据类型、不同的应用目标以及不同的挖掘策略对数据挖掘系统的功能部件要求不同，这些研究主要是从知识发现的基本过程出发，探讨系统应具备的主要功能部件及其相互联系等。在关联规则挖掘理论研究上，我们首次给出了项目序列集格空间，并且探讨了在这个空间上的基本操作算子。基于项目序列集格空间及其操作，我们建立了关联规则挖掘模型和算法。在关联规则挖掘算法方面，设计了基于项目序列集操作理论的关联规则挖掘算法ISS-DM、时态约束下的关联规则挖掘算法TISS-DM、数据分割下的关联规则挖掘算法PISS-DM。ISS-DM 算法是建立在严格的项目序列集格理论及其操作基础上，是一个一次数据库扫描的而且不使用侯选集的高效算法。我们选择目前引用率较高的Apriori算法和ISS-DM进行了对比实验。结果表明，ISS-DM执行时间整体上优于Apriori算法，而且随着数据量的增大ISS-DM执行时间的增长幅度也小于Apriori算法。为了提高对大型数据集挖掘的适应性，将时态约束应用到挖掘的预处理中，改进ISS-DM成TISS-DM。这部分工作还包括对时态区间、时态约束下的数据挖掘空间以及时态区间操作等进行了形式化，它们是TISS-DM的理论基础。对ISS-DM的另一个改进算法是PISS-DM。它是针对大数据集挖掘过程中对内存和CPU等系统资源要求较高的情况被提出和设计的，采用了数据分割的方法来减少资源的占用。本文解决了数据分割下局部频繁项目序列集和全局频繁项目序列集的转换等问题，是一个两次扫描数据库的算法。总之，本文在分析、归类现有数据挖掘研究成果以及原型系统的基础上，进行了数据挖掘应用系统体系结构、关联规则挖掘理论模型以及算法方面的研究。在项目序列集格及其操作、时态约束挖掘空间等方面具有较好的<WP=4>理论价值，所设计的算法在挖掘效率和对大型数据库挖掘的可用性方面具有潜在的应用前景。
[59]周海燕.空间数据挖掘的研究[D].导师：王家耀.中国人民解放军信息工程大学,2003.
关键词:数据挖掘,空间数据挖掘,空间数据仓库,粗集,空间关联规则,空间统计分析,空间数据聚类,遗传算法,Voronoi图,Delaunay三角网
摘要:空间数据挖掘是指从空间数据库中提取用户感兴趣的空间模式与特征、空间与非空间数据的普遍关系及其它一些隐含在空间数据中的普遍的数据特征。本文系统研究了空间数据挖掘的理论、方法和应用。主要内容有：(1)建立起空间数据挖掘的基础理论和技术框架，进一步完善了空间数据挖掘的理论和方法。阐述了空间数据挖掘的定义与特点，提出一种包括数据源、挖掘器、用户界面三层结构的空间数据挖掘体系结构，阐述空间数据挖掘的基本步骤和从空间数据库中能发现的九种知识类型，系统研究了17种空间数据挖掘方法，阐述了各种方法的特点和适用范围，阐述了空间数据挖掘与其它相关学科的区别与联系，指出空间数据挖掘的主要研究方向，提出开发空间数据挖掘系统的几条原则。(2)将粗集理论引入空间数据挖掘领域，系统地研究了粗集理论用于空间数据挖掘的基础理论和方法，包括粗集的基本概念和性质、粗集的扩展模型、空间数据库中知识表达系统的分类、属性表的一致性分析、属性的依赖关系和属性的重要性、决策表属性约简和属性值约简等。(3)提出空间关联规则主要指空间对象之间的空间和非空间关系，指出空间关联规则的形式十分丰富，重点研究了两种形式的空间关联规则的挖掘。阐述了A=>B[s％，c％]形式的空间关联规则的基本概念和算法，详细研究了一种逐步求精的空间关联规则挖掘算法的实现；提出一种基于空间数据立方体的空间关联规则挖掘的新思路；将空间统计分析引入空间关联规则挖掘领域，研究了空间权重矩阵、空间自相关、空间关联等的度量函数，并利用空间统计分析技术发现空间相关关系和空间关联规则。(4)系统研究了七种典型的空间数据聚类方法，积极探索基于约束条件的空间聚类问题的解决方案；将遗传算法引入空间数据聚类领域，提出一种基于遗传算法的空间聚类算法，该算法兼顾了局部收敛和全局收敛性能。(5)系统研究了Voronoi图和Delaunay三角网的定义、性质及各种建立算法，并对它们在空间数据挖掘中的应用进行了探索性研究：提出Voronoi图是界定空间目标(现象)的空间影响范围的一种行之有效的办法；从理论上论证了Voronoi图的形成与城市中心地的形成是一致的，提出Delaunay三角网是建立城镇网络体系的最佳模型；研究了利用Voronoi图进行公共设施选址优化的算法及实现。
[60]李仁璞.分类数据挖掘中若干基本问题的研究[D].导师：王正欧.天津大学,2003.
关键词:数据挖掘,分类,粗集理论,神经网络,熵
摘要:面对大规模的、高维的数据，如何建立有效的，可扩展的分类数据挖掘算法是数据挖掘领域的研究热点。围绕以上问题，本文对分类数据挖掘中涉及的若干基本问题进行了深入研究，主要包括以下几个方面的内容：提出了一种结构自适应的神经网络特征选择方法。通过交替删除网络中冗余的输入特征和隐结点，使网络结构在特征选择的过程中保持相对良好。实验表明该方法能快速有效删除特征，提高网络泛化性能。提出一种基于粗集理论和神经网络相结合的分类规则挖掘算法。首先使用粗集理论和神经网络对决策表进行两次属性约简，然后使用粗集理论对约简后的决策表进行规则抽取。该方法充分融合了粗集理论强大的规则生成能力和神经网络优良的容错性能。实验表明，该方法快速有效，生成规则简单准确，具有良好的鲁棒性。属性离散化的方法可以分为两类：局部方法和全局方法。局部方法简单易行但效果较差，而全局方法效果较好但算法复杂计算量大。本文提出一种有效的结合两类方法优点的折衷算法，在一种已有基于熵的局部算法基础上加入对决策表数据不一致度的检验，从而使该算法具有了全局化的特性。实验结果表明使用相同的规则生成器C4.5，本文方法比传统离散化方法生成的规则更强壮。对目前广泛应用的基于粗集理论和信息熵的几种规则不确定性度量准则进行了比较分析，通过定理证明了它们之间存在不一致性以及发生不一致时的必要条件，提出了下一步构建更有效的不确定性度量的方向。提出一种基于粗糙集理论的分类别进行规则抽取的算法。首先获得每类数据的属性约简；然后为每类数据构造一个分辨矩阵和一个合并矩阵,通过两个矩阵的交互作用逐类抽取规则。UCI数据库上的实验结果表明,与传统方法相比该算法能够在更短的时间内得到分类精度更高的规则。
[61]郭秀娟.基于关联规则数据挖掘算法的研究[D].导师：孙运生;周云轩.吉林大学,2004.
关键词:数据挖掘,关联规则,算法,频繁项集,支持度,可信度,模糊关联规则,加权关联规则,模板,解空间,算法,信息增益
摘要:数据挖掘是指从大量的数据中发现人们事先不知道的、有用的知识（或模式）的处理过程，它是继数据库、人工智能等领域之后发展起来的一门重要学科。随着计算机软、硬件技术的发展以及在各行各业中的应用，使得人们对数据挖掘技术的需求越来越迫切。由于挖掘到的知识能够给其领域以有力的支持，因此，数据挖掘技术得到了广泛的应用。在数据挖掘算法的研究中，比较有影响的是关联规则发现算法，它是数据挖掘研究的一个重要分支，也是数据挖掘的众多知识类型中最为典型的一种。该问题于1993年由Agrawal等人在对市场购物篮问题（Market Rule Analysis）进行分析时首次提出的，用以发现商品销售中的顾客问题。关联规则可以发现存在于数据库中的项目（Items）或属性(Attributes)间的有趣关系，这些关系是预先未知的和被隐藏的，即不能通过数据库的逻辑操作或统计方法得出。这说明它们不是基于数据自身的固有属性，而是基于数据项目的同时出现的特征，所发现的规则可以辅助人们进行市场运作、决策支持、商业管理及网站设计等。因此对关联规则算法的研究是非常重要的。关联规则是指从一个大型的数据集（Dataset）中发现有趣的关联（Association）或相关(Correlation)的关系，即从数据集中识别出频繁出现的属性值集(Sets of Attribute-Values)，也称为频繁项集(Frequent Itemsets，简称频繁集)，然后再利用这些频繁集创建描述关联关系的规则的过程。在关联规则描述中，需要指定规则必须满足的支持度和信任度的门限，即最小支持度和最小信任度；若给定一个事务数据集（Transaction Dataset）D及用户指定的最小支持度(min_sup)与最小信任度(min_conf)，则关联规则挖掘问题即是发现所有满足最小支持度与最小信任度约束的关联规则；关联规则数据挖掘方法中规则的发现思路还可以用于序列模式的发现，寻找事务在时间上的规律等。关联规则挖掘的问题自提出以来，人们相继提出了许多关联规则挖掘的算法，这些算法基本上都是围绕如何快速高效的生成频繁集这一核心问题进行展开的，并在此基础上提出一些改进的方法。由于关联规则挖掘中最为耗时的操作是发现频繁集，因此大部分算法的主要特征是对这部分的工作进行有效的划分。在数据库中包含各种不同属性的数据，因此所采取的挖掘方法也不同，关联规则挖掘最初的算法是针对布尔关联规则的挖掘，以后又扩展到分类关联规则、数值型关联规则、多概念层次型关联规则等。目前，探索关联规则不同类<WP=110>型并提出相应的挖掘算法是一项重要的内容。本文围如何提高关联规则算法的效率，挖掘出更为有价值的规则，结合领域知识，从不同的角度进行了研究。R.Agrawal等人提出的Apriori算法是关联规则的基本算法，以后出现的各种算法基本上都是基于Apriori算法改进的。Apriori算法利用了如下两个基本性质：即任何强项集的子集必定是强项集及任何弱项集的超集必定是弱项集，该算法的关键是尽可能生成较小的侯选项目集，它的依据是一个频繁项目集的任一子集必定是频繁项目集，进而提出算法的基本框架描述。本算法的突出特点是利用第k-1趟扫描中得到的强项集的集合Lk-1来生成k-项集Ck，由apriori-gen(Lk)实现。同时分析了Apriori算法的缺点是Ck中的每个元素需要在交易数据库中进行验证，从而决定是否加入Lk，此验证过程是该算法的一个瓶颈，这个方法要求多次扫描很大的交易数据库，I/O的负载过大。因此，引入了快速更新算法、DHP、JAFLR算法。DHP算法重点是侯选2-项集的生成，侯选项个数少于以前所述方法生成的个数，解决了生成L2时的性能瓶颈问题，对数据进行了剪枝，减少了数据量。而JAFLR算法则通过统计任意两个属性间的组合次数直接获得最长频繁项目集。该算法实现了一次扫描数据库，但同时带来了占用庞大内存空间的问题，即程序设计中存在的运行时间与占用存贮空间的矛盾。第四章讨论了含有模糊数值约束的关联规则的定义、算法，将模糊查询与归纳模板有机结合，提出挖掘含有模糊数值约束的关联规则的定义、公式及挖掘算法，利用最小支持度和最小信任度约束进行前期挖掘，然后生成规则模板，利用模糊查询和语言量词概念对前期的挖掘结果进行进一步的挖掘，因此模糊关联规则是关联规则挖掘的一个扩展，模糊数值关联规则的优点是它所表达的语义与人的表达方式非常接近，易于理解。第五章讨论了关联规则解空间的优化问题，给出了意想不到的关联规则（即可能对用户是有趣的规则）的定义、算法。提出了两类意想不到的关联规则的基本定义，一类是意想不到的模板规则；另一类是与规则模板后项不同的意想不到的规则，这些规则是最终应提交给用户的主要结果，即那些事先无法遇见的规则。提出了利用(2检验的方法剔除那些缺乏相关的项集的方法，并给出了利用信息增益对第二类规则进行排序的方法，表明信息增益越大的规则越是有趣的规则。在算法设计时，给出了修改后的框架，使得中的频繁集分为和两个部分，使得频繁集生成的数量大大的减少，从而提高了算法的效率，因此这一部分是对含有项目约束的关联规则挖掘的一个拓展。在对关联规则的算法的讨论中，发现在现实生活中的事
[62]陈刚.基于数据挖掘的电力营销决策支持系统的结构原理及算法研究[D].导师：孙才新.重庆大学,2004.
关键词:神经网络,聚类分析,电力营销,决策支持系统,数据挖掘,数据仓库,联机分析
摘要:随着我国电力市场的逐步发展和完善，电力工业已经逐步从“卖方市场”转变为“买方市场”，这将给我国电力工业的发展带来重大的影响。作为独立市场主体的电力企业，其经营目标转变为关注企业效益的最大化，工作的重点逐渐从发输电方面转移到市场营销开拓以及电力需求侧的管理服务方面。随着机制的转换，传统的面向基本业务的信息管理系统(如用电MIS等)已不能满足电力企业营销工作的需要，如何建立适应于我国电力营销需求的决策支持系统已成为当务之急。数据挖掘技术是人工智能和数据库结合的产物，用于发现海量数据库中存在的潜在关系和规则，已经成为一种重要的智能决策方法以及决策知识获取的重要途径，在决策支持系统中具有重大的应用研究价值。本文对电力营销决策支持的需求进行了详细的分析和设计，在此基础上提出了一种全新电力营销决策支持系统的整体框架设计原理。该系统结构的特点是具有问题引导功能以及融合了数据仓库、OLAP分析以及DM技术，能较好地满足电力营销决策支持系统的实际需要。基于数据仓库的OLAP技术是电力营销辅助决策支持的重要技术之一。在详细分析数据仓库基础上，设计了电力营销数据仓库的实现方案；对电力营销的OLAP分析内容和方法进行了研究；在BusinessObject基础上设计和实现了电量电费的多维决策分析，包括语义层设计、通用查询报表的设计以及切片、旋转和钻取操作等。DM技术与OLAP技术是电力营销决策支持系统中的关键数据分析技术，二者有机结合构成的多维数据挖掘模型能提高数据分析的效果和性能。针对多维数据挖掘模型中的挖掘空间的选择方法问题，提出了一种用于数据挖掘空间选择的神经网络结构和算法，其算法既避免统计方法中复杂的非线性建模问题，又比一般神经网络变量选择方法的计算量小。鉴于聚类分析在数据挖掘中具有重要的作用，本文针对聚类分析中聚类数确定难的问题，深入研究了聚类准则的选择和曲线特性；提出了一种基于SOFM神经网络的结构自适应聚类神经网络，其特点是能够自动确定最佳的聚类数。基于实际营销数据，采用结构自适应聚类神经网络技术实现了用户用电量时间特征分析，所得结论对于电价的针对性的调整以及合理地安排电力生产具有重要的参考价值。本文的研究成果对于电力市场环境下电力企业的电力营销决策系统的方案设计以及实现有重要的参考价值。
[63]杨小兵.聚类分析中若干关键技术的研究[D].导师：孔繁胜.浙江大学,2005.
关键词:数据挖掘,聚类分析,模糊聚类,高斯混合模型,切换回归模型,噪音
摘要:基于数据库的知识发现(Knowledge Discovery in Database,简称KDD)是指从大量数据中提取有效的、新颖的、潜在有用的和最终可被理解的模式的非平凡过程。它是一个反复迭代的人机交互处理过程,该过程需要经历多个步骤,主要包括数据整理、数据挖掘(Data Mining)和结果的解释评估。其中数据挖掘是整个KDD过程中最核心的步骤,数据挖掘的目的就是运用特定的数据挖掘算法,从数据库中提取用户感兴趣的知识,并以一定的方式表示出来,如树、表、规则、图等。聚类分析是数据挖掘的最主要的功能之一,聚类就是将数据对象分组为多个类或簇,在同一个簇中的对象之间具有较高的相似度,而不同簇中的对象差别较大。本文将重点研究聚类分析中的若干关键技术和算法。在第一章中,首先就数据挖掘进行概述,主要讨论数据挖掘的产生、发展以及数据挖掘算法可以实现的功能,主要包括:类/概念描述、关联规则、分类与回归、聚类分析、序列与时序分析以及孤立点分析等。最后给出了本文研究的主要内容和组织结构。在第二章中,首先介绍了聚类分析的定义,聚类算法的基本要求,以及聚类中用到的主要数据类型;然后讨论了聚类分析的各种算法:划分方法、层次方法、基于密度的方法、基于网格的方法以及基于模型的方法;最后对聚类算法的应用领域进行了探讨。第三章介绍了模糊集合的基本概念,模糊集合的运算,模糊截集及分解定理,在此基础上,研究了基于模糊关系的模糊聚类及其算法,通过应用FCM算法的实例解释了模糊聚类的应用。第四章重点研究了高斯混合模型的聚类算法,除了介绍经典的EM算法以外,还讨论了GMDD算法。由于在某些领域,为了更准确地识别出不同性质的数据,人们会根据经验利用加权函数以获得更好的聚类效果,本文以加权似然方程为
[64]樊明辉.空间数据挖掘及其可视化系统若干关键技术研究[D].导师：池天河.中国科学院研究生院（遥感应用研究所）,2006.
关键词:空间数据仓库,空间数据集成,空间OLAP分析,概念层次树,空间关联规则,优势关系,粗糙集,空间邻接关系,MST,空间聚类,可视化,开放式数据挖掘系统
摘要:数据挖掘技术已经成为解决“数据爆炸、知识贫乏”问题的有效手段，在地学数据分析领域引入数据挖掘与知识发现的概念、模式和方法，探讨适合地学应用的数据挖掘新方法，对于有效处理海量地学数据、提高地学分析的自动化和智能化水平具有重要意义。可视化技术能为数据挖掘提供直观的数据输入、结果输出和挖掘过程的交互探索分析手段，提供在人的感知力、洞察力、判断力参与下的数据挖掘手段，从而大大地弥补了GIS重“显示数据对象”轻“刻画信息结构”的弱点，有力地提高空间数据挖掘进程的效率和结果的可信度，在地学领域，可视化与空间数据挖掘的结合已成为必然。本文系统地讨论了基于数据仓库的空间数据集成技术，改进了空间关联规则、粗糙集和空间聚类算法，研究了契合上述挖掘算法的若干可视化技术，在此基础上，实现了一种开放式的“即插即用型”数据挖掘系统，并集成上述数据挖掘技术、可视化技术，形成一套可视化空间数据挖掘的理论框架、技术方法和原型系统。研究内容和结果可归纳为：(1)阐述了空间数据集成和空间数据集成模型的相关理论和概念，对多源空间数据的集成模式进行了探讨。讨论了多源空间数据的一体化处理技术和多尺度空间数据的一体化处理技术，提出了基于数据仓库的数据集成总体框架，设计了一个基于Web的空间OLAP工具，并给出了具体的实现流程。(2)改进了Apriori算法，提出了一种基于映射的高效大项集关联规则发现算法MBAR。探讨了空间概念树和层次关联规则结合的途径，提出了基于概念树的多层次空间规则算法，给出了算法处理流程和应用实例。(3)探讨了应用于多准则决策分析的基于优势关系的粗糙集扩展模型，对该模型中已有的求核和知识约简算法进行了研究，提出了一个新的优势区分矩阵的定义，在该定义的基础上给出了相应的求核和求约简算法，给出了在属性约简之后提取优势规则的方法。(4)研究了基于空间邻接关系的空间聚类挖掘算法VSG-CLUST。该算法是一种基于图分割的可视化空间聚类算法，利用Delaunay三角网工具和MST(最小生成树)将地理实体的邻接信息(空间相邻关系)加入并参与到空间聚类中。研究了利用多尺度的空间概念层次关系进行空间聚类挖掘的算法，将尺度因素作为一种约束条件施加于VSG-CLUST算法中MST的分割和修剪策略，即一种基于尺度约束的空间层次聚类挖掘算法。(5)讨论了基于OLAP的空间多维可视化方法，并给出OLAP多维可视化
[65]赵恒.数据挖掘中聚类若干问题研究[D].导师：杨万海.西安电子科技大学,2005.
关键词:数据挖掘,模糊聚类,聚类有效性,聚类初始化,分类属性,高维数据
摘要:数据挖掘是为了满足人们对数据中所蕴涵的信息和知识的充分理解和有效应用而发展起来的一门新兴技术。数据库、人工智能和数理统计是知识发现和数据挖掘的三个强大的技术支柱。发展自统计学的聚类分析作为数据挖掘的一项主要功能和任务,成为数据挖掘中的一个重要的研究领域,至今已提出了大量的理论和方法,取得了丰硕的研究成果。尽管如此,聚类中还存在许多问题,尤其随着数据挖掘技术的广泛应用,数据挖掘所面对的数据对象日趋复杂,聚类研究也面临更多新的内容和挑战。这就要求对现有聚类技术进行改进,同时不断提出新的聚类理论和方法以适应新的应用。本文对聚类有效性问题,迭代优化聚类的初始化问题,分类属性数据聚类算法及高维数据聚类方法进行了较为深入的研究,主要内容如下:第一章简单介绍了数据挖掘技术和数据挖掘中的聚类分析的特点,详细论述了聚类有效性问题、迭代优化聚类的初始化、分类属性数据聚类方法以及高维数据聚类的研究现状,最后介绍了本文的主要研究工作成果及内容安排。第二章介绍了数据挖掘中的聚类分析,包括聚类分析的数据结构和数据类型,聚类准则的确定,聚类算法的分类,并详细论述了数据挖掘中用到的主要聚类算法,最后对聚类结果的评价方法进行了简要介绍。第三章主要研究聚类有效性函数。首先介绍了模糊聚类的划分系数与划分熵,研究了基于几何结构的聚类有效性函数,从聚类的“紧致度”和“分离度”角度出发,提出了一种新的基于几何结构的加性聚类有效性函数;研究了改进的HubertГ统计量,将其与聚类分离度相结合,提出了一种基于HubertГ统计量和分离度的聚类有效性函数。此外,研究了聚类算法的实验结果的评价,指出了现有聚类结果评价方法的不足,阐明了聚类精确度是反映聚类效率的观点,用Fowlkes&Mallows划分相似测度作为聚类精确度,来评价后续章节中聚类算法的实验结果。第四章研究了现有的迭代优化聚类的初始化方法:即采样法,距离优化法以及密度估计法,分析了它们的优缺点,提出一种新的基于距离的初始化方法,它不需要设定门限,不受数据集的顺序影响,而且对孤立点和噪声有较强的抑制,适用于较大规模数据的聚类初始化;分析了对初值不敏感的k-harmonicmeans算法,提出了模糊k-harmonic means算法,并导出了该算法在中心迭代统一框架下的描述。第五章研究了k-modes、k-prototypes和fuzzy k-modes聚类算法,通过仿真讨论了k-prototypes算法的性能;在新的差异度函数的基础上提出了一种新的
[66]宋余庆.医学图像数据挖掘若干技术研究[D].导师：孙志挥.东南大学,2005.
关键词:医学图像,聚类分析,特征提取,关联规则,图像分类
摘要:医学影像诊断是医学无创伤性诊断的主要方法之一,是国内外医学领域重点研究的方向。医学图像具有很大的数据量。医学图像中蕴含着丰富的图像特征信息和规则,有待人们去研究和认识,所以,面向医学图像的数据挖掘技术研究成为医学和计算机科学交叉学科研究的一个十分重要的领域。医学图像的高分辨率、数据的海量性、图像特征表达的复杂性等特点,使得数据挖掘技术在医学图像中的研究具有较大的学术价值和广泛的应用前景。目前,面向医学图像的数据挖掘研究刚刚起步,现有的数据挖掘方法直接应用还存在许多问题。研究和探索适合于医学图像的数据挖掘方法及其算法等医学图像数据挖掘的理论和实践问题具有重要而现实的意义,对辅助医生进行医学图像临床诊断具有重要实用价值。本论文介绍了“基于医学图像数据挖掘若干技术研究”工作的相关研究成果,主要内容有:(1)总结了国内外关于图像数据挖掘研究现状和发展,探讨了医学图像的特点,提出了适合医学图像数据挖掘的图像数据预处理技术。图像象素的灰度及其密度是表达医学图像特征的主要内容,本文研究了医学图像的灰度及其密度与人体组织器官的解剖语义关系,分析了医学图像的成像原理和临床诊断要求,定义了表征医学图像的特征内容,并提出了适合医学图像数据的灰度特征及其表达方案。(2)基于医学图像数据挖掘的需求,本文综述了数据挖掘、非结构数据挖掘、图像数据挖掘的理论和方法,探讨了医学图像数据挖掘的方法和途经,提出了基于医学图像的数据挖掘的过程框架。(3)从聚类分析的角度出发,深入研究了医学图像数据的核密度函数、数据分箱问题和基于数据分箱策略的近似核密度构造方法。在此基础上,研究并提出了适用于医学图像数据的基于医学图像近似密度构造的聚类特征提取算法及其实现。根据这个算法,可以为基于医学图像聚类的组织器官分类及其自动分割提供有效的方法和技术。(4)从关联规则发现的角度出发,围绕医学图像的组织分类,深入研究了医学图像数据特征的关联问题,提出了基于关联规则的医学图像分类挖掘方法及其实现技术。图像特征的正确选择对图像数据的关联规则发现十分重要,本文在深入研究医学图像内容特征的基础上,首次提出了医学图像局部特征,并实现了基于医学图像组织器官聚类的医学图像局部特征提取,如:基于灰度共生矩阵和基于小波的特征提取方法和算法等。此外,本文还重点研究了医学图像数据特征的关联规则,探讨了所发现的规则与医学图像诊断的关系,为医学图像自动诊断提供了新的途径。(5)在相关医学图像数据挖掘算法研究的基础上,设计并开发了一个医学图像数据挖掘实验系统,该系统具有医学图像预处理、医学图像数据特征提取等功,能为面向医学图像数据的各种数据挖掘技术的研究和实现提供实验平台。鉴于人体腹部医学图像的数据挖掘研究是一个全新领域,人体腹部影像是医学图像中最复杂的部分,解决好腹部影像问题对整个医学图像都具有适用价值。本文所提出的基于医学图像近似密度构造的聚类特征提取算法及其实现、基于关联规则的医学图像分类规则挖掘方法等创新性研究成果,对医学图像数据挖掘研究、临床医学图像的自动诊断和临床医学早期诊断都具有重要意义。
[67]刘明亮,李雄飞,孙涛,许晓晴.数据挖掘技术标准综述[J].计算机科学,2008, 06:5-10+14.
关键词:数据挖掘,技术标准,紧密耦合,应用程序架构
摘要:随着数据挖掘技术应用日趋广泛,涌现出各种挖掘工具和系统。为规范相应的软件开发和数据交换方法,制订数据挖掘技术规范和标准成为当务之急。在将数据挖掘标准划分为过程标准、接口标准、语言标准和Web标准等四类进行分析介绍后,给出一个综合多种标准的应用程序框架,最后总结出数据挖掘标准化领域面临的问题和挑战,并对发展趋势予以展望。
[68]王立伟.数据挖掘研究现状综述[J].图书与情报,2008, 05:41-46.
关键词:数据挖掘,PAKDD
摘要:数据挖掘作为情报学最常用的分析手段得到各个领域的广泛关注,每年KDD、PAKDD和ECML/PKDD三大学术会议的召开也给各国家和地区进行学术交流提供便利。文章基于PAKDD学术会议和KDnuggets公司的统计数据对当前数据挖掘现状进行综述分析。
[69]李玲娟.数据挖掘技术在入侵检测系统中的应用研究[D].导师：王汝传.苏州大学,2008.
关键词:数据挖掘,入侵检测系统,特征选择,层次聚类,基于案例的推理
摘要:数据挖掘(Data Mining)技术是从已知数据集中挖掘有用知识的技术。近十年来的有关研究结果表明,将数据挖掘技术应用于入侵检测系统(Intrusion Detection System,IDS),对有效地进行特征选择,建立合适的检测模型,最终提高入侵检测系统的入侵检测能力,降低其误报率和漏报率有着十分重要的意义。虽然将数据挖掘技术应用于IDS时可借鉴的算法较多,但由于能适合所有情形的数据挖掘算法是不存在的,所以算法研究方面至今尚无权威性的成果;同时,很多研究过于注重理论性与技术性,忽略了所引入的数据挖掘算法的复杂度对入侵检测系统效率的影响;此外,目前成熟的IDS产品基本都采用基于规则的检测方法,这类IDS将数据包与规则库的规则进行精确匹配,如果攻击模式很常见或过于特殊,就容易产生误报或漏报,从而降低入侵检测的准确率。为此,本文以江苏省教育厅的研究项目“基于数据挖掘的入侵检测技术的研究”(02SJD520002)为背景,以适应IDS数据源特点、降低复杂度、提高效率为目标,对数据挖掘算法进行研究,包括特征选择算法、数值归约算法、聚类算法;也以增强灵活性、降低误报率和漏报率为目标,对基于数据挖掘的入侵检测方法进行研究。论文针对入侵检测系统中被检测数据的特点,提出了一种适用于IDS的多次模糊迭代特征选择算法和一种适用于IDS的基于相关性度量的特征选择算法。多次模糊迭代特征选择算法由在属性空间中搜索特征子集、评估每个候选特征子集和分类这三个步骤组成,有与之相应的搜索算法和评估函数;该算法通过多次迭代去除特征值集的冗余特征得到精确度较高的特征值集,使用模糊逻辑得到与精确度要求相应的取值范围;由于单纯对数据进行操作,该算法能更客观地分析数据;论文还基于KDD Cup 99数据集对该算法进行了仿真分析;并将实验结果与特征可视化结果进行了比较;实验结果表明该算法在IDS数据集上可取得良好的特征选择效果。基于相关性度量的特征选择算法对特征值进行模糊处理,计算特征相关性度量值,按度量值降序排列特征,再基于该特征序列进行特征选择;以分类器作为评估系统,以KDD Cup 99为数据源的仿真结果验证了该算法能在不影响效率的同时降低时间复杂度。论文还以提高IDS中分类挖掘的效率为目标,提出了一种适用于IDS中数据分类的数值归约算法,该算法一方面用值域来减少特征值数目,一方面将孤立的点放大为一个区域以预测类似行为;以KDD Cup 99数据集为数据源、以决策树分类算法为例的仿真实验结果表明,该算法能在降低已有分类算法的时间复杂度的同时使分类准确率有所提升。聚类分析常被用于IDS的入侵检测阶段。本文针对经典模糊C-均值算法FCM的缺陷,提出了一种基于层次聚类的模糊聚类算法HFC,该算法采用凝聚的层次聚类方法,快速地发现高度聚集的数据区域,并对这些高密度区域进一步分析与合并,通过评估函数的评估,找到最优的聚类方案;仿真实验结果表明,该算法具有较高的聚类精确度和较强的排除噪声的能力;论文还通过基于KDD Cup 99数据集的仿真实验,分析了该算法对IDS中入侵检测的适用性。为了提高基于规则的IDS的检测能力,论文提出了基于CBR (Case-Based Reasoning,基于案例的推理)的入侵检测方法;描述了实现CBR的步骤;给出了由规则设计和构造案例库的启发式方法;设计了适用于IDS的CBR引擎及案例匹配算法;分别通过基于Snort的规则集、自行开发的攻击平台及离线检测系统的实验和基于在线数据包的实验,验证了CBR对基于规则的IDS检测能力的增强作用。最后,总结了所做的工作,分析了存在的不足,提出了进一步研究的目标。论文对数据挖掘技术在入侵检测系统中的应用做了有益的研究。
[70]覃明贵.城市道路交通数据挖掘研究与应用[D].导师：朱扬勇.复旦大学,2010.
关键词:智能交通系统,交通流,交通拥堵,交通流分布模式,数据挖掘
摘要:智能交通系统是有效地集成信息技术、数据通讯技术、电子传感技术、电子控制技术以及计算机数据处理技术的地面运输管理体系,是当前研究与应用的热点。其中,大规模交通数据管理、整合和挖掘是一项关键技术。数据挖掘是从大量数据中寻找其规律的技术,是目前最强有力的计算机数据分析技术之一。交通数据挖掘技术的研究是智能交通技术和数据挖掘技术领域最活跃的研究方向之一。交通数据挖掘的主要目的是寻找交通数据中的规律,为智能交通系统的设计提供技术支持,有利于缓解交通拥挤、优化交通路网运行,促进交通健康稳定发展。交通流量、交通拥堵状况和交通流分布预测和分析是目前智能交通数据挖掘研究中的三个重要问题,对于智能交通系统的交通信号管理与控制、交通流诱导、动态交通分配等方面有着重要的意义,在智能交通系统设计和实现中起着重要作用。当前智能交通数据挖掘研究的重点在于如何设计有效的挖掘算法,主要有两个方面的难题：一方面,由于交通流数据的特殊性,使得现有的数据挖掘算法无法直接在大规模交通流数据中高效实现；另一方面,由于没有根据领域知识设计专门的挖掘算法,造成挖掘结果无法满足应用需求。本文针对当前智能交通数据挖掘技术研究领域中存在的问题,在交通流量预测、交通拥堵事件挖掘和交通流分布模式挖掘等几个方面开展研究,提出了相应的挖掘算法,并将这些方法应用于智能交通数据挖掘系统中。本文取得的主要研究成果如下：1)针对短时十字路口交通流量预测问题设计实现了基于组合模型的挖掘算法及时、准确地识别和预测道路交通的状态是智能交通系统实现动态交通管理的重要前提。交通流量是交通流的重要特性之一,智能交通系统的控制和诱导需要对道路网络交通流量进行准确、快速的预测。本文针对路口短时交通流量预测问题,提出了基于交通流量序列分割和神经网络组合模型的交通流量预测算法CITFF (Combined Intersection Traffic flow Forcast), CITFF算法首先采用聚类方法对交通流量在流量大小和时间上进行序列分割,然后再采用神经网络对各个交通流模式进行描述和预测。实验证明基于组合模型的预测方法具有较高的预测精度。2)构建了道路交通流模式库并设计了相应的交通流拥堵事件挖掘算法如何应对城市现代化带来的交通拥堵问题,是交通管理者迫切需要解决的问题。道路交通的拥堵事件检测是智能交通领域研究的关键技术。本文通过对道路交通流数据的分析,构建了道路交通流模式库,并给出一个结合同向斜率树(Same-Directed Slope Tree, SDS-Tree)逐层分类表示交通流数据的方法。基于构建的交通流模式库,提出了一种高效的道路交通流的拥堵事件挖掘算法Detection-CS (Detection of Continual Stream of Traffic Flow),同时对算法效率和空间复杂度进行了详细分析。Detection-CS算法首先对当前实时交通数据进行特征提取,通过对交通流模式库进行匹配,获取前k个有效反馈,并根据反馈的交通路况信息进行分析,结合路况分层模式信息,给出当前路况的实时检测信息,实现对交通路况检测。为提高挖掘算法的效率,根据交通流模式库的路况分层信息,建立了多层索引结构,减少算法的搜索空间,从而实现算法优化。结合实际需要,算法进一步给出随着时间推移如何更新交通流模式库的方法,通过逐步替换使用频度最少的信息和更新新出现的路况信息,保证交通流模式库的有效性。在真实数据集上的实验表明,与现有算法相比,Detection-CS算法对于当前解决交通路况的实时检测具有很好的效率和较高的准确度。3)提出了一个道路交通流分布模式挖掘算法道路网络上运行的交通流具有不同的空间分布模式,根据交通流运行的空间分布特性,对道路交通网络进行实时、动态的交通区域划分是当前智能交通系统的研究热点之一。本文对分布在道路网络空间中的环形感应线圈检测器检测的交通流数据进行空间聚类分析,设计了一个高效的交通流空间聚类算法SPANBRE (Efficient Clustering Algorithm for Spatial Data with Neighborhood Relations),自底向上生成道路交通流的空间簇,使具有相似性质且具有空间关联性的交通流数据对象聚成一簇,用以发现道路交通流的空间分布模式。SPANBRE算法无需执行复杂的空间连接和空间合并操作,实验证明具有良好的时间效率。4)设计实现了一个基于数据挖掘技术的综合智能交通系统道路交通数据挖掘技术的研究对于智能交通系统的交通信号管理与控制、交通流诱导、动态交通分配等方面有着重要的意义。本文将上述挖掘方法应用于智能交通系统中,设计并实现了一个基于数据挖掘技术的综合智能交通系统。该系统已经实际获得应用,为道路交通管理提供了有效的工具。
[71]胡俊.数据挖掘可视化模型及其应用研究[D].导师：黄厚宽.北京交通大学,2009.
关键词:数据挖掘可视化,度量模型,可视计算,数据可视化,可视化技术,图标技术,平行坐标技术,多边形技术
摘要:数据挖掘是从大数据集中自动或方便地发现知识模式。可视化技术是一种表示数据对象的技术,在数据挖掘中主要可以应用于数据对象与数据挖掘过程可视化等方面,常常需要处理大数据集。目前,可视化技术一般是用于数据挖掘中的数据对象可视化,而数据分析方法及挖掘过程本身常常没有进行有效的可视化。可视化与数据挖掘技术之间的关系是松散的。将可视化技术应用于数据挖掘中,或者建立可视挖掘方法是有关可视化与数据挖掘的一个交叉研究课题。这种研究需要建立在合理的认知基础和依据之上。一方面需要分析研究这种方法的理论与技术基础,另一方面还需要考虑到挖掘对象的属性的可视特征与人们对可视特征的认知基础和依据。将可视化技术用于数据挖掘时主要可以考虑两个方面,一个是挖掘算法运行过程的可分性,也就是算法运行过程分解对结果不产生变异的可行性;另一个是确定算法及度量标准中的关键因素,并找出其对挖掘结果的影响。为了更好地说明多维数据的可视化效果,应该使对可视化对象的处理能够对应到对数据对象的处理,这样可以在一定程度上实现在可视化应用中引进必要的度量指标。引进合适的应用于量化的度量指标,有助于改进可视化技术,并设计适用的可视化技术的评测指标,建立实用的评测模型。基于度量指标的可视化技术在对可视对象的分析处理上可以借助适用的数学方法建模与评测,这有助于数据挖掘可视化的研究与应用。基于可视化度量指标的数据挖掘算法的应用,提供了一种可视的数据挖掘方法。在数据挖掘过程中,通过可视化技术的应用,有助于发现数据的特征。将度量指标作为一种评测指标,通过改进参数与过程,可以改进挖掘结果。本论文针对数据与数据挖掘可视化模型的形式表示、可视化技术的度量模型及其应用方法等作了研究。本论文的主要工作包括以下方面:(1)分析研究数据挖掘中可视化技术应用的特点与方法。给出了数据对象与数据挖掘过程的可视化表示的一般数学形式,即数据对象的转换模型、关联可视化模型、关联统计可视化以及过程可视化模型。(2)提出了描述数据属性间特征的影响度概念,基于图标技术,提出相应的可视化表示及可视计算方法,并将概念与方法应用于数据对象及与数据属性相关统计信息的可视化表示。实验表明,该方法用于数据可视化与数据分析是简单有效的。(3)提出了一种基于平行坐标技术的度量模型及相应的指标体系,证明了其中的相关性质与结论,形成了一套基于平行坐标技术的度量模型量化理论,并研究了度量指标在聚类分析算法K-means中的应用方法。实验表明,提出的度量模型和度量指标在数据与数据挖掘可视化应用中是有效的。(4)介绍了八叉树在数据挖掘中的运用以及设计实现的三维数据可视化平台。介绍了基于平行坐标技术的关联规则的可视化方法,以及基于多边形技术在多维数据可视化中的应用方法。
[72]方洪鹰.数据挖掘中数据预处理的方法研究[D].导师：张俊容.西南大学,2009.
关键词:数据挖掘,数据预处理,统计方法,非线性相关分析
摘要:在现代的科研和实际工作中,各行各业都需要对采集到的各种各样的数据进行处理。如何从这些海量的数据之中发现更深层次、更重要的信息,使之能够描述数据的整体特征,可以预测发展趋势,从而生成决策。这就需要进行数据挖掘。数据挖掘与知识发现过程中的第一个步骤就是数据预处理。统计发现,在数据挖掘与知识发现的过程中,数据预处理占到了整个工作量的60%。因为现实世界的数据往往是不完整的、含噪声的和不一致的,数据预处理能有效提高数据质量,为数据挖掘内核提供更有针对性的可用数据,不仅可以节约大量的时间和空间,而且得到的挖掘结果能更好地起到决策和预测作用。目前数据预处理的常用步骤包括:数据清理、数据集成、数据变换以及数据归约。本文总结了目前数据预处理的常刚方法,并对其分析和思考。发现有些方法可以在数据预处理的不同阶段使用,分别达到相应阶段的预处理效果。在预处理中用到了许多的统计方法,但需要与实际的数据特征和专业知识相结合才能有效地应用。强调了在预处理的每一个步骤都要与专业知识和实际应用相结合。考虑到若在数据获得初期就有一定的指导,可以减少数据获取的盲目性以及不必要的噪声引入,且为后期的工作节约大量的时间和空间,因此认为应该把数据源的获取作为预处理的一个步骤。在预处理的实际应用过程中,上述步骤并不是相互独立的,而是相关联的,因而提倡对数据预处理采取循环的模式。最后针对银行房贷信用风险评估课题中所遇到的数据预处理问题,结合数据特征,考虑到与之相关的各个因素的内在相关性,使用一种基于全局的非线性相关分析技术,这是一种统计方法,来对该问题进行讨论,并且实证研究。
[73]杨宸铸.基于HADOOP的数据挖掘研究[D].导师：向宏.重庆大学,2010.
关键词:云计算,数据挖掘,SPRINT,HADOOP,并行计算
摘要:随着计算机技术以及互联网运用高速的扩展到人类社会生产生活的各个方面,数据量呈现出爆发性的增长。如今,大数据集以及超大数据集的存储和处理已成为很多企业面临的新的挑战。而如何能以更加快速、高效、低成本的方式从海量数据中挖掘有价值的、可理解的知识从而帮助企业制定决策成为数据挖掘技术面临的新课题。云计算技术的出现为数据挖掘技术的发展带来了新的机遇。云计算技术通过使存储和计算能力均匀的分布到集群中的多个存储和计算节点上,从而实现了对超大数据集的巨大的存储和计算能力。由于可以使用大量的廉价计算机通过集群来代替价格高昂的服务器,云计算大大的降低了成本。使用云计算技术提供的巨大的存储能力和计算能力,数据挖掘技术进入了基于云计算的数据挖掘时代。HADOOP是一个用于构建云平台的Apache开源项目。使用HADOOP框架有利于我们方便、快速的实现计算机集群。在HADOOP平台上,采用了HDFS(分布式文件系统)来实现超大文件的存储和容错,而使用了MapReduce的编程模式来进行计算。将HADOOP运用到数据挖掘,一个关键的问题就是如何实现将传统的数据挖掘算法实行并行化。对于传统的数据挖掘算法,结合算法自身的特点,我们可以很容易或者需要深入研究才能发现它是否能够并行。对于能够并行实现的算法,结合MapReduce编程模式,我们可以将其移植到HADOOP平台上,高效的、并行的完成数据挖掘任务。本文首先详细的介绍了云计算和HADOOP平台的核心架构以及运行机制。然后结合传统的数据挖掘系统提出了基于HADOOP的数据挖掘平台的技术架构。所以,在深入了解到MapReduce编程模式后,结合决策树算法中的SPRINT算法,我们成功的实现了将SPRINT移植到HADOOP平台。在给出详细的算法后,我们通过实验验证了算法的有效性。
[74]樊嘉麒.基于大数据的数据挖掘引擎[D].导师：潘维民.北京邮电大学,2015.
关键词:大数据,数据挖掘,Spark
摘要:随着互联网技术的快速发展,人们积累的数据量越来越大,数据的规模已经从之前的GB级别,上升到TB甚至PB。为了发现数据中的潜在价值,通常的做法是根据实际情况,灵活的运用各种数据挖掘算法。尽管数据挖掘在传统的小数据集上已经得到了充分的利用和发展,证明了其价值和指导意义,但是在大数据集上,数据挖掘算法的实施面临着执行效率、算法并行化、平台易用性等方面的重大挑战。本论文是一篇工程性论文,调查并研究了众多相关开源解决方案,最终基于Spark作为引擎核心和编程模型,设计并实现了部分并行化数据挖掘算法,并且构建了一个易用、高效的大数据挖掘引擎系统。从总体上看,本文完成了以下工作：(1)调研了两种主要的大数据并行计算模型一一以MapReduce为编程范式的编程模型和以内存计算算子为编程范式的编程模型。通过比较其计算效率、编程接口丰富程度和友好性等方面,确定了采用内存计算的方式,并以Spark作为大数据处理的核心引擎。(2)基于Spark的内存计算模型及其提供的若干个动作、转换算子,完成了两个传统数据挖掘算法一-Apriori和PageRank的并行化改造。通过实验验证了这两个算法的执行效率和并行化效果。(3)设计了大数据挖掘平台,以平台即服务的方式提供大数据计算资源,提供了远程过程调用的开发工具包(SDK)。解决了易用性、跨平台、多用户并发控制等问题。通过以上工作,实现了一个完整的大数据挖掘系统,为数据挖掘算法在大数据集上的实施提供了高效、易用的利器。
[75]王达明.基于云计算与医疗大数据的Apriori算法的优化研究[D].导师：崔晓燕.北京邮电大学,2015.
关键词:数据挖掘,云计算,医疗大数据,Apriori算法,Hadoop平台
摘要:随着医疗行业的不断发展,医疗数据的规模不断扩大,而其蕴含的价值也不断增高,医疗大数据的概念已经成为很多专家及学者研究的目标。面对医疗大数据庞大的数据规模,传统的存储架构已不能满足其需求,而云计算的出现为医疗大数据的储存和调用提供了一个完美的解决方案。医疗大数据中潜在信息的价值更是无穷无尽的,如何将这些潜在的信息挖掘出来是研究的重点。数据挖掘技术以及关联规则挖掘是能体现医疗大数据价值的重要技术,但是传统的挖掘算法已不能满足医疗大数据以及云计算的要求,通过对算法的改进和优化以适用于医疗云平台,将是未来研究的重要方向。本文首先根据医疗大数据以及云计算的概念及特点,提出了一种医疗云平台的架构方案,包括数据采集层、数据云储存层、数据挖掘层、企业及数据库以及应用层5个部分。针对现有医疗数据挖掘技术中的关联规则算法,本文进行了分析与研究,并通过引入了兴趣度对经典Apriori算法进行改进,并且运用云计算和云平台Hadoop的知识,提出了一种基于MapReduce化以及兴趣度的改进Apriori医疗数据挖掘算法。最后,本文通过搭建Hadoop平台进行仿真实验,算法用JAVA实现,通过对训练数据进行挖掘,结果表明改进算法在处理大数据时空间复杂度更低,且挖掘时间随着数据规模的增大呈线性增长,验证了改进算法在进行大数据挖掘时的优越性。
[76]贾云朋.数据挖掘在股票曲线趋势预测中的研究及应用[D].导师：曹旭光.吉林大学,2015.
关键词:股票分析,数据挖掘,曲线趋势
摘要:我国的股票市场正在快速发展，并走向成熟化。随着股票市场的发展，股票数据曲线趋势的研究仍具有很强的应用价值。技术分析，作为证券分析中的重要组成部分，在国内外的研究己经达到了较高的水平。在信息技术不断发展的同时，新的理论和技术分析手段不断地被应用到技术分析中。目前，市场上有很多种类的股票分析方法，但都有各自的优缺点，存在各种各样的不足。通过对众多股票预测方法研究分析发现，大多股票分析方法都存在操作过程复杂、股票数据分析的不准确或不容易量化分析等问题。本文主要研究了数据挖掘在股价曲线的趋势预测。文章从上市公司的历史股票数据入手，应用数据挖掘中几种常用概念和方法对其未来股价进行分析，以预测该公司股价的未来变化趋势，并与实际趋势进行比较，分析其适用性。主要研究内容包括以下几个方面：文中首先介绍了数据挖掘技术与证券分析技术的基本内容并论证了数据挖掘在股市趋势预测中的可应用性。在此基础上研究了一些现有方法，包括时间序列方法和马尔可夫方法，并分别进行实验。应用时间序列方法预测时使用了一次移动平均预测法、一次指数平滑预测法和两次指数平滑预测法。根据实验结果，发现一次指数平滑预测法避免了一次移动平均预测法无法覆盖样本数据且无法判断样本数据影响力大小的问题，而两次指数平滑预测法避免了一次指数平滑预测法只适合于具有水平发展趋势的时间序列分析的问题。然后根据上述方法中避免缺陷的改进策略，分析马尔科夫预测方法的实验结果，找到其缺陷并提出了考虑成交量影响的马尔可夫预测法，提高数据覆盖率，然后对其进行实验验证。文章最后总结了所有方法，并提出避免新方法状态可能不存在缺陷的方法，以提高运算效率。从实验中可以看到：时间序列法预测计算量小，过程简单，但是误差较大；马尔可夫预测法预测准确度有所提高，但由于只考虑单一因素的影响，所以仍有改良空间；而成交量影响的马尔可夫预测法，考虑到了不同因素的影响，准确度最高，适合预测单一股票短期的价格趋势。文章中使用的方法都较为容易量化实现，且结果清晰，实际股价曲线趋势预测具有一定的参考价值。
[77]何小东,刘卫国.数据挖掘中关联规则挖掘算法比较研究[J].计算机工程与设计,2005, 05:1265-1268.
关键词:数据挖掘,关联规则,算法,频集
摘要:分析数据挖掘中关联规则挖掘算法的研究现状,提出关联规则新的价值衡量方法和关联规则挖掘今后进一步的研究方向。以核心Apriori算法为基点,运用文献查询和比较分析方法对典型的关联规则挖掘算法进行了综合研究:①Apriori方法即使进行了优化,一些固有的缺陷仍然无法克服,还需进一步研究;②今后的研究方向将是提高处理极大量数据和非结构化数据算法的效率、与OLAP相结合以及生成结果的可视化。
[78]谈恒贵,王文杰,李游华.数据挖掘分类算法综述[J].微型机与应用,2005, 02:4-6+9.
关键词:数据挖掘,关联规则,决策树,分类算法
摘要:基于数据挖掘分类算法的研究现状,对目前发展较成熟的几种分类算法如决策树、关联规则分类、神经网络、贝叶斯方法、遗传算法等数据挖掘分类算法分别进行了论述。主要分析比较各典型算法的优点和不足,对其他一些算法也作了简单介绍,旨在追溯算法的发展轨迹,指出部分算法可能发展的方向,为进一步研究提供有益的借鉴。
[79]颜巍.基于云平台的数据挖掘算法的研究与实现[D].导师：罗光春.电子科技大学,2013.
关键词:Hadoop,MapReduce,数据挖掘,K-Means,协同过滤
摘要:随着信息社会的发展，每天产生的数据量成指数级增长。如何从海量数据中挖掘有用信息成为公司面对的一大难题。数据挖掘算法对数据进行处理，挖掘隐藏有用信息，有利于公司作出发展决定，但目前的挖掘算法处理海量数据需要耗费很长的时间或无法处理海量数据。将传统算法迁移到云平台进行并行化改进可以有效的解决该问题。Hadoop是Apache开发的一种分布式系统框架，底层的HDFS提供了具有高容错、高吞吐率的文件存储读写；MapReduce提供了一种并行化编程框架，用户无需了解分布式并行化编程细节，只需编写Map和Reduce类就能实现分布式程序。Hadoop的海量数据存储平台和简单的并行化计算平台，为传统数据挖掘算法能够处理海量数据提供了基础。本文研究Hadoop平台技术和常见的数据挖掘算法，利用Hadoop集群并行处理数据的能力对K-Means算法、协同过滤算法进行并行化改进。主要工作如下：(1)K-Means算法是一种常见的聚类算法，按照元素之间的相似性将原始数据划分为多个簇。在本文中，针对聚类算法K-Means依赖于k值和初始中心点的缺陷，提出了基于采样和密度的改进K-Means算法。通过采样和密度来确定K-Means算法初始k值和初始中心点，并且基于Hadoop平台进行并行化改进。通过实验验证，改进后的K-Means算法具有很好的并行性。(2)协同过滤算法是目前用的最多的一种项目推荐算法，通过计算用户之间的相似性找到具有最高相似度的k个邻居，然后通过邻居对项目的评分为用户推荐项目。在本文中，针对用户评分的稀疏性，提出了一种基于用户相似度和属性权值的混合推荐算法。通过对用户评分记录的学习，求出项目属性的权值，通过属性的权值并结合用户相似度来推荐项目，最后将算法移植到Hadoop平台。通过实验验证，改进后的协同过滤算法比原始算法具有更好的精准度和并行性。(3)目前，Hadoop平台主要通过命令行进行操作，这对普通用户具有一定的难度。本文设计实现了基于Hadoop平台的数据挖掘系统。该系统将数据挖掘算法和Hadoop平台细节进行封装，对外提供Rest接口，用户通过Rest接口调用并行化的数据挖掘算法进行数据分析，无需了解底层的具体实现。
[80]张轲智.基于web的数据挖掘系统设计与实现[D].导师：刘强;杨军.电子科技大学,2013.
关键词:数据挖掘,web挖掘,数据库
摘要:对企业而言，如何在竞争日趋激烈的商业中生存，发展，争取更多的客户显得格外重要。如果了解客户需要什么，对什么更感兴趣，如何做出关键决策，更能吸引用户购买自己的商品，将为企业获得更多的利润。数据挖掘，作为一种新兴的商业技术，可以获得利于商业化运作、富有竞争力的信息，成为解决此问题的关键。用户在通常的行为过程中，如浏览网页等，会留下大量的记录。这些看似无用的信息在数据挖掘系统里面通过分析、转换、抽取或者利用其他模型化等方式进行处理，就可以得到对商业决策有很大帮助的重要数据。本文研究了以下的内容：首先，探究了数据挖掘的概念，介绍了数据挖掘的过程和功能，并且对数据仓库进行了研究。本次数据挖掘重点采用web挖掘，并且详细讨论了web挖掘的特点和用户行为分析的相关基础知识。接着对数据挖掘的各个功能模块进行设计，并对数据挖掘体系进行研究。非常详尽的介绍了系统中常用的一些算法，并对数据挖掘体系进行了研究分类。重点对关联规则，聚类算法和回归分析等算法进行介绍，并且构造了此次任务所使用的web算法。最后本文对数据挖掘系统进行设计，并对系统架构的相关模块进行实现，包括数据的预处理模块，数据读取的模块，以及兴趣挖掘的模块，再对系统性能进行调试，主要对准确率和查全率这2个指标进行模拟评估，得出系统的可靠性，并且展示出系统所挖掘出来的一些数据。本设计通过提取xml文件中用户在网页中留下的大量记录，作为基础数据源，提出了数据挖掘的一般模型，通过聚类，关联等算法，研究出用户上网行为中的普遍规律，分析出用户潜意识中的需求。对于企业了解用户行为产生了良好的效果，意义在于力求对企业做出利于商业化运作的决策提供良好的支持。
[81]李伟卫.基于Hadoop平台的数据挖掘技术研究[D].导师：张阳.西北农林科技大学,2013.
关键词:云计算,数据挖掘,Hadoop,MapReduce,HBase
摘要:随着科技的飞速发展，人们基于互联网所产生的数据呈现出爆炸般的增长态势。传统的计算机体系架构在大数据面前显得力不从心。云计算的提出，为复杂的大数据处理提供了新的解决方案。Hadoop是Apache基金会的开源项目之一，它基于普通商用计算机集群，展现出了卓越的计算能力、存储能力与调度能力。数据挖掘技术也以此为契机，进入了一个飞速发展的阶段。本研究基于Hadoop平台，在充分学习分布式程序的运行机理基础之上，对几种具有代表性的数据挖掘算法的实现思路与方法进行了深入研究，提出了将它们向分布式平台改造的方案，并实现了可以良好运行的Hadoop版本，从而帮助广大数据挖掘从业人员更好地基于该平台开展各项工作。课题研究的主要内容有：（1）针对传统的以文本方式存储的数据，基于MapReduce分布式编程框架，从数据挖掘三大类算法：分类、聚类和关联规则挖掘算法中，分别取每一类中有代表性的一种，分析算法的运行原理，制订改造方案，针对朴素贝叶斯分类算法、K-modes聚类算法、ECLAT频繁项集挖掘算法，进行了分布式算法的实现，它们均能够基于Hadoop平台高效、稳定运行。（2）针对互联网中新兴的非结构化数据，采用HiveQL语言作为检索入口，基于HBase分布式数据库，实现能够在其中稳定运行的分布式GAC-RDB分类算法。它使用高层语言作为切入点，不需要拥有诸如Java、MapReduce等背景知识，将开发人员从各类底层繁琐代码中解放出来，把主要精力投入到具体的业务分析中去，从而更快速、更便捷地完成各类数据挖掘任务。基于西北农林科技大学高性能计算集群，设计了多组方案对改造后算法的有效性和Hadoop平台的高效性进行了实验验证，将数据绘制成曲线并从多个角度进行了分析。实验结果表明，在保证算法有效性和准确率的前提下，MapReduce编程框架可以有效提高程序的运行效率，降低数据的处理时间；HiveQL查询语言可以减少程序的开发周期，更加方便地处理各种存储在分布式数据库中的数据。
[82]刘丽娟.网络用户数据挖掘与行为分析[D].导师：沈波.北京交通大学,2014.
关键词:互联网,用户行为分析,数据挖掘,兴趣模型,网络舆论
摘要:随着互联网的不断发展和用户需求的不断提高,有关网络用户的行为分析和数据挖掘研究迅速发展起来。作为Web2.0技术的典型代表,网络论坛承担着传播信息和舆论导向的作用。因此,对论坛用户的兴趣建模和预测不仅有助于正确分析用户的兴趣所在,而且有助于向用户提供个性化服务。论坛帖子的热度预测对于提前掌握舆论动向具有重要意义。本文首先对常用的数据挖掘算法和用户兴趣模型进行简要介绍,然后对天涯论坛的用户数据集进行处理分析,设计了适合论坛的用户兴趣权重更新算法,并对用户兴趣进行有效预测,接下来分析了帖子热度的影响特征来对热门帖子进行预测。基于论坛访问时间间隔和发帖回帖数量的用户兴趣权重更新算法,建立在用户访问时间存在较大间隔的基础上,将用户的访问时间间隔和发帖回帖次数同时作为权重计算的重要变量；在兴趣预测方面,设计了一种两阶段的用户兴趣聚类算法。通过对论坛数据集进行仿真实验,验证了用户兴趣更新算法和推荐的有效性和准确性。论坛帖子热度受多方面因素的影响。根据网站用户的好友关系、关注关系、经验值等信息提取出用户性质和用户关系特征；帖子受众程度与其讨论内容有密切联系,因此帖子内容也是热度的重要影响因素；另外,帖子的发帖时间也会对其热度产生一定程度的影响。在分析帖子热度影响特征的基础上对帖子热度进行支持向量机回归,取得了满意的预测结果。最后,将用户兴趣建模和热帖预测相关算法应用到网络舆论分析中,设计了基于论坛的用户行为分析系统。系统分为数据获取、数据预处理、用户行为分析和数据存储模块,负责实现用户兴趣识别、上网时间统计、活跃用户发现、意见领袖发现和热帖预测等功能,并详细介绍了各个模块的设计,然后对系统的设计框架进行构建,作为未来系统实现的基础。论文的工作得到了国家自然科学基金(No.61172072,61271308)、北京市自然科学基金(No.4112045)、高等教育博士点基金(No.W11C100030)、北京科技计划(No.Z121100000312024)和北京市教育委员会学科建设与研究生建设项目等课题的支持。
[83]郭秀娟.数据挖掘方法综述[J].吉林建筑工程学院学报,2004, 01:49-53.
关键词:数据挖掘,挖掘工具,挖掘方法,挖掘理论
摘要:数据挖掘方法结合了数据库技术、机器学习、统计学等领域的知识,从深层次挖掘有效的模式.数据挖掘技术的常见方法,关联规则、决策树、神经网络、粗糙集法、聚类方法、遗传算法和统计分析方法被应用到各个领域,数据挖掘技术具有广泛的应用前景.
[84]卢硕.数据仓库和数据挖掘在决策支持系统中的应用研究[D].导师：王保保.西安电子科技大学,2006.
关键词:决策支持,数据仓库,数据挖掘
摘要:随着计算机的普及和关系数据库系统的巨大成功，各种数据库系统以前所未有的速度开发出来并在各行业广泛应用，使得事务处理变得更加准确、高效，积累的数据更是以指数级的速度增长，但数据泛滥、信息贫乏仍困扰着决策者。作为新的数据库应用技术和工具，数据仓库和数据挖掘技术日益盛行并成为决策支持系统的技术支柱。本文从决策支持系统发展和需求出发，全面介绍了数据仓库设计理论和数据挖掘概念及其应用。重点讨论了数据仓库的构建和数据挖掘中的关联规则算法，并运用高校教师相关数据，初步分析了高校教师数据仓库的设计和关键技术，完成了相关主题的多维数据模型的设计，并用三种不同方法示例OLAP分析结果，特别是对MDX处理过程及扩展作了详细说明。运用Apriori算法实现基于教师素质主题数据立方体的关联规则挖掘模型的构建，通过对挖掘结果分析发现教师引进相关知识，协助决策者找到学校教师引进的决策支持信息。最后提出进一步建设基于Web的数据仓库以实时挖掘知识和支持决策。
[85]关大伟.数据挖掘中的数据预处理[D].导师：李雄飞.吉林大学,2006.
关键词:数据挖掘,数据预处理,维规约,聚集,过滤异常值,重复记录处理
摘要:随着社会的发展和数据库的应用,各领域的应用数据库中都积累了大量的历史数据。如何利用这些有潜在价值的数据,从中提取出有用的信息和知识,是应用者日益关注的问题,也是数据挖掘技术的关键所在。要进行数据挖掘,首先要保证数据质量,良好的数据能提高数据挖掘效果和效率,数据预处理逐渐成为数据挖掘不可缺少的重要前提。在数据挖掘的过程中如果只着眼于数据挖掘算法的探讨,而忽视了对数据预处理的研究,在一定程度上往往会失去数据挖掘的某些重要意义。因为实际系统中的数据一般都具有不完整性、冗余性和模糊性,很少能直接满足数据挖掘算法的要求。另外,海量的数据中无意义的成分很多,严重影响了数据挖掘算法的执行效率,而且由于其中的噪音干扰还会造成挖掘结果的偏差。因此,对不理想的原始数据进行有效的归纳和预处理,已经成为数据挖掘系统实现过程中的关键问题。本文通过对数据挖掘、数据预处理技术和理论的学习,以及对国内外数据挖掘与数据预处理系统的发展情况的研究,归纳总结了国内、外数据挖掘系统中数据预处理的特点,根据当今数据挖掘技术和数据挖掘系统的发展趋势,设计了一个数据预处理系统,该软件设计实现的预处理系统主要包括数据预处理过程中最常用、最直接、最有效的和有一定通用价值的维规约、聚集、过滤异常值、去掉重复记录处理,软件在一定程度上实现了对大量数据的清洗工作,为进一步数据挖掘提供了可靠的数据保障。
[86]周东华.数据挖掘中聚类分析的研究与应用[D].导师：梁洪峻.天津大学,2006.
关键词:数据挖掘,聚类分析,k-平均算法,DBSCAN算法,异常点
摘要:数据挖掘是目前信息领域和数据库技术的前沿研究课题,被公认为是最具发展前景的关键技术之一。数据挖掘涉及到统计学、人工智能(特别是机器学习)、模糊理论和数据库技术等多种技术,它强调的是大量数据和算法的可伸缩性,是一门很接近实用的技术,其技术含量比较高,实现难度也较大。聚类分析是数据挖掘的重要功能之一,近年来在该领域的研究取得了长足的发展,出现了许多聚类分析方法,如划分聚类方法、层次聚类方法、基于密度的聚类方法、基于网格的聚类方法、基于模型的聚类方法等。这些方法所涉及的领域几乎遍及人工智能科学的方方面面,而且在特定的领域中,特定的情形下取得了良好的效果。但是当处理数大量数据、具有复杂数据类型的数据集时,仍存在若干尚未解决的问题。本文系统地研究了数据挖掘的概念、功能、处理过程及技术算法,数据挖掘的核心技术是数据挖掘的算法,本文就数据挖掘的算法做了分析和比较,选取了K-平均算法和DBSCAN算法做了深入的研究,并给出了一种基于距离的异常数据挖掘算法。本文以山西省一所高职院校的学生成绩数据为背景,通过数据预处理工作,应用以上几种算法对上述数据进行了聚类分析,实现了可视化,最终挖掘到一定价值的信息。
[87]陈文文.图书馆使用者行为模式的数据挖掘研究[D].导师：余建桥.西南大学,2007.
关键词:数据挖掘,图书馆,行为模式,书目挖掘
摘要:在数字化的时代里，数据收集与数据挖掘，被视为是单位制订政策与决策建立时的一项具有高度参考价值的信息。图书馆经营的目的就是要能够更符合读者的需求。主动发掘读者的需求，主动提供读者所需要的信息，便是现今图书馆重要的工作项目，而图书馆自动化系统便是读者积极满足个人信息需求的行为结果，也是读者使用图书馆资源的最佳证据。对图书馆的借阅历史记录进行数据挖掘和分析，以变图书馆的被动服务为主动服务，提高图书馆在校园里的整体形象。在数据挖掘的过程中，首先要先确定研究主题，本研究是以西南大学图书馆用户，在图书馆自动化系统中的借阅记录为轴心，并加入用户的基本数据来当作挖掘时的特性区分，经过数据的整理与数据的转换，建立数据仓库。针对所建立的数据仓库，作聚类分析、分类分析与关联规则分析的数据挖掘探勘，挖掘的项目以四个维度「图书」、「读者」、「时间」、「读者单位」做交叉分析，最后所得的结果即是用户使用图书馆的一个行为模式。这些行为模式除了是直接反映出用户使用图书馆的行为模式之外，同时针对这些模式来作分析，可以提供图书馆在做经营决策时，一个重要的而且客观的参考依据，这些经营决策包含了馆藏政策、图书推荐、预算分配以及图书馆经营等工作。本论文是利用数据挖掘技术探讨读者的行为模式，以西南大学图书馆的“金盘信息管理系统”中的历史借阅记录、西南大学图书馆馆藏、读者信息库为基础数据来源，运用数据挖掘技术来探索西南大学读者的社群特性，并运用数据挖掘的成果来提升图书馆的经营与服务，期望能使西南大学图书馆在西南大学的读者学术、知识吸收和运用中扮演更积极的角色。本论文拟探索的读者社群关系包含：1．馆藏借阅的共同性：有类似兴趣的读者通常所借阅的馆藏也会很类似，如果利用数据挖掘技术把馆藏借阅的共同性找出来?2．馆藏借阅的顺序：读者借阅馆藏可能会先借入门的再借深入的，如何用数据挖掘方法把读者借阅馆藏的顺序特性找出来?。当我们挖掘出读者的社群关系后，希望能运用这些社群关系和数据挖掘的相关技术达到以下的目的：1．吸引读者到管借阅：我们发现很多读者从未借阅过馆藏，要如何增加借阅的读者人数?2．提升馆藏的借阅率：我们发现有很多馆藏是未曾或极少被借阅的，要如何才能把这些馆藏推销出去呢?3．提升读者忠诚度：我们发现有很多读者只借一、两次就不再借阅，要如何提升读者的忠诚度，使读者能够持续地借阅?4．协助馆藏副本采购：图书馆针对一本书所采购的副本数往往有限，但有些热门书读者常常要预约很久才能借到，很多甚至是借不到，很多读者因此而放弃借阅。要如何找出哪些是热门的书?哪些该多买一本?5．促进馆藏流通率：过期还书对图书馆经营来说，是一个令人棘手的工作。很多热门的馆藏往往过期才归还，其他读者要借阅预约很久才能借到。因此针对读者逾期的状况来分析，找出经常逾期还书的特殊群体，可以在事前多做预防。6．时间序列的分析：对于开管时间是利用时间序列分析，找出是否于每周、每月甚至每季、每年中读者使用图书馆的时间规律性，一旦规则可以找出，将可作为图书馆开管时间延长或缩短的参考，这样的资讯尤其在寒、暑假，将更加重要，以数据挖掘技术所得的资讯，将可水副学校决策单位提供适当的人力，同时对于图书馆工作人员也更可以接受开管的时间。
[88]黄玲.在电子商务中应用Web数据挖掘的研究[D].导师：王树林;胡觉生.湖南大学,2014.
关键词:Web数据挖掘,电子商务,Apriori算法,推荐系统
摘要:互联网的应用使数据增长速度惊人,智能手机、平板电脑、云空间、物联网的推进,促使数据膨胀问题更加严峻。经济全球化需企业家敢于表现,吸引客户注意力,服务好客户,与客户达到互利共赢。而这表现的平台便是利用互联网的电子商务网站。可是平台里依旧有历史遗留问题,即“数据亿万万,价值找不到”。数据如同改革开放,也需要开放,即流通。流通应该顺应时代与技术发展要求,因为拒绝数据意味着拒绝财富。数据“4V”时代已经来临,即数据的“大量化(Volume)、多样化(Vaviety)、快速化(Velocity)、价值化(Value)"、门户站点商情广告、网上银行支付结算、搜索引擎社交网络等多种类型的电子商务以数据的形式正改变着人们的生活。对于激增的存储数据量,剧增的数据复杂度,数据的分析研究者们突破重重困境,找到行之可行的方法,将数据的价值挖掘出来,以帮助数据拥有者能从大量的数据中寻找某些规律性以辅助决策。这个方法便是数据挖掘技术。电子商务是未来经济发动机,在电子商务中运用数据挖掘推荐页面是企业向世界全面展示形象和产品、寻找合作伙伴和扩大销售规模的最佳途径。本文通过数据挖掘技术在新兴的电子商务推荐系统领域的应用进行了初步研究。本人主要完成如下工作：一是系统的论述了目前国内外数据挖掘、电子商务及推荐系统研究的现状。二是简述了在电子商务企业中应用Web数据挖掘技术。三是阐述了在推荐系统中运用的推荐算法与技术。四是改进推荐Apriori算法,设计了一个基于Web数据挖掘的电子商务推荐系统。推荐系统是本论文的重点。在推荐系统设计之前,先是对推荐系统进行可行性分析,然后是分三大模块对推荐系统进行设计。这三大模块分别是数据访问模块、系统架构应用模块和交互用户模块。接下来对这三大模块进行细分,详细设计了组成数据访问模块的数据收集模块和数据预处理模块,组成系统架构应用模块的OLAP系统架构模块和基于B/S服务的数据挖掘系统模块,及组成交互用户模块的在线推荐模块与模式应用模块。在系统架构应用模块中运用了改进后的Apriori算法,实现关联规则的推理,确定关联页面,形成推荐集。在用户交互模块中显示运行算法后的运行界面,展示推荐系统的个性化服务。虽然在电子商务推荐系统中运用数据挖掘技术能够为商家带来大量的经济价值和利益,但它也是一把双刃剑。商家在收集大量的数据的同时,又面临着数据处理、使用、保管和安全等方面的新挑战。如何有效保护消费者个人的隐私安全等,如何真正利用数据挖掘提升企业的价值,如何在移动互联网时代让更多的数据以非结构化的形式出现,数据挖掘发展还任重而道远。
[89]常凯.基于神经网络的数据挖掘分类算法比较和分析研究[D].导师：王爱平.安徽大学,2014.
关键词:数据挖掘,分类,人工神经网络,BP神经网络,支持向量机,极限学习机
摘要:随着信息技术的发展,人们生产数据和采集数据的能力愈来愈高,但是,我们在数据分析和知识获取方面,能力还相对滞后。因此,从收集数据、创建数据库,管理数据,到数据分析,数据挖掘技术渐渐产生和发展。数据挖掘(Data Mining, DM)是一门跨学科的课题,涉及许多领域,包括统计学(Statistics)、数据库(Database)、机器学习(Machine Learning)和人工智能(Artificial Intelligence)等。数据挖掘,也被称为数据库中的知识发现,是从“海洋般”的大量数据中获取新颖的、有用的、有效的、可理解的模式的非平凡过程,也就是从大量数据里提取知识。分类(Classification)问题是数据挖掘技术中非常重要的研究课题,利用分类技术,可以从数据集中提取出描述数据类相同的模型或函数,并且能够顺利把数据集中每一个未知类别的数据划归到某个已知的类别中去。目前,常用的数据挖掘分类算法主要有：统计分类法、决策树、人工神经网络方法等。不同的算法会产生不同的分类器,而不同的分类器又会影响数据挖掘的准确率和数据挖掘的效率。因此,当面对数据量庞大的分类问题时,选择适当的分类算法是非常有必要的。人工神经网络(Artificial Neural Network, ANN)是数据挖掘常用的方法之一,该方法通过模拟人脑生物神经网络,将若干个具有处理功能的神经元(neurone)节点,按照一定的网络结构连接起来,使它能够处理不精确数据、模糊数据或者复杂的非线性映射问题。人工神经网络能够识别的模式是由网络的连接权值、拓扑结构及神经元阈值决定的。通过优化人工神经网络的拓扑结构及网络的权值、阈值,可以达到优化人工神经网络模型的目的。本文针对实际应用中的分类问题,详细介绍了三种人工神经网络算法的网络结构和算法描述,以及三种算法的优缺点,重点阐述了极限学习机的理论基础。将极限学习机算法应用于六个真实的数据集中,实现分类应用试验,并对实验结果与支持向量机和BP算法实验结果进行比较分析。通过实验结果发现,极限学习机在分类时间和准确率等反面,均具有明显的优势。
[90]糜元根.数据挖掘方法的评述[J].南京化工大学学报(自然科学版),2001, 05:105-110.
关键词:数据挖掘,神经网络,决策树,粗集,遗传算法,云模型
摘要:决策离不开知识 ,从数据库中采掘知识 ,是解决从大信息量中获取有用知识的有效途径。但是在实际数据库中 ,数据的复杂性 (如信息量大、噪声等 )对数据挖掘方法提出了比机器学习更高的要求 ,这方面的研究正受到越来越多的关注。本文就当前数据挖掘的几种主要方法 ,即神经网络、决策树、粗集和云模型等方法的研究现状进行了评述 ,指出其存在的问题。从总体上看 ,这些方法都有局限性 ,但它们的有机组合具有互补性 ,多方法融合将成为数据挖掘的发展趋势 ,最后指出数据挖掘方法面临的挑战
[91]赵丹群.数据挖掘:原理、方法及其应用[J].现代图书情报技术,2000, 06:41-44.
关键词:数据挖掘,数据采掘,知识发现,KDD
摘要:数据挖掘是当前数据库和信息决策领域的最前沿研究方向之一。首先介绍了数据挖掘的基本概念和处理过程,然后分别分析了数据挖掘所发现的主要知识类型和使用的技术方法 ,最后对基于 Web的几个数据挖掘应用系统进行了较为细致的剖析 ,并指出数据挖掘技术和搜索引擎技术的结合对网络信息的发现、搜集和管理、利用具有巨大的发展前景
[92]邓博.基于数据挖掘技术构建电信4G客户预测模型的研究[D].导师：张瑞生.兰州大学,2015.
关键词:数据挖掘,电信大数据,4G客户预测模型,决策树算法,Logistic回归,SVM算法,Hadoop
摘要:2013年12月,中国正式进入4G时代。与此同时,运营商之间的4G客户竞争也进入白热化阶段。随着数据挖掘技术的广泛应用和运营商积累的越来越多的数据,如何利用数据挖掘技术手段处理电信大数据,受到越来愈多人的关注与研究。4G时代,针对电信业客户关系管理的需要,在现有的数据仓库技术和数据挖掘技术基础上,帮助运营商找出潜在的4G客户,扩大其市场占有份额,对电信运营商来讲具有很重大的现实意义和经济效益。本文研究的4G客户预测问题正是在这样一个时代背景下旨在为扩大运营商的4G客户规模而提出的。本文所采用的数据集来自于某电信公司。最主要的目标是建立一个准确率高的、实用性强的电信4G客户预测模型。模型的建立以数据挖掘的CRISP-DM方法论为基础。首先,在模型构建的准备阶段,本文对原始的电信数据进行了集成、清洗、规约、转换、分割等一系列的数据预处理工作,初步筛选并构建了模型的预测指标体系。然后,建立决策树、Logistics回归、SVM这三种4G客户预测模型,经过多次的模型训练与对比,最终选择出效果最好的决策树模型应用于电信4G客户预测。在模型应用阶段,参照预测模型计算出的所有客户得分情况,重点关注的对象是那些得分较高的客户,对这部分潜在的4G客户进行有针对性的业务推广和精确营销,从而达到扩大4G客户规模的目的。最后,本文还搭建了一个具有9个节点的Hadoop集群,实现了决策树C4.5算法的并行化,有效地解决了单机无法处理大规模数据的问题,验证了Hadoop平台在处理电信大数据方面的高效性与可扩展性。本文是把数据挖掘理论和实际项目相结合一个典型案例,利用数据挖掘的相关技术建立了电信4G客户预测模型。结果表明,所建立的模型是基本符合电信实际需求的,能够提供有价值的预测信息给相关的决策人员和市场营销人员,对电信运营商扩大4G客户规模具有重大的现实意义。
[93]刘欢.数据挖掘在淘宝客户评价方面的研究与应用[D].导师：张景祥.济南大学,2014.
关键词:数据挖掘,关联规则,文本分析,分词,词频统计
摘要:数据挖掘（Data Mining，简称DM）主要是将众多的、冗杂的、存储在数据库中的数据转化成对人们有使用意义的信息的一系列过程。这些潜藏在数据中的信息大多是不可预测的。DM的聚类算法、分类算法、关联规则等算法在各个领域得到广泛应用，例如本文所提到的在电子商务、教育系统、医学领域中的应用。近些年，将DM技术应用到电子商务领域是倍受大家关注的一个研究方向。这也是本文选取数据挖掘在淘宝客户评价方面的研究与应用为题的原因。课题中主要运用到数据挖掘技术中的关联规则挖掘找出淘宝客户评价中描述产品属性的特征词。本文首先分析淘宝网信誉评价体系特点，了解其评价指标以及每个指标具有的实时性和评分标准，以及店铺综合评分的评判指标和评分计算方法。随后从淘宝网用户具体评价入手，利用ICTCLAS汉语分词系统对SQL Server数据库中的用户评价进行逐句分词处理。随即，运用关联规则挖掘算法找出客户评价中描述产品特性的词汇，并提取出与该产品特性词汇相关联的观点词以及观点词的极性。最后，统计出客户对产品以及与产品相关的服务的满意度，为管理者和经营者提供真实可靠的宝贵信息。客户在评价中提到的描述产品特性的高频词汇可视为客户比较在乎的产品属性，对于经销商来说极具有参考价值。同时这也描述产品特性的词汇也是潜在客户比较关注的方面，可以提高客户购买效率也防止电子商务平台的营销欺骗。在本文的最后一章，我们依据以上几章的理论基础和实际考察。选取Visual Studio（简称VS）作为开发环境，C#语言作为开发语言，在winForm中建造UI界面，对于用户来说具有较强的可用性，系统操作简单，且方便易懂。在系统实现的整个过程中，全方位考虑系统的可用性，整个系统分为五个模块：旗舰店信誉提取、客户评价提取、评价文本分析、分析结果展示和旗舰店信用对比。文本分析模块将分类算法与关联规则算法相结合，找出最优分词和词性标注算法，提高系统的准确率。分析结果展示又分为两个模块，来提高软件的可靠性。在本文最后，文本做出总结并对数据挖掘技术和电子商务的发展做出展望。
[94]张伟,杨炳儒,宋威.多关系数据挖掘研究综述[J].计算机工程与应用,2006, 02:1-6.
关键词:多关系数据挖掘,归纳逻辑程序设计,多关系决策树,关系距离测度,多关系关联规则,统计关系学习
摘要:多关系数据挖掘是近年来快速发展的重要的数据挖掘领域之一。传统的数据挖掘方法只能完成单一关系中的模式发现,多关系数据挖掘能够从复杂结构化数据中发现涉及多个关系的复杂模式。该文综述了多关系数据挖掘的研究状况。首先分析了多关系数据挖掘领域发生的原因和背景,其次总结了多关系数据挖掘研究的一般方法,然后介绍、分析了最具代表性的多关系数据挖掘算法。最后,总结了多关系数据挖掘将来发展需重点解决的问题和面临的挑战。
[95]张慧萍.数据挖掘技术与应用研究[D].导师：程耕国.武汉科技大学,2005.
关键词:数据挖掘,关联规则,FP-growth算法,频繁项集
摘要:本课题旨在研究数据挖掘技术及其应用,包括对数据挖掘算法的理论研究及数据挖掘技术的应用研究等内容。数据挖掘是兴起于九十年代的一项用于决策支持的新技术。作为数据库中知识发现的一个重要步骤,它主要对数据进行微观、中观乃至宏观的统计、分析、综合和推理,以指导实际问题的求解,企图发现事件间的相互关联,甚至利用已有的数据对未来的活动进行预测。数据挖掘是一门广义的交叉学科,涉及数据库、人工智能、数理统计、并行计算等多方面的知识,由于数据挖掘算法的好坏直接影响到所发现知识的质量,因此挖掘算法是数据挖掘的一个研究重点。本文首先对数据挖掘的概念及应用进行了较详尽的阐述,然后重点研究分析数据挖掘的一个重要方面一一关联规则挖掘,对其概念、算法进行了分析,并且着重研究了FP-growth算法。最后本文具体分析了一个数据挖掘在房地产行业中的应用实例来说明数据挖掘的应用过程。在课题的研究过程中,我通过阅读大量国内外著作、论文,对数据挖掘技术的理论和应用有了一个较为全面的了解,在理论上对关联规则的挖掘算法进行了深入的研究;对于数据挖掘的应用通过实现具体的实例进行研究,并且对挖掘结果进行评价,从而对数据挖掘的应用步骤有了更加深刻的理解。数据挖掘是一种基于应用的技术,因此很多知识和经验还需要我们在实践中进一步总结和发现。
[96]周艳山.数据挖掘中关联规则算法的研究及应用[D].导师：滕春贤.哈尔滨理工大学,2005.
关键词:数据挖掘,关联规则,Apriori 算法
摘要:近年来,数据挖掘己经引起了信息产业界的极大关注,这是快速增长的数据量和日益贫乏的信息量之间矛盾运动的必然结果,对数据挖掘技术进行系统、深入、全面、详尽地研究是全球信息化发展的客观需要。本文对数据挖掘技术,尤其是关联规则数据挖掘技术进行了系统、深入、全面、详尽地分析和研究,主要包括以下一些内容:数据挖掘技术的分析与研究。对数据挖掘技术的国内外研究现状进行了广泛而全面地归纳、分析和研究,对数据挖掘技术的未来发展趋势和热点研究领域进行了总结和探讨,对数据挖掘的定义及定位进行了简要的回顾,在数据挖掘基本概念的基础上,对数据挖掘常使用的技术和研究的对象进行了详细地分类、归纳和总结。为本文的全面展开奠定了基础。关联规则数据挖掘技术的分析与研究。在介绍关联规则基本概念的基础上,对关联规则的Apriori 算法进行了详细地分析和研究,并就目前针对提高该算法效率的各种优化技术也进行了详细地描述,在此基础上提出了基于筛选压缩的Apriori 挖掘算法。并进行了模拟实验,比较结果显示基于筛选压缩的Apriori挖掘算法极大的提高了效率。
[97]曹丹阳.数据挖掘在教务系统中的应用研究[D].导师：李晋宏.北方工业大学,2006.
关键词:数据挖掘,数据仓库,决策树,聚类分析,教务系统
摘要:数据仓库和数据挖掘是数据库研究、开发和应用最活跃的分支之一,也是决策支持系统的关键因素,数据仓库是一个支持管理决策过程的、面向主题的、随时间而变的数据集合,它是集成的,也是稳定的。数据挖掘是采用人工智能的方法对数据库和数据仓库中的数据进行分析、获取知识的过程。它们的结合能更好地为企业或有关部门不同范围的决策分析提供有力的依据。纵观以往的教学管理系统,多半是OLTP系统,缺乏综合分析、辅助决策的能力;并且对其历史积累的海量信息中隐含知识的利用无能为力。对教学管理进行分析是教学评估的重要手段,采用数据挖掘技术对教务数据进行多层次、多角度的分析与挖掘,利用挖掘结果辅助教学决策是保证教学质量、提高学生素质的必然要求。本文主要探讨了基于数据仓库的数据挖掘技术的基本理论和实施方法,探索了数据挖掘分类方法和聚类方法。结合教务系统,改进分类方法中的决策树算法并应用于英语四级成绩分析,实现聚类方法中的K-平均算法和k-中心点算法并应用于学生毕业情况分析,从而实现了基于教务的数据挖掘系统。本文首先从决策分析需求出发构建教务系统数据仓库;接着对数据进行预处理并改进概念分层方法,使概念分层更适合教务系统数据挖掘;而后对预处理后的数据以图、表的形式分析统计;最后利用改进的数据挖掘算法对数据进行挖掘,得出有效结果并运用于实践中。通过在教务系统中的具体挖掘实践,得到了许多有价值的信息,这些知识在帮助学校更好地进行学生的培养,对学生表现情况的掌握以及课程的安排等方面无疑具有重要的指导意义。
[98]王丽娜.基于粗糙集的数据挖掘改进的属性约简算法研究[D].导师：祝峰.电子科技大学,2012.
关键词:数据挖掘,粗糙集,属性约简
摘要:目前数据挖掘的方法有很多，本文主要研究了数据挖掘中的粗糙集方法，重点研究了基于粗糙集的属性约简算法在数据挖掘规则提取阶段的应用。粗糙集在数据挖掘中通常被用于知识的约简，从而进行规则的提取。属性约简是粗糙集理论研究的核心内容之一。本文对传统的基于粗糙集的属性约简算法深入研究的同时进行了改进，并针对大规模数据集的数据挖掘，提出了一种新的属性约简算法。粗糙集理论是一种新的处理模糊和不精确问题的重要数学工具，是一种新的数据挖掘技术。传统的属性约简算法要么空间复杂度比较高，要么约简不够精确，本文提出的新的属性约简算法很好的解决了空间复杂度的问题，适合对数据挖掘中的大表、大文件进行约简，从而得出具体的规则，这是传统的属性约简算法不能做到的。本文的主要研究内容如下：（1）对基于粗糙集的数据挖掘研究现状进行了分析；深入研究了粗糙集相关理论知识和数据挖掘相关技术；将粗糙集与数据挖掘相结合，着重研究了基于粗糙集的数据挖掘模型，对粗糙集在数据挖掘中的应用进行了系统分析。（2）对几种传统的基于粗糙集的属性约简算法进行了深入研究，并分析其各自的优缺点。在此基础上，提出了一种改进的基于差别矩阵的属性约简算法，并通过实验验证其有效性。（3）针对传统属性约简算法在应用中暴露出的问题，本文借助数据结构中的树型结构建立了多叉树理论，并在此基础上提出了一种新的基于多叉树的属性约简算法。该算法相对于传统属性约简算法来说空间复杂度较低，适合对数据挖掘中的大表、大文件进行约简，从而得出具体的规则，较传统的属性约简算法有很大优势。（4）在UCI中选取三个不同规模的数据集作为测试训练集，通过对两个对比算法进行详细的仿真实验，验证了基于多叉树算法的可行性和有效性。
[99]段录平.基于RBF神经网络的数据挖掘研究[D].导师：周丽娟.哈尔滨理工大学,2007.
关键词:数据挖掘,RBF神经网络,分类,聚类
摘要:随着数据库技术的成熟应用和Internet的迅速发展,人们利用信息技术生产和搜集数据的能力大幅度提高,使得从大量数据中挖掘出有用的信息或知识成为一个迫切需要解决的问题。正是这种需求推动了数据挖掘兴起和数据挖掘技术的发展。数据挖掘经常要面对一些有噪声、杂乱、非线性的数据,而神经网络具有良好的鲁棒性、自适应性、并行处理、分布存储和高度容错性等特点,因此神经网络非常适合用来解决数据挖掘的一些问题。本文简单阐述了数据挖掘和人工神经网络的基本理论。在分析数据挖掘各种技术的基础上,对神经网络方法在数据挖掘中的应用进行了研究分析,接着着重研究了基于RBF神经网络的分类数据挖掘方法。在梯度算法基础推导出一种增量式的学习算法,在训练过程中该算法可以自适应调整网络参数。然后在IRIS数据库上进行分类实验,仿真实验结果表明该算法性能较好。在对RBF神经网络训练算法深入研究的基础上,本文采用了两阶段学习策略来加速学习收敛;提出动静相结合的隐含层设计方法来构造出较优的隐含层结构;提出采用误差校正的思想来改进RBF网络输出精度,并给出了其实现算法。并对这些改进算法在UCI数据库上进行了实验和对比分析,实验结果表明改进后的算法其性能均有明显提高。基于对数据挖掘和神经网络技术的研究,开发了一个主要用作实验平台的集成了本文各种算法的数据挖掘系统。本论文研究的基于RBF神经网络的数据挖掘方法具有一定的理论深度和实用价值,尤其创新的学习算法可以为相关的科研工作提供有益的参考。
[100]张春华,王阳.数据挖掘技术、应用及发展趋势[J].现代情报,2003, 04:47-48+50.
关键词:KDD,数据挖掘,知识
摘要:数据挖掘是当前数据库和信息决策领域的最前沿研究方向之一。本文从知识发现和数据挖掘的概念出发 ,总结了数据挖掘常采用的技术方法 ,同时对数据挖掘的应用及发展进行了阐述。